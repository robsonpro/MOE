[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelagem e Otimização de Experimentos",
    "section": "",
    "text": "Prefácio\nLivro sobre planejamento, modelagem e otimização de experimentos científicos e industriais utilizando a linguagem R.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "01-Intro.html",
    "href": "01-Intro.html",
    "title": "1  Introdução",
    "section": "",
    "text": "1.1 Testes de hipóteses e conceitos fundamentais\nInferência é o ramo da estatística que trata da obtenção de informações acerca de um parâmetro populacional a partir de dados amostrais. Em outras palavras, pode-se dizer que inferência constiste no aprendizado sobre a população considerando um conjunto limitado, porém suficiente, de observações retiradas desta. Em diversas situações deseja-se obter informações de parâmetros desconhecidos de uma população de interesse. Por exemplo, de um lote de tubos sem costura produzidos em um determinado horizonte de produção, por uma determinada empresa metalúrgica. Neste caso é viável coletar uma amostra para inspecionar e inferir sobre o diâmetro médio da população de tubos produzida em relação a um valor alvo de interesse. Em outros procedimentos, podem ser comparados processos, materiais, métodos de preparação, entre outras fontes de variação de interesse científico e industrial.\nNeste capítulo serão abordadas algumas distribuições essenciais à modelagem e análise de experimentos. Posteriormente serão abordados alguns testes de hipóteses para média de uma e duas amostras. Finalmente será abordada a análise de variância para um fator.\nNeste capítulo são utilizados os pacotes DescTools, asbio, ggpubr e ggExtra. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). Sempre que aparecer nos blocos de código R propostos o comando library(&lt;nome_pacote&gt;) para carregar um determinado pacote, antes este deve ser instalado.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#distribuição-normal",
    "href": "01-Intro.html#distribuição-normal",
    "title": "1  Introdução",
    "section": "1.2 Distribuição normal",
    "text": "1.2 Distribuição normal\nSeja uma amostra aleatória de \\(n\\) observações,\\(x_1\\), \\(x_2\\), …, \\(x_n\\), retirada de uma população de tamanho \\(N\\). Cada observação amostral é retirada de forma independente. Se a população de origem é dita normal, ela é descrita pela função densidade de probabilidade (fdp) da Equação 1.1. Uma variável aleatória (va) \\(x\\) descrita por esta distribuição é dita normal com média \\(\\mu\\) e variância \\(\\sigma^2\\), isto é \\(x \\sim N(\\mu,\\sigma^2)\\).\n\\[\n  f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^{2}}\n\\tag{1.1}\\]\nA Figura 1.1 ilustra a função densidade de probabilidade da distribuição normal de uma variável aleatória (va) \\(x \\sim N(100,1)\\), enquanto a Figura 1.2 expõe um histograma de uma amostra com n = 1000 observações retirada de tal va. O código para obter tais gráficos no R são expostos à seguir.\n\n\n\n\n\n\n\n\nFigura 1.1: fdp normal, \\(\\mu = 100\\), \\(\\sigma^2 = 1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 1.2: histograma de uma amostra com n = 1000 observações retirada de uma população \\(N(100,1)\\)\n\n\n\n\n\nA Figura 1.3 expõe gráficos de densidade de probabilidade da função normal com variação nos parâmetros de posição (média) e dispersão (variância). Pode-se observar que o aumento na média apenas desloca a distribuição para a direita, enquanto o aumento na variância resulta em uma distribuição com maior probabilidade nas caudas e menor probabilidade na média. Quando duas vas tem médias diferentes, com variância igual, diz-se haver um viés ou vício entre estas, enquanto duas vas com médias iguais e variâncias distintas, são ditas com erro aleatório distinto. A distribuição normal é simétrica e assíntota, tendo portanto domínio \\(x \\in (-\\infty, +\\infty)\\).\n\n\n\n\n\n\n\n\nFigura 1.3: Variação dos parâmetros da distribuição normal\n\n\n\n\n\nOs parâmetos populacionais da distribuição normal podem ser calculados conforme a Equação 1.2 e a Equação 1.3. A variância populacional \\(\\sigma^2\\) tem unidade de medida igual ao quadrado da unidade de medida da va em avaliação. Neste sentido, uma outra medida é comumente utilizada como medida de dispersão, o desvio-padrão, \\(\\sigma\\), sendo calculado conforme a Equação 1.4. O desvio-padrão, \\(\\sigma\\), tem sua unidade de medida igual à da va de interesse, sendo de interpretação mais fácil como medida de dispersão em situações práticas. Uma propriedade importante do desvio-padrão é que no gráfico da função densidade de probabilidade os pontos de inflexão estão à distância de um desvio-padrão em relação à média, conforme ilustrado na Figura 1.4.\n\\[\n  \\mu = \\frac{\\sum_{i = 1}^{N}x_i}{N} = \\frac{x_1+x_2+\\dots+x_N}{N}\n\\tag{1.2}\\]\n\\[\n  \\sigma^2 = \\frac{\\sum_{i = 1}^{N}(x_i - \\mu)^2}{N}\n\\tag{1.3}\\]\n\\[\n  \\sigma = \\sqrt{\\frac{\\sum_{i = 1}^{N}(x_i - \\mu)^2}{N}}\n\\tag{1.4}\\]\n\n\n\n\n\n\n\n\nFigura 1.4: Desvio-padrão \\(\\sigma\\), \\(N(0, 1)\\)\n\n\n\n\n\nAo obter uma amostra de uma distribuição normal com parâmetros desconhecidos é importante estimar os parâmetros populacionais. A estimativa para a média, \\(\\hat{\\mu} = \\bar{x}\\), é obtida conforme a Equação 1.5, tomando, portanto, a razão entre a soma das \\(n\\) observações, \\(x_1, x_2, ..., x_n\\), e o tamanho amostral \\(n\\). Já a variância amostral \\(\\hat{\\sigma}^2 = s^2\\) é estimada considerando o quadrado da soma dos desvios em relação à média, dividido pelo número de graus de liberdade da amostra \\(n - 1\\), conforme Equação 1.6. O desvio-padrão amostral também pode ser obtido tomando a raiz quadrada da variância amostral, conforme Equação 1.7.\n\\[\n  \\bar{x} = \\frac{\\sum_{i = 1}^{n}x_i}{n} = \\frac{x_1+x_2+...+x_n}{n}\n\\tag{1.5}\\]\n\\[\n  s^2 = \\frac{\\sum_{i = 1}^{n}(x_i - \\bar{x})^2}{n - 1}\n\\tag{1.6}\\]\n\\[\n  s = \\sqrt{\\frac{\\sum_{i = 1}^{n}(x_i - \\bar{x})^2}{n - 1}}\n\\tag{1.7}\\]\nEm uma distribuição de probabilidade contínua, como a normal, a probabilidade consiste na área sob a curva, enquanto as distribuições discretas admitem a probabilidade pontual, conforme expresso na Tabela 1.1. A Figura 1.5 ilustra o conceito de probabilidade pontual em distribuição discreta e de probabilidade em um intervalo de interesse, consistindo na área sob a curva da função densidade de probabilidade, no caso contínuo.\n\n\n\n\nTabela 1.1: Probabilidade em distribuição discreta e contínua\n\n\n\n\n\n\n\n\n\n\nDistribuição discreta\nDistribuição contínua\n\n\n\n\n0 \\(\\leq p(x_j) \\leq 1\\)\n\\(p(a \\leq x \\leq b) = \\int_a^b f(x)dx\\)\n\n\n\\(\\sum_{j=1}^{n} p(x_j) = 1\\)\n\\(\\int_{-\\infty}^{+\\infty} f(x)dx = 1\\)\n\n\n\\(\\mu = E(x) = \\sum_{j=1}^{n} x_jp(x_j)\\)\n\\(\\mu = E(x) = \\int_{-\\infty}^{+\\infty} xf(x)dx\\)\n\n\n\\(\\sigma^2 = Var(x) = \\sum_{j=1}^{n} (x_j-\\mu)^2p(x_j)\\)\n\\(\\sigma^2 = Var(x) = \\int_{-\\infty}^{+\\infty} (x-\\mu)^2f(x)dx\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 1.5: probabilidade em (a) distribuição discreta e (b) contínua\n\n\n\n\n\nAinda conforme expresso na Tabela 1.1, para o caso discreto o total de todos os eventos deve ser unitário. De maneira análoga, a integral de uma função densidade de probabilidade contínua em todo o seu domínio deve ser igual à unidade. A média de uma va pode ser descrita utilizando o operador de esperança \\(\\mu = E(x)\\). No caso discreto a média consiste na soma do produto entre os eventos e suas respectivas probabilidades em todo o espaço amostral. Já no caso contínuo, a média consiste na integral do produto entre o valor da va e sua fdp em todo o domínio da função. A variância de uma va pode ser descrita através do operador de variância, que por sua vez, pode ser descrito usando o operador de esperança, isto é, \\(\\sigma^2= Var(x) = E[(x-\\mu)^2]\\). A Tabela 1.1 finaliza expondo o cálculo da variância para os casos discreto e contínuo.\nAlgumas propriedades dos operadores de média ou esperança e variância são essenciais à análise, modelagem e otimização de experimentos, sendo resumidas na Tabela 1.2, sendo \\(x\\) uma va com média \\(E(x)=\\mu_x\\) e variância \\(V(x)=\\sigma_x^2\\). Seja \\(a\\) uma constante \\(a \\in \\Re\\). Seja também uma va \\(y\\) com média \\(E(y)=\\mu_y\\) e variância \\(V(y)=\\sigma_y^2\\), sendo \\(x\\) e \\(y\\) vas independentes, é possível provar as propriedades resumidas na Tabela 1.2.\n\n\n\n\nTabela 1.2: Propriedades dos operadores de média e variância\n\n\n\n\n\n\nOperador de média ou esperança\nOperador de variâncias\n\n\n\n\n\\(E(x)=\\mu_x\\)\n\\(V(x)=E[(x-\\mu_x)^2]=E(x^2)−E^2(x)\\)\n\n\n\\(E(a)=a\\)\n\\(V(a)=0\\)\n\n\n\\(E(a+x) = a + E(x)\\)\n\\(V(a+x) = V(x)\\)\n\n\n\\(E(ax) = aE(x)\\)\n\\(V(ax) = a^2V(x)\\)\n\n\n\\(E(x + y) = E(x) + E(y)\\)\n\\(V(x+y)=V(x-y)=V(x)+V(y)\\)\n\n\n\n\n\n\n\n\nTomando uma variável aleatória que segue a distribuição normal com parâmetros \\(\\mu\\) e \\(\\sigma^2\\), isto é, \\(x \\sim N(\\mu,\\sigma^2)\\), é possível calcular probabilidades considerando valores de interesse do investigador, conforme o Exemplo a seguir.\nSeja um processo de trefilação de aço que produz arames com diâmetro médio mm \\(\\mu\\) = 3,40 e variância \\(\\sigma^2 = 0,10^2 mm^2\\). Deseja-se calcular a probabilidade de o diâmetro ser menor que 3,30 mm.\nNo R é fácil calcular esta probabilidade através do comando pnorm, conforme segue. Logo, \\(P(x &lt; 3,3) = 0.1586553\\). A Figura 1.6 ilustra esta probabilidade.\n\n# P(x &lt; 3,3)\npnorm(q = 3.3, mean = 3.4, sd = 0.1)\n\n[1] 0.1586553\n\n\n\n\n\n\n\n\n\n\nFigura 1.6: \\(P(x&lt;3,3), x \\sim N(3,4; 0,1^2)\\)\n\n\n\n\n\nPara obter o gráfico da função densidade de probabilidade com a área relacionada à probabilidade hachurada, similar ao da Figura 1.6, deve-se utilizar o código a seguir.\n\ndf &lt;- data.frame(\n  x = seq(3, 3.8, length = 500),\n  y = dnorm(seq(3, 3.8, length = 500), mean = 3.4, sd = 0.1)\n)\nshaded_area &lt;- data.frame(\n  x = seq(3, 3.3, length = 100),\n  y = dnorm(seq(3, 3.3, length = 100), mean = 3.4, sd = 0.1)\n)\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\", linewidth = 0.8) +\n  geom_ribbon(\n    data = shaded_area,\n    aes(ymin = 0, ymax = y),\n    fill = \"seagreen3\", alpha = 0.5\n  ) +\n  annotate(\"text\", x = 3.15, y = 1, \n           label = \"P(x &lt; 3.3)\", color = \"green4\", size = 5) +\n  labs(x = \"x\", y = \"Probabilidade\")\n\nUm caso particular da distribuição normal é a normal padrão \\(z \\sim N(0,1)\\). É comum utilizá-la como referência para obter escores da distribuição normal, isto é valores \\(Z\\) em relação à uma probabilidade de interesse. Além disso, a padronização deixa a va normal adimensional e centrada em zero e com desvio-padrão unitário. São facilmente encontradas tabelas para estes valores considerando probabilidades distintas. Entretanto, o advento dos pacotes computacionais estatísticos diminui a necessidade destas. Qualquer variável aleatória normalmente distribuída, \\(x \\sim N(\\mu,\\sigma^2)\\), pode ser padronizada utilizando-se a Equação 1.8.\n\\[\n  z = \\frac{x-\\mu}{\\sigma}\n\\tag{1.8}\\]\nA Equação 1.9 expõe a função densidade de probabilidade da distribuição normal padrão \\(z\\). O coeficiente \\(\\frac{1}{\\sqrt{2\\pi}}\\) garante que a área sob a curva seja unitária. A probabilidade à esquerda de um valor de interesse é denotada \\(\\Phi(\\zeta) = P(z \\leq \\zeta)\\), sendo calculada conforme a Equação 1.10. A Figura 1.7 ilustra três exemplos com probabilidade de 0,25, 0,5 e 0,75.\n\\[\n  f(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}z^{2}}\n\\tag{1.9}\\]\n\\[\n  \\Phi(\\zeta) = \\int_{-\\infty}^{\\zeta} f(z) dz\n\\tag{1.10}\\]\n\n\n\n\n\n\n\n\nFigura 1.7: quantil \\(\\phi(z_q) = q\\)\n\n\n\n\n\nPara encontrar no R o valor da probabilidade à esquerda associada a um determinado valor \\(z_p\\), deve-se utilizar o comando pnorm(zq), enquanto para determinar o valor \\(z_p\\) associado a uma probabilidade \\(p\\) de interesse, deve-se utilizar o comando qnorm(p), conforme exemplos à seguir.\n\n# probabilidade phi(z_q) para z = 0.6744898\npnorm(0.6744898)\n\n[1] 0.75\n\n# valor z_q associado à probabilidade p = 0.75, P(Z &lt; z_q) = 0.5\nqnorm(0.75)\n\n[1] 0.6744898\n\n# probabilidade p para z_p = 0 \npnorm(0)\n\n[1] 0.5\n\n# valor z_p associado à probabilidade p = 0.5\nqnorm(0.5)\n\n[1] 0\n\n# probabilidade q para z_p = -0.6744898 \npnorm(-0.6744898)\n\n[1] 0.25\n\n# valor z associado à probabilidade p = 0.25\nqnorm(0.25)\n\n[1] -0.6744898\n\n\nUma regra usual da distribuição normal é a regra 68-95-99%. Por esta regra sabe-se que na distribuição normal a probabilidade entre \\(\\pm 1\\) desvio-padrão em relação à média é igual a 0,6827, enquanto a probabilidade entre \\(\\pm 2\\) desvios-padrões em relação à média é igual a 0,9545. Por fim, a probabilidade entre \\(\\pm 3\\) desvios é igual a 0,9973, conforme ilustrado na Figura 1.8. Em metrologia é comum a incerteza de medição ser calculada considerando mais ou menos dois desvios-padrões em relação à média do mensurando corrigida, sendo considerado 0.9545 de confiança ara encontrar o erro de medição. Em controle estatístico de qualidade é comum o uso de mais ou menos três desvios-padrões em relação à média em cartas de controle, sendo o nível de confiança de 0.9973 o mais usado em tais aplicações. Para calcular tais probabilidades na linguagem R, pode-se utilizar o código abaixo.\n\n# P(-1&lt;z&lt;1)\npnorm(q = 1)-pnorm(q = -1)\n\n[1] 0.6826895\n\n# P(-2&lt;z&lt;2)\npnorm(q = 2)-pnorm(q = -2)\n\n[1] 0.9544997\n\n# P(-3&lt;z&lt;3)\npnorm(q = 3)-pnorm(q = -3)\n\n[1] 0.9973002\n\n\n\n\n\n\n\n\n\n\nFigura 1.8: Regra 68-95-99.7\n\n\n\n\n\nApós todas estas constatações, é viável apresentar o Teorema 1.1, denominado central do limite (TCL), sendo este essencial à inferência e estatística experimental.\n\nTeorema 1.1 (Teorema central do limite) Sejam \\(n\\) variáveis aleatórias \\(x_1, x_2, ..., x_n\\), sendo estas independentes e identicamente distribuídas (iid), com média \\(\\mu\\) e variância \\(\\sigma^2\\). A média amostral \\(\\bar{x}\\) é aproximadamente normal com média \\(\\mu\\) e variância \\(\\sigma^2/n\\):\n\\(\\bar{x} \\sim N(\\mu,\\frac{\\sigma^2}{n})\\)\nDe maneira análoga,\n\\(P(\\frac{\\mu - \\bar{x}}{\\sigma/\\sqrt{n}} \\leq z) \\rightarrow \\Phi(z)\\)\n\nPelo TCL, para um \\(n\\) suficientemente grande, pode-se afirmar que a média amostral é aproximadamente normalmente distribuída com média \\(\\mu\\) e variância \\(\\frac{\\sigma^2}{n}\\). Ademais, o desvio-padrão da média amostral é igual \\(\\sigma/\\sqrt{n}\\). O enunciado do TCL tem diversas implicações em modelagem e otimização de experimentos planejados, sendo, portanto, essencial sua compreensão.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#distribuição-chi-quadrado",
    "href": "01-Intro.html#distribuição-chi-quadrado",
    "title": "1  Introdução",
    "section": "1.3 Distribuição Chi-quadrado",
    "text": "1.3 Distribuição Chi-quadrado\nA distribuição da variância amostral \\(s^2\\) é de interesse em muitos problemas de inferência. A distribuição chi-quadrado, denotada \\(\\chi^2\\), com \\(k\\) graus de liberdade é utilizada para descrever a soma dos quadrados de \\(k\\) vas normais-padrão independentes, \\(z_i \\sim N(0,1)\\), conforme segue. Uma vez que, ao calcular a variância amostral, conforme Equação @ref(eq:samplevar), toma-se a soma dos quadrados dos desvios das observações em relação à média, isto é, a soma dos quadrados de vas normais-padrão, pode-se inferir que a variância é distribuída pela va segue a distribuição \\(\\chi^2\\).\n\\[\n  z_1^2 + z_2^2 + ... + z_k^2 \\sim \\chi^2\n\\]\nA Equação 1.11 expõe a função densidade de probabilidade da distribuição \\(\\chi^2\\), onde \\(\\Gamma(k/2)\\) denota a função gamma, \\(\\Gamma(n) = (n-1)!\\). A Figura 1.9 expõe gráficos da fdp \\(\\chi^2\\) com variação do número de graus de liberdade.\n\\[\n  f(x) = \\frac{1}{\\Gamma(k/2)2^{k/2}} x^{(k/2)-1} e^{-x/2}\n\\tag{1.11}\\]\n\n\n\n\n\n\n\n\nFigura 1.9: Distribuição chi-quadrado com \\(k\\) graus de liberdade\n\n\n\n\n\nPara obter um gráfico da fdp da distribuição \\(\\chi^2\\) pode-se utilizar um código similar ao que segue.\n\ndf &lt;- data.frame(\n  x = rep(seq(0, 20, length = 500), 5),\n  y = c(dchisq(seq(0, 20, length = 500), 1),\n        dchisq(seq(0, 20, length = 500), 2),\n        dchisq(seq(0, 20, length = 500), 3), \n        dchisq(seq(0, 20, length = 500), 5),\n        dchisq(seq(0, 20, length = 500), 9)),\n  k = factor(rep(c(1, 2, 3, 5, 9), each = 500))\n)\n\nggplot(df, aes(x, y, color = k)) + \n  geom_line() +\n  scale_color_manual(values = c(\"1\" = \"darkgreen\", \n                              \"2\" = \"blue\",\n                              \"3\" = \"red\",\n                              \"5\" = \"orange\", \n                              \"9\" = \"purple\"),\n                    labels = c(\"k=1\", \"k=2\", \"k=3\", \"k=5\", \"k=9\")) +\n  labs(x = \"x\", y = \"densidade\", color = NULL) +\n  coord_cartesian(ylim = c(0, 0.5))\n\nPara obter uma determinada probabilidade à esquerda de um determinado valor na distribuição Chi-quadrado, pode-se utilizar o comando pchisq(), conforme segue.\n\n\n[1] 0.8282029\n\n\nCaso o analista deseje obter a probabilidade à direita do valor de interesse, deve-se utilizar o argumento lower.tail = FALSE.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#distribuição-t-de-student",
    "href": "01-Intro.html#distribuição-t-de-student",
    "title": "1  Introdução",
    "section": "1.4 Distribuição t de Student",
    "text": "1.4 Distribuição t de Student\nNem sempre é possível garantir que a população de origem de uma determinada amostra coletada de uma va de interesse é normalmente distribuída, especialmente quando o tamanho amostral é limitado. Tomando uma amostra aleatória \\(x_1, x_2, ..., x_n\\) de uma distribuição \\(N(\\mu,\\sigma^2)\\), a quantidade\n\\[\n  \\frac{\\bar{x}- \\mu}{s / \\sqrt{n}} \\sim t_{n-1}\n\\]\nsegue a distribuição \\(t\\) de Student com \\(n-1\\) graus de liberdade. A função densidade de probabilidade da distribição \\(t\\) de Student, com \\(p=n-1\\) graus de liberdade, é exposta na Equação 1.12. A Figura 1.10 expõe a variação no formato da função com a variação no número de graus de liberdade da distribuição \\(t\\). Pode-se observar que à medida que \\(p=n-1\\) aumenta, a distribuição se aproxima da normal padrão. Neste sentido, muitos pesquisadores admitem que em procedimentos de inferência com amostras com \\(n \\geq 30\\), pode-se utilizar a distribuição \\(z \\sim N(0,1)\\).\n\\[\n  f(t) = \\frac{\\Gamma(\\frac{p-1}{2})}{\\Gamma(\\frac{p}{2})}\\frac{1}{p\\pi^{1/2}}\\frac{1}{(1+t^2/p)^{(p+1)/2}}\n\\tag{1.12}\\]\n\n\n\n\n\n\n\n\nFigura 1.10: Distribuição t de Student com \\(\\nu\\) graus de liberdade\n\n\n\n\n\nA distribuição t, assim como a normal é simétrica em relação à média, tem domínio \\(t \\in (-\\infty, +\\infty)\\), sendo, portanto, assíntota.\nPara encontrar uma determinada probabilidade à esquerda de um valor de interesse da distribuição \\(t\\) com \\(\\nu=n-1\\) graus de liberdade pode-se utilizar no R o comando pt(), conforme segue.\n\n\n[1] 0.969999\n\n\n[1] 0.03000102\n\n\n[1] 0.9234472\n\n\nDe outra forma, para se encontrar o valor \\(t\\) de interesse considerando uma determinada probabilidade, deve-se utilizar no R o comando qt(), conforme à seguir.\n\n\n[1] 0.854192\n\n\n[1] 1.311434 1.478705 1.699127 2.045230\n\n\nPara obter um gráfico da fdp da distribuição \\(t\\) pode-se utilizar um código similar ao que segue.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#distribuição-f-de-fisher-snedecor",
    "href": "01-Intro.html#distribuição-f-de-fisher-snedecor",
    "title": "1  Introdução",
    "section": "1.5 Distribuição F de Fisher-Snedecor",
    "text": "1.5 Distribuição F de Fisher-Snedecor\nA distribuição F é utilizada para descrever a razão entre vas que seguem a distribuição chi-quadrado, isto é, a razão entre variâncias. Sejam duas amostras aleatórias \\(x_1, x_2, ..., x_n\\) e \\(y_1, y_2, ..., y_m\\) retiradas, respectivamente de populações normais \\(N(\\mu_x,\\sigma_x^2)\\) e \\(N(\\mu_y,\\sigma_y^2)\\). Pode ser de interesse inferir sobre a razão entre as variâncias populacionais, \\(\\sigma_x^2 / \\sigma_y^2)\\), a partir de estimativas amostrais, \\(s_x^2 / s_y^2)\\). A quantidade\n\\[\\begin{equation}\n  \\frac{s_x^2 / \\sigma_x^2}{s_y^2 / \\sigma_y^2} \\sim F_{n-1,m-1}\n\\end{equation}\\]\nsegue a distribuição \\(F\\) de Fisher-Snedecor com \\(n-1\\) e \\(m-1\\) graus de liberdade. A razão entre variâncias pode seguir esta distribuição mesmo se as populações de origem apresentam desvios de normalidade. Analogamente à distribuição \\(t\\), a distribuição \\(F\\) deriva da normal, sendo um caso específico da distribuição \\(F\\) derivado da distribuição \\(t\\). A distribuição \\(F\\) apresenta domínio \\(F \\in [0, +\\infty)\\), por descrever a razão entre variâncias, sendo também assíntota. A Equação @ref(eq:fdpf) descreve a função densidade de probabilidade F, com \\(p=n-1\\) graus de liberdade e \\(q=m-1\\) graus de liberdade. Esta fdp é plotada com variação dos graus de liberdade na Figura @ref(fig:fdpf).\n\\[\\begin{equation}\n  f(X) = \\frac{\\Gamma(\\frac{p+q}{2})}{\\Gamma(\\frac{p}{2})\\Gamma(\\frac{q}{2})}(\\frac{p}{q})^{p/2}\\frac{x^{(p/2)-1}}{[1+(p/q)x]^{(p+q)/2}}\n  (\\#eq:fdpf)\n\\end{equation}\\]\n\n\n\n\n\nDistribuição F com n-1,m-1 graus de liberdade\n\n\n\n\nPara obter a probabilidade associada a um determinado valor de interesse da distribuição \\(F\\) com \\(p\\) e \\(q\\) graus de liberdade, pode-se utilizar a sintaxe que segue.\n\n\n[1] 0.1813001\n\n\nDe outra forma, pode ser interessante obter o valor associado a uma determinada probabilidade de interesse.\n\n\n[1] 5.317655\n\n\nO código à seguir serve para obtenção da fdp da distribuição \\(F\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#teste-t-para-média-de-uma-amostra",
    "href": "01-Intro.html#teste-t-para-média-de-uma-amostra",
    "title": "1  Introdução",
    "section": "1.6 Teste t para média de uma amostra",
    "text": "1.6 Teste t para média de uma amostra\nAinda em relação a amostra aleatória de \\(n\\) observações, \\(x_1, x_2, ..., x_n\\), retirada de uma va que segue a distribuição normal, um problema comum de decisão é o teste de hipóteses. Neste tipo de teste pode-se inferir, por exemplo, se o parâmetro em estudo é igual a um determinado valor de interesse ou não. No caso da média de uma determinada amostra de interesse, o teste \\(t\\) pode ser utilizado.\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  6.134   7.431   8.484   8.784  10.039  12.076 \n\n\n\n\n\n\n\nBox-plot de Ront \\([\\mu m]\\)\n\n\n\n\nPara responder à pergunta do experimentador, deve-se formular as hipóteses a serem testadas, sendo \\(H_0\\) a hipótese nula e \\(H_1\\) a hipótese alternativa, conforme segue.\n\\[\\begin{equation}\n  H_0: \\mu = 10\n\\end{equation}\\]\n\\[\\begin{equation}\n  H_0: \\mu &lt; 10\n\\end{equation}\\]\nO valor de interesse testado na hipótese é denotado \\(\\mu_0\\). Uma vez que o experimentador já coletou a amostra para testar sua hipótese, pode-se agora calcular a estatística do teste. Como ele coletou uma amostra de tamanho pequeno, além de a variância populacional ser desconhecida, deve-se utilizar o teste \\(t\\) para uma amostra, baseado na distribuição \\(t\\) de Student. A estatística do teste para testar uma hipótese sobre a média de uma amostra neste caso é apresentada na Equação @ref(eq:ttest). Por este cálculo padroniza-se a distribuição amostral obtida em relação ao valor hipotético, havendo mais evidência para rejeição da hipótese nula, quanto maior for o desvio negativo de \\(t_0\\) em relação a zero. Deve-se recordar que, pelo TCL, o desvio-padrão da média é \\(s_{\\bar{x}} = s/\\sqrt{n}\\).\n\\[\\begin{equation}\n  t_0 = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\n  (\\#eq:ttest)\n\\end{equation}\\]\nPara o exemplo esta estatística pode ser facilmente calculada como segue.\n\n\n[1] -2.211601\n\n\nPara julgar se a hipótese nula deve ser rejeitada em favor da alternativa ou não, deve-se definir uma região crítica ou região de rejeição de \\(H_0\\). Para tal, deve-se definir um nível de significância \\(\\alpha\\) de interesse. O nível de significância consiste em uma probabilidade que se assume ao testar a hipótese. Quanto menor, menor a probabilidade de cometer o erro de rejeitar a hipótese nula caso esta seja verdadeira. Neste caso, maior o nível de confiança do teste, \\(\\gamma = 1 - \\alpha\\). Entretanto, quanto menor o nível de significância \\(\\alpha\\), mais difícil é a rejeição da hipótese nula. É comum adotar-se em pesquisas \\(\\alpha = 0,05\\), mas alguns pesquisadores mais criteriosos costumam adotar \\(\\alpha = 0,01\\), ou valores inferiores. A Figura @ref(fig:regcrit) ilustra a distribuição \\(t\\) com 11 graus de liberdade e região crítica em vermelho para o teste em questão, considerando \\(\\alpha = 0,05\\).\n\n\n\n\n\nRegião crítica para o teste t, com \\(\\alpha = 0,05\\), \\(n-1=11\\) graus de liberdade\n\n\n\n\nConsiderando a distribição \\(t\\) com 11 graus de liberdade, pode-se obter o valor \\(t_\\alpha\\), o qual garante uma probabilidade igual a 0,05 à sua esquerda, conforme segue. Este valor \\(t_\\alpha\\) é comumente conhecido como valor crítico.\n\n\n[1] -1.795885\n\n\nPara decidir deve-se comparar o valor da estatística do teste com o valor crítico. Neste caso, como a hipótese alternativa é \\(H_0: \\mu &lt; \\mu_0\\), se \\(t_0 &lt; t_\\alpha\\), rejeita-se \\(H_0\\) em favor de \\(H_1\\). Logo, neste caso como \\(t_0 = -2,21 &lt; -1,796 = t_\\alpha\\), rejeita-se a hipótese nula, com \\(\\alpha = 0,05\\) de significância, podendo-se concluir que a média da circularidade total \\(Ron_t\\) é menor que \\(10 \\mu m\\).\nA função t.test() do R pode ser utilizada para realizar o teste \\(t\\) para uma amostra. Para o caso do Exemplo @ref(exm:t1), pode-se utilizar sintaxe que segue.\n\n\n\n    One Sample t-test\n\ndata:  Ront\nt = -2.2116, df = 11, p-value = 0.02454\nalternative hypothesis: true mean is less than 10\n95 percent confidence interval:\n     -Inf 9.771407\nsample estimates:\nmean of x \n 8.783892 \n\n\nO resultado fornece o valor de \\(t_0\\) calculado, o número de graus de liberdade do teste, e o p-valor (p-value), que consiste na probabilidade associada ao valor calculado. O resultado obtido deixa claro na saída a hipótese testada, além de fornecer um intervalo de confiança associado ao teste realizado e a estimativa pontual do parâmetro testado, isto é, a média. O intervalo de confiança consiste em limites de confiança para média, neste caso apenas o inferior, uma vez que foi realizado o teste unilateral à esquerda. A média esta acima deste limite com \\(\\gamma = 1 - \\alpha = 0,95\\) de confiança.\nNo teste unilateral à esquerda realizado o limite superior de confiança é calculado conforme Equação @ref(eq:liminf). Para o Exemplo @ref(exm:t1) este limite é de \\(9,77\\), indicando que a média é menor que este valor com \\(\\gamma = 0,95\\) de confiança.\n\\[\\begin{equation}\n  \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}} &lt; t_{(\\alpha,n-1)}\n\\end{equation}\\]\n\\[\\begin{equation}\n  \\mu &lt; \\bar{x} + t_{(1-\\alpha,n-1)}\\frac{s}{\\sqrt{n}}\n(\\#eq:liminf)\n\\end{equation}\\]\nSendo o p-valor a probabilidade associada ao valor calculado, ele também pode ser utilizado na tomada de decisão em inferência. A Figura @ref(fig:pvaluet) ilustra o p-valor, sendo neste caso a área sob a curva à esquerda do valor calculado \\(t_0\\), isto é \\(p-valor = P(t &lt; t_0) = \\Phi(t_0)\\). Pode-se constatar que, para hipótese unilateral à esquerda, \\(H_1: \\mu &lt; \\mu_0\\), \\(t_0 &lt; t_\\alpha\\) implica em \\(p-valor &lt; \\alpha\\). Quanto menor o p-valor, maior a evidência na rejeição da hipótese nula. Caso o analista queira obter o p-valor utilizando a função pt base do R, pode-se utilizar o código à seguir.\n\n\n[1] 0.02454049\n\n\nA vantagem de tomar a decisão considerando o p-valor é que para um \\(\\alpha\\) fixo, basta comparar tais probabilidades para tomar a decisão. Se o experimentador deseja, entretanto, tomar a decisão considerando o valor \\(t_0\\), ele deve conhecer o valor crítico \\(t_\\alpha\\) e este muda conforme o número de graus de liberdade associado ao teste. Deve-se atentar para o fato de que se o valor calculado \\(t_0\\) cresce à medida que o tamanho amostral aumenta, o p-valor diminui no mesmo sentido. Deste modo, um pesquisador mal intencionado pode manipular seu estudo aumentado o tamanho amostral para rejeitar a hipótese nula, ou de outra forma, mudar o nível de significância para respaldar as conclusões almejadas.\n\n\n\n\n\np-valor associado ao valor calculado \\(t_0\\)\n\n\n\n\nO teste de hipóteses para média de uma amostra, considerando variância populacional desconhecida e amostras pequenas, pode ser realizado utilizando-se a distribuição \\(t\\) de Student. Além da hipótese alternativa unilateral à esquerda, há outras duas possibilidades a serem elucidadas, além de pressuposições a serem observadas para condução do teste. Antes, porém, é razoável apresentar conceitos relacionados aos erros que podem ser cometidos ao se testar uma hipótese, além de como planejar o teste de forma a minimizar estes erros.\nUm analista que deseja testar uma determinada hipótese não conhece a realidade acerca do parâmetro que deseja testar a partir de uma amostra limitada. Neste sentido, em inferência há dois tipos de erros que podem ser cometidos. O primeiro, chamado de erro do tipo I, consiste na rejeição da hipótese nula \\(H_0\\), quando esta é verdadeira. A probabilidade de ocorrência deste erro consiste no próprio nível de significância \\(\\alpha\\), sendo este erro denotado utilizando probabilidade condicional, conforme segue.\n\\[\\begin{equation}\n  \\alpha = P(Erro \\: tipo \\: I) = P(rejeitar \\: H_0 | H_0 \\: é \\: verdadeira)\n\\end{equation}\\]\nAo se adotar portanto, um determinado nível de significância \\(\\alpha\\), assume-se o risco de cometer o erro do tipo I com probabilidade \\(\\alpha\\).\nO erro do tipo II, denotado \\(\\beta\\) consiste na probabilidade de não rejeitar \\(H_0\\), dado que \\(H_0\\) é falsa. Este erro é denotado conforme segue.\n\\[\\begin{equation}\n  \\beta = P(Erro \\: tipo \\: II) = P(não \\: rejeitar \\: H_0 | H_0 \\: é \\: falsa)\n\\end{equation}\\]\nConsiderando ainda o Exemplo @ref(exm:t1), com teste unilateral à esquerda, isto é, \\(H_1: \\mu &lt; \\mu_0\\), supondo que a hipótese nula seja falsa a média verdadeira pode ser descrita como \\(\\mu = \\mu_0 - \\delta\\), \\(\\delta &gt; 0\\). Logo, somando e subtraindo \\(\\delta\\) na estatística do teste e sabendo que em uma amostra bem coletada \\(\\bar{X} \\rightarrow \\mu_0 - \\delta\\), tem-se:\n\\[\\begin{equation}\nt_0 = \\frac{\\bar{x}-\\mu_0 + \\delta}{s/\\sqrt{n}} -\\frac{\\delta}{s/\\sqrt{n}}\n\\end{equation}\\]\n\\[\\begin{equation}\nt_0 = \\underbrace{\\frac{\\bar{x}-(\\mu_0 - \\delta)}{s/\\sqrt{n}}}_{0, \\: pois \\: \\bar{x} \\rightarrow \\mu_0 - \\delta} -\\frac{\\delta \\sqrt{n}}{s}\n\\end{equation}\\]\nLogo, se \\(H_0\\) é falsa, \\(t_0\\) segue a distribuição \\(t\\) não central, com \\(n-1\\) graus de liberdade e parâmetro de não centralidade \\(-\\delta \\sqrt{n}/s\\), conforme segue.\n\\[\\begin{equation}\nt_0 \\sim t(n-1,-\\frac{\\delta \\sqrt{n}}{s})\n  (\\#eq:t0)\n\\end{equation}\\]\nEste teste unilateral à esquerda com a hipótese nula falsa pode ser ilustrado conforme a Figura @ref(fig:pwrt).\n\n\n\n\n\nErro do tipo II, teste t unilateral à esquerda\n\n\n\n\nTomando a curva sob a hipótese nula \\(H_0\\), na Figura @ref(fig:pwrt), pode-se definir \\(\\beta\\) como a probabilidade de o valor calculado \\(t_0\\) estar à direita do valor \\(t\\) ilustrado, sendo este t relacionado à curva de \\(H_0\\), isto é, \\(-t_{(\\alpha,n-1)}\\), negativo, uma vez que está à esquerda de \\(\\mu_0\\).\n\\[\\begin{equation}\n\\beta = P(t_0 \\geq -t_{(\\alpha,n-1)}|H_0)\n\\end{equation}\\]\nTomando o valor de \\(t_0\\) considerando, a existência de um deslocamento na média à esquerda, conforme a Equação @ref(eq:t0), tem-se:\n\\[\\begin{equation}\n\\beta = P(-\\frac{\\delta \\sqrt{n}}{s} \\geq -t_{(\\alpha,n-1)}|H_0)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\beta = P(-\\frac{\\delta \\sqrt{n}}{s} +t_{(\\alpha,n-1)} \\geq 0 |H_0)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\beta = 1 - P(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)} \\leq 0 |H_0)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\beta = 1 - \\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)})\n  (\\#eq:beta)\n\\end{equation}\\]\nDe modo análogo, pode-se definir \\(\\beta\\) considerando a curva sob a hipótese alternativa \\(H_1\\), na Figura @ref(fig:pwrt), que neste suposto caso corresponde à realidade.\n\\[\\begin{equation}\n\\beta = 1 - \\Phi(t_{(\\beta,n-1)})\n  (\\#eq:beta2)\n\\end{equation}\\]\nTomando as Equações @ref(eq:beta) e @ref(eq:beta2), pode-se derivar o tamanho amostral necessário para garantir um erro do tipo II mínimo, dado o nível de significância \\(\\alpha\\) adotado, o desvio-padrão amostral \\(S\\) e o deslocamento \\(\\delta\\) que deseja-se detectar no teste, conforme Equação @ref(eq:npwr).\n\\[\\begin{equation}\n1 - \\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)}) = 1 - \\Phi(t_{(\\beta,n-1)})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)}) = \\Phi(t_{(\\beta,n-1)})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)} = t_{(\\beta,n-1)}\n\\end{equation}\\]\n\\[\\begin{equation}\nn = \\left[\\frac{(t_{(\\alpha,n-1)}+t_{(\\beta,n-1)})s}{\\delta}\\right]^2\n  (\\#eq:npwr)\n\\end{equation}\\]\nPela Equação na Figura @ref(eq:npwr) pode-se constatar que quanto maior o desvio-padrão amostral, quanto menor o deslocamento da média a ser detectado e quanto menor o nível de significância adotado, maior será o tamanho amostral necessário para manter o erro do tipo II em um valor mínimo almejado. Enquanto o erro do tipo I, \\(\\alpha\\), depende da escolha do analista, o erro do tipo II depende de como o teste foi planejado, isto é, qual o tamanho amostral adotado, considerando determinada variabilidade amostral e determinado deslocamento a ser detectado. O erro do tipo I é mais grave que o erro do tipo II, por isso, geralmente recomenda-se um valor mais baixo deste, por exemplo \\(\\alpha = 0,05\\). Logicamente também é desejável um erro do tipo II baixo, entretanto, para determinados valores de \\(s\\) e \\(\\delta\\), pode ser necessário um tamanho amostral muito alto para minimizar \\(\\beta\\), aumentando os custos experimentais.\nA probabilidade \\(1 -\\beta\\) ilustrada na Figura @ref(fig:pwrt) é chamada de poder do teste. O poder do teste consiste na capacidade do teste estatístico de detectar um deslocamento na média, isto é, de rejeitar a hipótese nula, quando ela é falsa, não cometendo o erro do tipo II. A Figura @ref(fig:erros) apresenta as possibilidades quanto a decisão em testes de hipóteses em relação à realidade, que supõe-se desconhecida por parte do analista. Ao recomendar \\(\\beta =0,2\\), procura-se um poder do teste \\(1- \\beta = 0,8\\).\n\n\n\n\n\nErros em testes de hipóteses\n\n\n\n\nPode-se utilizar o comando power.t.test para calcular o tamanho amostral, dado um poder do teste, \\(1-\\beta\\), desejado conforme segue. Com este comando pode-se também obter o poder do teste, dado um tamanho amostral disponível. Pode-se constatar que, para garantir um poder do teste \\(1-\\beta = 0,8\\) para o Exemplo @ref(exm:t1) detectar uma diferença de \\(2 \\mu m\\), seria necessário coletar uma amostra com 8 observações.\n\n\n\n     One-sample t test power calculation \n\n              n = 7.168914\n          delta = 2\n             sd = 1.904829\n      sig.level = 0.05\n          power = 0.8\n    alternative = one.sided\n\n\nComo no teste realizado no Exemplo @ref(exm:t1) foi utilizado \\(n=12\\), para detectar uma diferença menor, \\(\\delta = 1,22\\), o poder do teste foi menor, \\(1-\\beta = 0,67\\), porém suficiente, uma vez que a hipótese nula foi rejeitada. Para obter este resultado no R, deve-se usar a sintaxe à seguir.\n\n\n\n     One-sample t test power calculation \n\n              n = 12\n          delta = 1.216108\n             sd = 1.904829\n      sig.level = 0.05\n          power = 0.6656294\n    alternative = one.sided\n\n\nÉ interessante avaliar graficamente o poder do teste em função do tamanho amostral, conforme Figura @ref(fig:pwrcurve) e código relacionado à seguir.\n\n\n\n\n\nPoder do teste em função do tamanho amostral\n\n\n\n\nDe forma análoga, pode ser interessante saber o poder do teste, \\(1-\\beta\\), em função do deslocamento na média (efeito), a ser detectado. Pode-se traçar no mesmo gráfico curvas considerando tamanhos amostrais distintos. A Figura @ref(fig:pwrcurve2) ilustra curvas de poder do teste em função do efeito a ser detectado, com código relacionado à seguir.\n\n\n\n\n\nPoder do teste em função do deslocamento na média\n\n\n\n\nTomando as curvas na Figura @ref(fig: pwrcurve2) pode-se constatar que quanto menor o efeito a ser detectado, menor o poder do teste e, consequentemente, maior a probabilidade de erro do tipo II, para um tamanho amostral fixo. De outra forma, fixando o deslocamento a ser detectado, quanto maior o tamanho amostral, maior o poder do teste.\nO Exemplo @ref(exm:t1) apresentou um teste unilateral à esquerda, entretanto há outras possibilidades. A Figura @ref(fig:hip) ilustra, da esquerda para direita os testes unilateral à esquerda, unilateral à direita e bilateral. Neste último o analista deseja apenas contestar se a média \\(\\mu\\) é diferente do valor de referência \\(\\mu_0\\), sendo a região de rejeição de \\(H_0\\) dividida pelas duas caldas, cada uma com área igual a \\(\\alpha/2\\). Para \\(H_1: \\mu &lt; \\mu_0\\), rejeita-se \\(H_0\\) se \\(t_0&lt;-t_{(\\alpha,n-1)}\\). Já para \\(H_1: \\mu &gt; \\mu_0\\), rejeita-se \\(H_0\\) se \\(t_0&gt;t_{(\\alpha,n-1)}\\). Por fim, para \\(H_1: \\mu \\ne \\mu_0\\), rejeita-se \\(H_0\\) se \\(|t_0|&gt;t_{(\\alpha/2,n-1)}\\).\n\n\n\n\n\nTipos de hipóteses\n\n\n\n\nA Figura @ref(fig:pvalue) ilustra a interpretação do p-valor para os três tipos de hipóteses. Para qualquer caso, a interpretação utilizando o p-valor é a mesma. Se \\(p-valor &lt; \\alpha\\), rejeita-se \\(H_0\\) em favor de \\(H_1\\).\n\n\n\n\n\nInterpretação do p-valor\n\n\n\n\nNo caso do teste bilateral, com \\(H_1: \\mu \\ne \\mu_0\\), o intervalo de confiança associado ao teste de hipótese para média com \\(\\gamma\\) de confiança é obtido conforme Equação @ref(eq:icmedia).\n\\[\\begin{equation}\n\\text{IC[$\\gamma=1-\\alpha$] p/ $\\mu$} : [\\bar{X} - t_{(\\alpha/2,n-1)}\\frac{s}{\\sqrt{n}};\\bar{X} + t_{(1-\\alpha/2,n-1)}\\frac{s}{\\sqrt{n}}]\n(\\#eq:icmedia)\n\\end{equation}\\]\nPara os casos onde deseja-se a hipótese para média de forma bilateral, o tamanho amostral para um determinado poder do teste deve ser calculado conforme Equação @ref(eq:npwrbil), a seguir.\n\\[\\begin{equation}\nn = \\lbrack\\frac{(t_{\\alpha/2,n-1}+t_{\\beta,n-1})s}{\\delta}\\rbrack^2\n  (\\#eq:npwrbil)\n\\end{equation}\\]\nPara utilizar o teste \\(t\\) para a média de uma amostra, é desejável que a amostra obtida seja normalmente distribuída. Para testar a normalidade dos dados, pode-se utilizar o teste de Shapiro. A hipótese nula do teste de normalidade \\(H_0\\) é que os dados são normalmente distribuídos. Para o exemplo @ref(exm:t1), pode-se utilizar a linha de código que segue.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  Ront\nW = 0.9518, p-value = 0.6634\n\n\nComo \\(p-valor &gt; \\alpha\\), não se rejeita a hipótese nula \\(H_0\\), concluindo-se que os dados de circularidade seguem a distribuição normal. Pode-se ilustrar o teste de normalidade através do gráfico quantil-quantil. Este gráfico plota as \\(n\\) observações ordenadas em função de \\(n\\) quantis teóricos da distribuição normal-padrão \\(z \\sim N(0,1)\\). Uma boa aproximação dos pontos à reta, demonstra uma boa aproximação dos dados à distribuição normal. A Figura @ref(fig:qqt1) expõe o gráfico quantil-quantil para o exemplo @ref(exm:t1).\n\n\n\n\n\nGráfico para Ront",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#teste-z-para-média-de-uma-amostra",
    "href": "01-Intro.html#teste-z-para-média-de-uma-amostra",
    "title": "1  Introdução",
    "section": "1.7 Teste z para média de uma amostra",
    "text": "1.7 Teste z para média de uma amostra\nNos raros casos onde a variância populacional é conhecida, pode-se utilizar a distribuição normal padrão para testar hipóteses sobre a média de uma população a partir de uma amostra disponível. Recomenda-se também para um tamanho amostral \\(n\\) suficientemente grande, utilizar este procedimento, visto que a distribuição \\(t\\) se aproxima da distribuição \\(z\\) à medida que \\(n\\) cresce. Em geral, uma amostra com tamanho a partir de \\(n = 30\\) é suficiente. Para realizar o teste \\(z\\) para média de uma amostra, deve-se calcular a estatística do teste conforme Equação @ref(eq:ztest).\n\\[\\begin{equation}\n  Z_0 = \\frac{\\bar{X}-\\mu_0}{\\sigma/\\sqrt{n}}\n  (\\#eq:ztest)\n\\end{equation}\\]\nPara planejar este teste considerou-se a necessidade de detectar uma diferença de 0,5 HRC na dureza, supondo um desvio-padrão de 1 HRC, baseado em dados históricos. O analista requer um poder mínimo \\(1-\\beta= 0,8\\). Pode-se utilizar o comando power.z.test do pacote asbio. O argumento test = \"two.tail\", é usado para o teste bilateral, \\(H_1: \\mu \\ne \\mu_0\\). Pelos resultados da análise, é necessária uma amostra com \\(n = 32\\) observações para garantir um poder do teste de 0,8. O analista considerou o tamanho amostral \\(n = 30\\) suficiente.\n\n\n$sigma\n[1] 1\n\n$n\n[1] 31.39552\n\n$power\n[1] 0.8\n\n$alpha\n[1] 0.05\n\n$effect\n[1] 0.5\n\n$test\n[1] \"two.tail\"\n\n\nAs trinta observações de dureza são expostas a seguir. Um boxplot é exposto na Figura @ref(fig:bpdureza) para ilustrar a variabilidade dos dados.\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  56.00   57.25   58.00   57.73   58.25   58.75 \n\n\n\n\n\n\n\nBoxplot para dureza\n\n\n\n\nO teste de normalidade é realizado à seguir, indicando não haver indícios para rejeição da hipótese nula de normalidade da variável dureza, \\(p-valor &gt; \\alpha\\). O gráfico q-q da Figura @ref(fig:qqdureza) confirma a normalidade da dureza.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  dureza\nW = 0.9363, p-value = 0.07236\n\n\n\n\n\n\n\nBoxplot para dureza\n\n\n\n\nAs hipóteses para o exemplo @ref(exm:z1) são expostas à seguir, onde \\(\\mu_0 = 55\\). O teste realizado é, portanto, bilateral. Para testar tais hipóteses, uma vez que tem-se um tamanho amostral considerável, pode-se utilizar do teste \\(Z\\) para média amostral. A função ZTest() do pacote DescTools é utilizada.\n\\[\\begin{equation}\n  H_0: \\mu = \\mu_0\n\\end{equation}\\]\n\\[\\begin{equation}\n  H_1: \\mu \\ne \\mu_0\n\\end{equation}\\]\n\n\n\n    One Sample z-test\n\ndata:  dureza\nz = 19.761, Std. Dev. Population = 0.7553, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 55\n95 percent confidence interval:\n 57.45473 57.99527\nsample estimates:\nmean of x \n   57.725 \n\n\nPelos resultados obtidos, rejeita-se a hipótese nula de que a dureza média é igual a 55 HRC. Apesar de a hipótese alternativa ser \\(H_1: \\mu \\ne 55\\), como \\(z_0 = 19.761\\) e pelos limites de confiança serem ambos maiores que 55, pode-se constatar especificamente que a média é maior que 55 HRC.\nConsiderando o tamanho amostral, desvio-padrão amostral e efeito detectado, o poder do teste pode ser calculado com a sintaxe à seguir. Portanto, o teste apresentou poder unitário, com probabilidade nula de erro do tipo II. Uma alta razão entre o efeito (deslocamento na média) a ser detectado e o desvio-padrão da variável estudada aumenta o poder do teste.\n\n\n$sigma\n[1] 0.7552974\n\n$n\n[1] 30\n\n$power\n[1] 1\n\n$alpha\n[1] 0.05\n\n$effect\n[1] 2.725\n\n$test\n[1] \"two.tail\"\n\n\nA curva para o poder do teste Exemplo @ref(exm:z1) é exposta na Figura @ref(fig:poderz1). Pode-se observar que para um efeito superior a 0,65 é possível realizar o teste com \\(1-\\beta = 1\\).\n\n\n\n\n\nCurva de poder do teste para média da dureza",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#teste-t-para-médias-de-duas-amostras-independentes",
    "href": "01-Intro.html#teste-t-para-médias-de-duas-amostras-independentes",
    "title": "1  Introdução",
    "section": "1.8 Teste t para médias de duas amostras independentes",
    "text": "1.8 Teste t para médias de duas amostras independentes\nEm diversas situações é de interesse do pesquisador realizar inferência sobre a média de duas amostras. Este tipo de teste pode ser realizado para comparar a diferença entre médias de dois tratamentos em uma resposta de interesse. O teste baseado na distribuição \\(t\\) pode ser utilizado para amostras pequenas quando as variâncias populacionais são desconhecidas. Há testes distintos para a diferença entre médias para amostras com variâncias iguais e para amostras com variâncias diferentes.\nAntes de entender os testes para média de duas amostras, é importante entender o que significa a independência e como testá-la estatisticamente. Duas amostras são ditas independentes quando são originadas de populações distintas. Uma forma de quantificar a dependência entre duas amostras é através da covariância e da correlação. Por estas medidas pode-se quantificar se a dependência entre duas variáveis de interesse é forte ou fraca. A covariância entre duas variáveis \\(xX\\) e \\(y\\), \\(Cov(x,y)=\\sigma_{xy}\\) pode ser definida conforme Equação @ref(eq:cov1), enquanto a correlação é definida conforme a Equação @ref(eq:cor1). Logo, pode-se constatar que a correlação é a covariância padronizada. Enquanto a covariância tem domínio em toda escala de números reais, \\(\\sigma_{xy} \\in (-\\infty,+\\infty)\\), a correlação tem domínio entre -1 e 1, \\(\\rho_{xy} \\in \\{-1,+1\\}\\), sendo mais fácil entender via correlação se o relacionamento linear é forte ou fraco.\n\\[\\begin{equation}\n  \\sigma_{xy} =  E((x_i-\\mu_x)(y_i-\\mu_y)) = E(xy) - \\mu_x\\mu_y\n  (\\#eq:cov1)\n\\end{equation}\\]\n\\[\\begin{equation}\n  \\rho_{xy} =  \\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}\n  (\\#eq:cor1)\n\\end{equation}\\]\nAs Figuras @ref(fig:corr), @ref(fig:corr2) e @ref(fig:corr3) são diagramas de dispersão que ilustram padrões de dependência entre variáveis. Na Figura @ref(fig:corr) as variáveis \\(x\\) e \\(y\\) apresentam correlação positiva, com \\(\\rho \\rightarrow 1\\). Já na Figura @ref(fig:corr2) as variáveis \\(x\\) e \\(y\\) apresentam correlação negativa, com \\(\\rho \\rightarrow -1\\). Por fim, na Figura @ref(fig:corr3) as variáveis \\(x\\) e \\(y\\) apresentam ausência de correlação positiva, com \\(\\rho \\rightarrow 0\\).\n\n\n\n\n\nDiagrama de dispersão entre variáveis X e Y com correlação positiva\n\n\n\n\n\n\n\n\n\nDiagrama de dispersão entre variáveis X e Y com correlação negativa\n\n\n\n\n\n\n\n\n\nDiagrama de dispersão entre variáveis X e Y não correlcionadas\n\n\n\n\nA correlação amostral \\(r_{xy}=\\hat{\\rho}\\) entre duas variáveis \\(x\\) e \\(y\\) pode ser calculada conforme Equação @ref(eq:cor), ou pela Equação @ref(eq:cor2), onde \\(S_{XY} = \\hat{\\sigma}_{xy}\\) é a covariância amostral entre as variáveis \\(x\\) e \\(y\\) enquanto \\(S_{x}\\) e \\(S_{y}\\) são os desvios-padrões amostrais destas variáveis. A covariância amostral entre \\(x\\) e \\(y\\) pode ser estimada conforme Equação @ref(eq:cov).\n\\[\\begin{equation}\n  r_{xy} = \\frac{\\sum_{i}(x_i-\\bar{x})\\sum_{i}(y_i-\\bar{y})}{\\sqrt{\\sum_{i}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i}(y_i-\\bar{y})^2}}\n  (\\#eq:cor)\n\\end{equation}\\]\n\\[\\begin{equation}\n  r_{xy} = \\frac{S_{xy}}{S_xS_y}\n  (\\#eq:cor2)\n\\end{equation}\\]\n\\[\\begin{equation}\n  S_{xy} = \\frac{\\sum_{i}(x_i-\\bar{x})\\sum_{i}(y_i-\\bar{y})}{n-1}\n  (\\#eq:cov)\n\\end{equation}\\]\nO teste de correlação de Pearson, pode ser utilizado para avaliar a significância estatística da correlação entre duas amostras. A hipótese nula do teste garante que a correlação é igual a zero, isto é, \\(H_0: \\rho=0\\). Para realizar o teste de correlação de Pearson entre a amostra de controle e a amostra tratada do Exemplo @ref(exm:t2), denotadas \\(x\\) e \\(y\\), respectivamente, pode-se utilizar a sintaxe à seguir. O teste é baseado na distribuição \\(t\\) e fornece como resultado o valor da estatística \\(t_0\\) a qual pode ser comparada com o valor crítico \\(t_{(\\alpha/2,n-2)}\\), onde \\(n = n_x + n_y\\). Se \\(t_0 &gt; t_{(\\alpha/2,n-1)}\\), rejeita-se \\(H_0\\). Considernado \\(\\alpha = 0,05\\), para \\(n = 58\\), \\(t_{(0,025,58)}=2.001717\\), qt(0.95+.05/2, 58). Logo, como \\(t_0 = 0,73203 &lt; 2.001717 = t_{(\\alpha/2,n-1)}\\), não há indícios para rejeição de \\(H_0\\), ou seja, a correlação entre as amostras é nula. A independência entre tais amostras é trivial, por terem sido retiradas de populações distintas. Entretanto é importante confirmar a independência para posteriormente realizar o teste de hipóteses para diferença entre médias das amostras adequado.\n\n\n[1] 0.1370349\n\n\n\n    Pearson's product-moment correlation\n\ndata:  X and Y\nt = 0.73203, df = 28, p-value = 0.4702\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2348276  0.4739076\nsample estimates:\n      cor \n0.1370349 \n\n\nAntes de realizar o teste \\(t\\) para averiguar a diferença entre médias entre as variáveis \\(x\\) e \\(y\\) do Exemplo @ref(exm:t2), é importante testar a homocedasticidade, isto é, a homogeneidade de variâncias entre as duas amostras. Primeiramente, é necessário organizar os dados de forma tabular utilizando o comando data.frame().\nPosteriormente, pode-se plotar alguns gráficos para visualizar a variabilidade dos dados. O pacote ggpubr() é uma boa opção. A Figura @ref(fig:bpcarbon) ilustra boxplots, enquanto a Figura @ref(fig:denscarbon) ilustra gráficos de densidade da distribuição amostral para a resistência à tração em função das amostras de controle e tratada. Em ambos os casos, pode-se constatar que a variabilidade dos dados parece similar e que a resistência média da amostra tratada é superior. Pelos gráficos de densidade, pode-se verificar que as distribuições amostrais aparentam ter normalidade. Todas estas evidências gráficas devem ser estatísticamente confirmados.\n\n\n\n\n\nBoxplots para resistância à tração das amostras de controle e tratada\n\n\n\n\n\n\n\n\n\nHistogramas para resistância à tração das amostras de controle e tratada\n\n\n\n\nO teste de homocedasticidade de Bartlett para o Exemplo @ref(exm:t2) é apresentado à seguir. A hipótese nula do teste postula a igualdade de variâncias entre as amostras, isto é, \\(H_0: \\sigma_1^2 = \\sigma_2^2\\). Pelos resultados, como \\(p-value = 0,07128 &gt; 0,05 = \\alpha\\), não se rejeita \\(H_0\\), podendo-se confirmar a homogeneidade entre as variâncias amostrais.\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  resistencia by grupo\nBartlett's K-squared = 3.2534, df = 1, p-value = 0.07128\n\n\nO teste de normalidade das duas amostras também deve ser realizado. Pode-se constatar, pelos resultados abaixo, \\(p-value&lt;\\alpha\\), que não há indícios para rejeição da hipótese nula de normalidade das amostras. A Figura @ref(fig:qq2t) ilustra os gráficos q-q para as amostras.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resistencia[grupo == \"Controle\"]\nW = 0.95678, p-value = 0.2557\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resistencia[grupo == \"Tratada\"]\nW = 0.96465, p-value = 0.4049\n\n\n\n\n\n\n\nGráficos q-q para resistência à tração das amostras controle e tratada\n\n\n\n\nA hipótese nula do teste \\(t\\) para média de duas amostras é exposta à seguir.\n\\[\\begin{equation}\nH_0: \\mu_1 = \\mu_2\n\\end{equation}\\]\nJá a hipótese alternativa pode ser bilateral, \\(\\ne\\), ou unilateral à esquerda ou a direita, conforme segue.\n\\[\\begin{equation}\nH_0: \\mu_1 \\ne \\mu_2\n\\end{equation}\\]\n\\[\\begin{equation}\nH_0: \\mu_1 &lt; \\mu_2\n\\end{equation}\\]\n\\[\\begin{equation}\nH_0: \\mu_1 &gt; \\mu_2\n\\end{equation}\\]\nA estatística do teste \\(t\\) para duas amostras com variâncias amostrais iguais é calculada conforme Equação @ref(eq:t2s), onde o desvio-padrão combinado \\(S\\) é obtido conforme a Equação @ref(eq:pooledS).\n\\[\\begin{equation}\nt_0 = \\frac{\\bar{x_1}-\\bar{x_2}}{s\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}\n  (\\#eq:t2s)\n\\end{equation}\\]\n\\[\\begin{equation}\ns = \\sqrt{\\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\n(\\#eq:pooledS)\n\\end{equation}\\]\nO cálculo da estatística \\(t_0\\) é trivial e pode ser facilmente realizado utilizando o R como uma calculadora. Entretanto, é mais interessante utilizar a função t.test(), por apresentar um resultado mais estruturado, cofnorme segue. Comparando o valor da estatística calculada com o valor crítico, \\(|t_0| = 10.393 &gt; 2.0003 = t_{\\alpha/2}\\), ou pelo p-valor, \\(p-valor = 7,3 \\times10^{-15} &lt; 0,05 = \\alpha\\), constata-se que há indícios para rejeição da hipótese nula, garantindo que as resistências das amostras são diferentes.\n\n\n\n    Two Sample t-test\n\ndata:  resistencia by grupo\nt = -10.393, df = 58, p-value = 7.3e-15\nalternative hypothesis: true difference in means between group Controle and group Tratada is not equal to 0\n95 percent confidence interval:\n -35.73313 -24.19135\nsample estimates:\nmean in group Controle  mean in group Tratada \n              116.4774               146.4396 \n\n\n[1] 2.000298\n\n\nO poder do teste pode ser obtido utilizando a função power.t.test, conforme segue. Pode-se observar que o poder do teste foi unitário.\n\n\n\n     Two-sample t test power calculation \n\n              n = 30\n          delta = 29.96224\n             sd = 11.1657\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nA Figura @ref(fig:powert2) apresenta a curva de poder do teste em função do deslocamento a ser detectado para o Exemplo @ref(exm:t2). A alta diferença entre médias, relativamente aos desvios-padrões amostrais, garantiu \\(1-\\beta \\backsimeq 1\\) no Exemplo @ref(exm:t2).\n\n\n\n\n\nCurva de poder do teste, n1 = n2 = 30, sd = 11.17, teste bilateral",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#teste-t-para-médias-de-duas-amostras-dependentes",
    "href": "01-Intro.html#teste-t-para-médias-de-duas-amostras-dependentes",
    "title": "1  Introdução",
    "section": "1.9 Teste t para médias de duas amostras dependentes",
    "text": "1.9 Teste t para médias de duas amostras dependentes\nO teste \\(t\\) para amostras pareadas (ou emparelhadas) é aplicado em estudos onde cada objeto é medido em duas diferentes ocasiões, antes e depois de um determinado tratamento, por exemplo. Este tipo de teste pode também ser aplicado em pares de indivíduos similares, sendo um tratamento aplicado a um elemento de cada par, enquanto o outro elemento dos pares é submetido a outro tratamento, ou não é submetido a tratamento algum (controle). Devido à possível dependência entre as amostras tomadas aos pares, utilizar os procedimentos anteriormente propostos para testar a diferença entre médias de duas amostras violaria a hipótese de independência estatística entre as amostras. Por conseguinte, o teste \\(t\\) pareado é utilizado para testar a diferença entre médias de amostras dependentes.\nPara realizar o teste \\(t\\) para amostras pareadas, é importante confirmar a dependência entre as amostras. Para isto pode-se realizar o teste de correlação de Pearson, conforme segue. A Figura @ref(fig:scattervegetal) apresenta um diagrama de dispersão, confirmando a correlação positiva entre as amostras de humidade do carvão vegetal pulverizado e granulado.\n\n\n\n    Pearson's product-moment correlation\n\ndata:  Pulverizada and Granulada\nt = 11.704, df = 28, p-value = 2.677e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8201861 0.9572343\nsample estimates:\n      cor \n0.9112053 \n\n\n\n\n\n\n\nDiagrama de dispersão para humidade das amostras de carvão vegetal pulverizada e granulada\n\n\n\n\nO teste \\(t\\) pareado é realizado considerando a diferença em relação às amostras pareadas. A hipótese nula consiste em testar se a diferença é igual a um valor de interesse, isto é, \\(H_0: \\mu_d = \\mu_{d0}\\). Já a hipótese alternativa pode ser bilateral ou unilateral à direita ou à esquerda. A estatística do teste \\(t\\) pareado é exposta na Equação @ref(eq:tpaired), onde \\(n\\) é o número de pares. Logo, o teste consiste no mesmo teste \\(t\\) para uma amostra, de forma que a hipótese de normalidade para as diferenças deve ser confirmada.\n\\[\\begin{equation}\nt_0 = \\frac{\\bar{x}_d-\\mu_d}{s_d/\\sqrt{n}}\n  (\\#eq:tpaired)\n\\end{equation}\\]\nO código à seguir calcula as diferenças entre os pares das duas amostras e, posteriormente a normalidade das diferenças.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  d\nW = 0.9786, p-value = 0.7871\n\n\n\n\n\nGráfico quantil-quantil para as diferenças\n\n\n\n\nFinalmente o teste \\(t\\) pareado é realizado através do código à seguir. Pode-se constatar que, como \\(p-valor = 0,8562 &gt; 0,05 = \\alpha\\), não se rejeita a hipótese nula de igualdade entre os métodos de preparação da amostra para medição de umidade do carvão vegetal. Como conclusão prática, não é necessário triturar o carvão para medir sua umidade.\n\n\n\n    Paired t-test\n\ndata:  Pulverizada and Granulada\nt = 0.18284, df = 29, p-value = 0.8562\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3055859  0.3655859\nsample estimates:\nmean difference \n           0.03 \n\n\nO cálculo do poder do teste pode ser realizado com a sintaxe que segue. Como a diferença é muito pequena considerando o desvio-padrão e o tamanho amostral, o poder do teste foi baixíssimo.\n\n\n\n     Paired t test power calculation \n\n              n = 30\n          delta = 0.03\n             sd = 0.8987156\n      sig.level = 0.05\n          power = 0.03728679\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#análise-de-variância",
    "href": "01-Intro.html#análise-de-variância",
    "title": "1  Introdução",
    "section": "1.10 Análise de variância",
    "text": "1.10 Análise de variância\nQuando deseja-se testar a diferença entre médias para três ou mais amostras ou tratamentos, deve-se utilizar a análise de variância (ANOVA). A presença de três ou mais tratamentos é comum em diversos estudos experimentais, tornando a análise de variância umas das técnicas mais importantes em inferência estatística.\nExistem diversos tipos de ANOVA, considerando o número de fatores em avaliação, efeitos fixos ou aleatórios, etc. Neste primeiro momento será abordada a ANOVA para um fator (ou one-way) com modelo de efeitos fixos.\nSeja o conjunto geral de dados resumido na Tabela @ref(tab:anova-data). Neste conjunto tem-se \\(a\\) tratamentos de interesse e \\(n\\) observações ou replicações experimentais em cada tratamento. De forma geral, cada observação pode ser denotada como \\(y_{ij}\\), com \\(i = 1, ..., a\\) e \\(j = 1, ..., n\\).\n\n(#tab:anova-data) Dados de um experimento com \\(a\\) tratamentos e \\(n\\) observações em cada tratamento\n\n\n\n\n\n\n\n\nTratamentos\nObservações\nSomas\nMédias\n\n\n\n\n1\n\\(y_{11}\\), \\(y_{12}\\), …, \\(y_{1n}\\)\n\\(y_{1.} = \\sum_{j=1}^{n}{y_{1j}}\\)\n\\(\\bar{y}_{1.} = y_{1.}/n\\)\n\n\n2\n\\(y_{21}\\), \\(y_{22}\\), …, \\(y_{2n}\\)\n\\(y_{2.} = \\sum_{j=1}^{n}{y_{2j}}\\)\n\\(\\bar{y}_{2.} = y_{2.}/n\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\na\n\\(y_{a1}\\), \\(y_{a2}\\), …, \\(y_{an}\\)\n\\(y_{a.} = \\sum_{j=1}^{n}{y_{aj}}\\)\n\\(\\bar{y}_{a.} = y_{a.}/n\\)\n\n\n\nAinda na Tabela @ref(tab:anova-data) é importante obter os totais e as médias de cada tratamento, \\(y_{i.}\\) e \\(\\bar{y}_{i.}\\), \\(i = 1, ..., a\\), para facilitar os cálculos necessários à análise.\nCada observação experimental \\(y_{ij}\\) pode ser discriminada conforme o modelo apresentado na Equação @ref(eq:anova-model), o modelo de efeitos fixos da ANOVA. Neste modelo a média geral ou grande média denotada \\(\\mu\\) e calculada conforme a Equação @ref(eq:medg). O efeito de cada tratamento \\(\\alpha_{i}\\) consiste na diferença entre médias do tratamento e a média geral, \\(i = 1, ..., a\\), segundo Equação @ref(eq:eftrat). Por fim, o termo de erro \\(\\varepsilon_{ij}\\) consiste na diferença entre cada observação e a média dentro do seu tratamento, \\(i = 1, ..., a\\), \\(j = 1, ..., n\\), conforme Equação @ref(eq:erroanova). Sobre o termo de erro residem as hipóteses de que este seja normalmente e independentemente distribuído com média nula e variância \\(\\sigma^2_\\varepsilon\\), ou seja, \\(\\varepsilon_{ij} \\sim N(0,\\sigma^2_\\varepsilon)\\).\nA média logicamente pode variar de tratamento para tratamento, sendo esta hipotética variação testada estatísticamente. Já a variância dentro dos tratamentos é assumida constante.\n\\[\\begin{equation}\ny_{ij} = \\mu + \\alpha_{i} + \\varepsilon_{ij}\n(\\#eq:anova-model)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\mu = \\bar{y}_{..} = \\frac{\n\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}{y_{ij}}}{an}\n(\\#eq:medg)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\alpha_{i} = \\bar{y}_{i.} - \\bar{y}_{..}\n(\\#eq:eftrat)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\varepsilon_{ij} = y_{ij} - \\bar{y}_{i.}\n(\\#eq:erroanova)\n\\end{equation}\\]\nEste modelo é chamado de modelo de efeitos fixos, com cada efeito dentro dos tratamentos fixo porém desconhecido a ser estimado. Este tipo de modelo é o mais comum na análise de variância, sendo utilizado quando deseja-se conhecer apenas o efeito dos tratamentos considerados. No caso onde se selecionam de forma aleatória \\(a\\) tratamentos de uma ampla população, desejando-se conhecer o efeito para toda população de origem, deve-se utilizar o modelo de efeitos aleatórios.\nAs hipóteses testadas na análise de variância são relacionadas aos efeito dos tratamentos e de forma análoga à média destes. A hipótese nula consiste na nulidade dos efeitos, enquanto a hipótese alternativa garante que ao menos um dos efeitos é não nulo, ou de outra forma ao menos uma média dos tratamentos é distinta dos demais. As hipóteses são formuladas à seguir.\n\\[\\begin{equation}\nH_0: \\alpha_1= \\alpha_2 = ... = \\alpha_a = 0\n\\end{equation}\\]\n\\[\\begin{equation}\nH_0: \\alpha_i \\ne 0, \\text{para ao menos um $i$}\n\\end{equation}\\]\nA análise de variância é um teste para diferença entre médias baseado no particionamento da soma dos quadrados total, na soma dos quadrados entre tratamentos e na soma dos quadrados dentro dos tratamentos, conforme Equação @ref(eq:vartotal). A variância total das observações experimentais da Tabela @ref(tab:anova-data) é expressa conforme Equação @ref(eq:vartotal). O numerador do cálculo, \\(SS_T\\), é a soma dos quadrados total, enquanto o denominador, \\(DF_T\\), consiste nos graus de liberdade total.\n\\[\\begin{equation}\ns_T^2 = s_{Entre}^2 + s_{Dentro}^2\n(\\#eq:sigmatotal)\n\\end{equation}\\]\n\\[\\begin{equation}\ns_T^2 = \\frac{SS_T}{DF_T} =  \\frac{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}{an-1}\n(\\#eq:vartotal)\n\\end{equation}\\]\nTomando a soma dos quadrados total, \\(SS_T\\), é possível particioná-la na soma dos quadrados entre os tratamentos, \\(SS_{Trat}\\), e na soma dos quadrados dentro dos tratamentos, \\(SS_{Erro}\\), conforme a Equação @ref(eq:ident-anova). Pode-se observar que a soma dos quadrados dos tratamentos e a soma dos quadrados dos erros são as somas dos quadrados dos efeitos expostos nas Equações @ref(eq:eftrat) e @ref(eq:erroanova), respectivamente. Na Tabela @ref(tab:anova-data) estas quantidades estão relacionados à variabilidade entre as linhas e dentro das linhas.\n\\[\\begin{equation}\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}_{SS_T}=\n\\underbrace{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}_{SS_{Trat}}+\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}_{SS_{Erro}}\n(\\#eq:ident-anova)\n\\end{equation}\\]\nOs graus de liberdade dos tratamentos estão relacionados ao número de tratamentos em estudo, \\(DF_{Trat} = a-1\\). Tomando a razão entre a soma dos quadrados e os graus de liberdade dos tratamentos, conforme Equação @ref(eq:mstrat) tem-se a média dos quadrados dos tratamentos, \\(MS_{Trat}\\). Esta medida é a estimativa da variância entre os tratamentos, \\(\\sigma_{Trat}^2=MS_{Trat}\\). Quanto maior esta medida, maior a diferença entre médias dos tratamentos. Entretanto, esta diferença deve ser avaliada relativamente à variância dentro dos tratamentos, isto é, em relação à variância experimental.\n\\[\\begin{equation}\nMS_{Trat} =  \\frac{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}{a-1}\n(\\#eq:mstrat)\n\\end{equation}\\]\nOs graus de liberdade dos erros devem ser avaliados com mais cuidado. Para o i-ésimo tratamento a i-ésima variância é calculada conforme a Equação @ref(eq:i-var). Combinando todas as variâncias dos \\(a\\) tratamentos, tem-se o resultado da Equação @ref(eq:mse). A média dos quadrados dos erros, \\(MS_E\\), é a estimativa da variância experimental na ANOVA, \\(\\sigma_\\varepsilon^2=MS_E\\). As médias dos quadrados são distribuídas pela distribuição \\(\\chi^2\\), por constarem de somas de desvios quadráticos em relação à média, isto é, soma dos quadrados de quantidades distribuídas pela normal-padrão \\(Z\\).\n\\[\\begin{equation}\ns_i^2 =  \\frac{\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{n-1}\n(\\#eq:i-var)\n\\end{equation}\\]\n\\[\\begin{equation}\nMS_E =  \\frac{\\displaystyle\\sum_{i=1}^{a}\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{a(n-1)}\n(\\#eq:mse)\n\\end{equation}\\]\nA estatística do teste ANOVA, \\(F_0\\), é calculada conforme Equação @ref(eq:f-anova), como a razão entre as médias dos quadrados dos tratamentos e dos erros. Quanto maior esta razão, maior a diferença entre os efeitos, relativamente ao erro experimental. Como esta quantidade consiste na razão entre médias dos quadrados, isto é, entre estimativas de variâncias ela é distribuída pela distribuição \\(F\\), \\(F_0 \\sim F_{(a-1,a(n-1))}\\). A hipótese \\(H_0\\) de nulidade e igualdade dos efeitos é rejeitada se \\(F_0 &gt; F_{(\\alpha,a-1,a(n-1))}\\). A Tabela @ref(tab:res-anova) resume os cálculos da ANOVA. Geralmente os resultados obtidos via ANOVA são apresentados neste formato.\n\\[\\begin{equation}\nF_0 =  \\frac{MS_{Trat}}{MS_{Erro}}\n(\\#eq:f-anova)\n\\end{equation}\\]\n\n(#tab:res-anova) Tabela resumo ANOVA\n\n\n\n\n\n\n\n\n\nFonte\nDF\nSS\nMS\n\\(F_0\\)\n\n\n\n\nTratamentos\n\\(a-1\\)\n\\(SS_{Trat}\\)\n\\(SS_{Trat}/(a-1)\\)\n\\(F_0 = MS_{Trat}/MS_{Erro}\\)\n\n\nErro\n\\(a(n-1)\\)\n\\(SS_{Erro}\\)\n\\(SS_{Erro}/[a(n-1)]\\)\n-\n\n\nTotal\n\\(an - 1\\)\n\\(SS_{T}\\)\n-\n-\n\n\n\nExistem algumas medidas de ajuste usadas para averiguar a efetividade do modelo obtido via ANOVA. O coeficiente de determinação simples \\(R^2\\) é calculado conforme a Equação @ref(eq:R2), como a razão entre a soma dos quadrados dos tratamentos e a soma dos quadrados total. Esta medida deve ser usada com cautela, por não levar em consideração o número de graus de liberdade do modelo. neste sentido, o coeficiente de determinação ajustado \\(R_{aj}^2\\) é obtido conforme a Equação @ref(eq:R2aj).\n\\[\\begin{equation}\nR^2 = \\frac{SS_{Trat}}{SS_T}\n(\\#eq:R2)\n\\end{equation}\\]\n\\[\\begin{equation}\nR_{aj}^2 = 1 - \\frac{MS_{Trat}}{SS_T/(an-1)}\n(\\#eq:R2aj)\n\\end{equation}\\]\nA ANOVA para três ou mais tratamentos é comumente chamada de ANOVA one-way. Para conduzir este tipo de análise, deve-se utilizar o chamado planejamento totalmente aleatorizado ou delineamento inteiramente casualizado. Neste planejamento todas as \\(N = an\\) observações experimentais são conduzidas em ordem e alocação de materiais totalmente aleatória. A aleatorização auxilia na garantia das hipóteses de normalidade e independencia dos resíduos. Ao aleatorizar os experimentos garante-se que fontes externas incontroláveis de variação, chamadas de ruídos, tenham interferência mínima ou ao menos tenham efeito diluido de maneira aleatória nos resultados experimentais. As replicações viabilizam a estimativa do erro experimental. Sem a replicação não é possível testar a significância dos efeitos avaliados, visto que estes são sempre avaliados relativamente ao erro experimental.\n\n\n\nPlanejamento totalmente aleatorizado para microdureza HV em [GPa] em função do método de resfriamento de cerâmicas de zirconia\n\n\nordem\ncooling\nhardness\n\n\n\n\n10\nslow\n5.34\n\n\n3\nslow\n5.43\n\n\n12\nslow\n5.42\n\n\n7\nslow\n5.40\n\n\n2\nslow\n5.38\n\n\n15\nnormal\n5.20\n\n\n6\nnormal\n5.22\n\n\n8\nnormal\n5.15\n\n\n14\nnormal\n5.25\n\n\n9\nnormal\n5.24\n\n\n13\nfast\n5.20\n\n\n11\nfast\n5.15\n\n\n5\nfast\n5.19\n\n\n4\nfast\n5.17\n\n\n1\nfast\n5.18\n\n\n\n\n\nPara obter este planejamento pode-se utilizar o código à seguir no R.\nPara realizar a análise é utilizado o comando aov(). Pelos resultados, como \\(F_0 = 62,84 &gt; 3,89 = F_{(0,05,2,12)}\\), ou como \\(p-value = 4,38 \\times 10^{-7} &lt; 0,05 = \\alpha\\), rejeita-se \\(H_0\\). Deste modo, há ao menos um dos tratamentos com efeito diferente, de forma que há influência do tipo de resfriamento na microdureza. A estatística de ajuste \\(R_{aj}^2=0,898\\), garante que a maior parte da variabilidade dos dados é explicada pelo efeito dos tratamentos e não pelo erro experimental.\n\n\n            Df  Sum Sq Mean Sq F value   Pr(&gt;F)    \ncooling      2 0.13489 0.06745   62.84 4.38e-07 ***\nResiduals   12 0.01288 0.00107                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[1] 3.885294\n\n\n\nCall:\nlm(formula = hardness ~ cooling, data = plan)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-0.062 -0.013  0.006  0.024  0.038 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    5.17800    0.01465 353.411  &lt; 2e-16 ***\ncoolingnormal  0.03400    0.02072   1.641    0.127    \ncoolingslow    0.21600    0.02072  10.425 2.28e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03276 on 12 degrees of freedom\nMultiple R-squared:  0.9128,    Adjusted R-squared:  0.8983 \nF-statistic: 62.84 on 2 and 12 DF,  p-value: 4.384e-07\n\n\nA Figura @ref(fig:Fcritico) ilustra a região crítica do teste, com regão de rejeição de \\(H_0\\) destacada em vermelho.\n\n\n\n\n\nRegião crítica ANOVA, \\(\\alpha = 0,05, DF1 = 2, DF2 = 12\\)\n\n\n\n\nPara testar as pressuposições de normalidade e homocedasticidade pode-se utilizar os blocos de código à seguir. Para ambos os testes obteve-se \\(p-value &gt; \\alpha\\), não havendo indícios para rejeição da hipótese nula \\(H_0\\), implicando na normalidade dos resíduos e na igualdade de variâncias dos tratamentos.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuos\nW = 0.92867, p-value = 0.2607\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  hardness by cooling\nBartlett's K-squared = 1.831, df = 2, p-value = 0.4003\n\n\nA Figura @ref(fig:resi-anova), com sintaxe à seguir, ilustra alguns gráficos dos resíduos que auxiliam na visualização das pressuposições da ANOVA. O gráfico superior esquerdo plota os resíduos \\(\\varepsilon_{ij}\\) em relação aos valores previstos ou ajustados (fitted), \\(\\hat{y}_i=\\mu+\\alpha_i=\\bar{y}_{i.}\\). Um padrão de aleatoriedade, sem crescimento ou decrescimento de \\(\\varepsilon_{ij}\\) em função de \\(\\hat{y}_i\\) deve ser observado. Para o caso estudado não há indícios de dependência entre resíduos e valores ajustados. O gráfico superior direito é o gráfico quantil-quantil que plota os resíduos ordenados em função dos quantis teóricos da normal padrão. Quanto mais próximo da reta, melhor os resíduos se ajustam à distribuição normal. O gráfico inferior esquerdo plota a raiz quadrada dos resíduos padronizados em função dos valores ajustados. Este é um auxílio para ver, além da independência entre resíduos e ajustados, a homocedasticidade. No caso estudado, já confirmado estatísticamente, visualiza-se a homogeneidade da raiz dos resíduos padronizados em relação às médias dos tratamentos. O último gráfico, plotado no canto inferior direito, plota os resíduos em função dos níveis (tratamentos) experimentais. Deve-se averiguar por este gráfico a homogeneidade e independência dos resíduos em função dos níveis, além da possível presença de outliers, isto é, de valores discrepantes. Em caso de um ajuste baixo, isto é, um \\(R_{aj}^2\\) insuficiente, alguns experimentos com resíduos extremos destacados neste gráfico poderiam ser repetidos. No caso estudado não seria necessário.\n\n\n\n\n\nGráficos de resíduos para ANOVA, dureza ~ resfriamento\n\n\n\n\nA Figura @ref(fig:bp-anova) apresenta um box-plot da dureza em função do tipo de resfriamento, com código relacionado à seguir. O resfriamento lento garante maior microdureza da cerâmica.\n\n\n\n\n\nBoxplot para dureza ~ resfriamento\n\n\n\n\nA Figura @ref(fig:efeitos-anova) apresenta a média com intervalos de confiança. Ao rejeitar a hipótese nula através da ANOVA, o analista apenas constata que há ao menos um efeito distinto dos demais, em conformidade com a hipótese alternativa \\(H_1\\). Entretanto, pode ser desejado investigar as diferenças específicas.\n\n\n\n\n\nAjustados ~ resfriamento\n\n\n\n\nPosteriormente à ANOVA pode-se utilizar de testes de comparação de médias, ou testes de comparações múltiplas para testar as diferenças específicas. Nestes tipo de teste todas as comparações aos pares são realizadas entre as médias dos \\(a\\) tratamentos testados na ANOVA. A hipótese nula de cada comparação é sempre \\(H_0:\\mu_i = \\mu_j\\). Um teste bastante utilizado é o teste de Tukey HSD (honestly significant difference), por apresentar um bom controle da probabilidade de erro do tipo I. Entretanto, este teste é conhecido por apresentar alta probabilidade de erro do tipo II (baixo poder do teste). Outras opções disponíveis para comparações múltiplas como os testes de Duncan, teste t, teste de Newman-Keuls, teste t-bayesiano, entre outros.\nO código à seguir pode ser utilizado para realizar o teste de Tukey. Pode-se confirmar que o resfriamento lento é diferente do resfriamento normal e do resfriamento rápido, enquanto estes dois não são estatísticamente diferentes.\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = hardness ~ cooling, data = plan)\n\n$cooling\n             diff        lwr       upr     p adj\nnormal-fast 0.034 -0.0212791 0.0892791 0.2670508\nslow-fast   0.216  0.1607209 0.2712791 0.0000006\nslow-normal 0.182  0.1267209 0.2372791 0.0000040\n\n\nÉ possível obter o poder do teste para ANOVA com o comando power.anova.test, conforme sintaxe à seguir. Pode-se observar que o poder foi unitário, o que já era esperado, uma vez que rejeitou-se a hipótese nula pela ANOVA.\n\n\n\n     Balanced one-way analysis of variance power calculation \n\n         groups = 3\n              n = 5\n    between.var = 0.06745\n     within.var = 0.00107\n      sig.level = 0.05\n          power = 1\n\nNOTE: n is number in each group\n\n\nCaso o experimentador deseje encontrar o número de réplicas adequado para um determinado poder do teste antes de planejar seu experimento, deve-se ter uma estimativa de \\(SS_{Trat}\\) e \\(SS_{Erro}\\), o que geralmente é difícil de conseguir, especialmente quando não se tem conhecimento da variabilidade acerca dos tratamentos em estudo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-Intro.html#bibliografia",
    "href": "01-Intro.html#bibliografia",
    "title": "1  Introdução",
    "section": "Bibliografia",
    "text": "Bibliografia\nANDERSON, Kenneth E. Computation of by Analysis of Variance. The American Statistician, v. 15, n. 2, p. 18-19, 1961.\nALMEIDA JUNIOR, Antonio Alves de et al. Effect of the cooling rate on the properties of veneer porcelain for zirconia dental prosthesis. Materials Research, v. 20, n. 5, p. 1418-1424, 2017.\nBOX, George EP et al. Some theorems on quadratic forms applied in the study of analysis of variance problems, I. Effect of inequality of variance in the one-way classification. The annals of mathematical statistics, v. 25, n. 2, p. 290-302, 1954.\nBUSSAB, Wilton de Oliveira; MORETTIN, Pedro Alberto. Estatística básica. 2009.\nCASELLA, George; BERGER, Roger L. Statistical inference. Pacific Grove, CA: Duxbury, 2002.\nCOCHRAN, William G. The distribution of quadratic forms in a normal system, with applications to the analysis of covariance. In: Mathematical Proceedings of the Cambridge Philosophical Society. Cambridge University Press, 1934. p. 178-191.\nCRUMP, S. Lee. The estimation of variance components in analysis of variance. Biometrics Bulletin, v. 2, n. 1, p. 7-11, 1946.\nDANIELS, Henry E. The estimation of components of variance. Supplement to the Journal of the Royal Statistical Society, v. 6, n. 2, p. 186-197, 1939.\nEISENHART, Churchill. The assumptions underlying the analysis of variance. Biometrics, v. 3, n. 1, p. 1-21, 1947.\nFELLER, Willliam. An introduction to probability theory and its applications. John Wiley & Sons, 2008.\nFISHER, Ronald Aylmer et al. Statistical methods for research workers. Statistical methods for research workers, 5th Ed, 1934.\nGRINSTEAD, Charles Miller; SNELL, James Laurie. Introduction to probability. American Mathematical Soc., 2012.\nGRONOW, D. G. C. Test for the significance of the difference between means in two normal populations having unequal variances. Biometrika, v. 38, n. 1/2, p. 252-256, 1951.\nGURLAND, John; MCCULLOUGH, Roger S. Testing equality of means after a preliminary test of equality of variances. Biometrika, v. 49, n. 3-4, p. 403-417, 1962.\nHALD, Anders. A history of parametric statistical inference from Bernoulli to Fisher, 1713-1935. Springer Science & Business Media, 2008.\nJOHNSON, N. L.; WELCH, B. L. Applications of the non-central t-distribution. Biometrika, v. 31, n. 3/4, p. 362-389, 1940.\nKEMPTHORNE, Oscar. The randomization theory of experimental inference. Journal of the American Statistical Association, v. 50, n. 271, p. 946-967, 1955.\nKENDALL, Maurice George et al. The advanced theory of statistics. The advanced theory of statistics, 2nd Ed, 1946.\nKOTZ, Samuel; JOHNSON, Norman L. (Ed.). Breakthroughs in statistics: methodology and distribution. Springer Science & Business Media, 2012.\nLEHMANN, Erich L.; ROMANO, Joseph P. Testing statistical hypotheses. Springer Science & Business Media, 2006.\nMCCULLOUGH, Roger S.; GURLAND, John; ROSENBERG, Lloyd. Small sample behaviour of certain tests of the hypothesis of equal means under variance heterogeneity. Biometrika, v. 47, n. 3-4, p. 345-353, 1960.\nMEHTA, J. S.; GURLAND, John. Testing equality of means in the presence of correlation. Biometrika, v. 56, n. 1, p. 119-126, 1969.\nMEYER, Paul L. Introductory probability and statistical applications. Oxford and IBH Publishing, 1965.\nMONTGOMERY, Douglas C. Design and analysis of experiments. John wiley & sons, 2013.\nMONTGOMERY, Douglas C.; RUNGER, George C. Applied statistics and probability for engineers. John Wiley & Sons, 2011.\nMORAIS, Manuel Cabral. Lecture Notes—Probability Theory.\nMORRIS, Eric A.; SMART, Michael J. Expert versus lay perception of the risks of motor vehicle-generated air pollution. Transportation Research Part D: Transport and Environment, v. 17, n. 1, p. 78-85, 2012.\nNEYMAN, Jerzy; PEARSON, Egon S. The testing of statistical hypotheses in relation to probabilities a priori. In: Mathematical Proceedings of the Cambridge Philosophical Society. Cambridge University Press, 1933. p. 492-510.\nNEYMAN, Jerzy; TOKARSKA, B. Errors of the second kind in testing “Student’s” hypothesis. Journal of the American Statistical Association, v. 31, n. 194, p. 318-326, 1936.\nOWEN, D. B. The power of Student’s t-test. Journal of the American Statistical Association, v. 60, n. 309, p. 320-333, 1965.\nPEARSON, Karl. Historical note on the origin of the normal curve of errors. Biometrika, p. 402-404, 1924.\nPLACKETT, R. L. Models in the analysis of variance. Journal of the Royal Statistical Society: Series B (Methodological), v. 22, n. 2, p. 195-209, 1960.\nROSS, Sheldon M. Introduction to probability models. Academic press, 2010.\nSCARIANO, Stephen M.; DAVENPORT, James M. The effects of violations of independence assumptions in the one-way ANOVA. The American Statistician, v. 41, n. 2, p. 123-129, 1987.\nSEARLE, Shayle R. Topics in variance component estimation. Biometrics, v. 27, n. 1, p. 1-76, 1971.\nSHAO, Yiqin et al. Interfacial strength and debonding mechanism between aerogel-spun carbon nanotube yarn and polyphenylene sulfide. Composites Part A: Applied Science and Manufacturing, v. 88, p. 98-105, 2016.\nSCHEFFE, Henry et al. Alternative models for the analysis of variance. The Annals of Mathematical Statistics, v. 27, n. 2, p. 251-271, 1956.\nSNEDECOR, George W.; COCHRAN, Witiiam G. Statistical methods, 8thEdn. Ames: Iowa State Univ. Press Iowa, 1967.\nSTEYER, Rolf; NAGEL, Werner. Probability and conditional expectation: Fundamentals for the empirical sciences. John Wiley & Sons, 2017.\nSTUDENT. The probable error of a mean. Biometrika, p. 1-25, 1908.\nTUKEY, John W. Comparing individual means in the analysis of variance. Biometrics, p. 99-114, 1949.\nWASSERMAN, Larry. All of statistics: a concise course in statistical inference. Springer Science & Business Media, 2013.\nWELCH, Bernard L. The significance of the difference between two means when the population variances are unequal. Biometrika, v. 29, n. 3/4, p. 350-362, 1938.\nWHITTLE, Peter. Probability via expectation. Springer Science & Business Media, 1992.\nWILSON, Edwin B.; WORCESTER, Jane. Note on the t-Test. Proceedings of the National Academy of Sciences of the United States of America, v. 28, n. 7, p. 297, 1942.\nYATES, Frank. The analysis of multiple classifications with unequal numbers in the different classes. Journal of the American Statistical Association, v. 29, n. 185, p. 51-66, 1934.\nZUEV, Konstantin. Statistical Inference. 2018.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "02-Testes.html",
    "href": "02-Testes.html",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "",
    "text": "2.1 Introdução\nNeste capítulo serão abordados alguns testes de hipóteses para média de uma e duas amostras. Alguns destes testes são fundamentais em planejamentos de experimentos e inferência de modelos muito populares. Existem diversas situações que testes simples como os explicitados aqui são suficientes para comprovar o efeito ou testar diferenças entre médias considerando uma ou duas amostras. Ademais, existem planejamentos que consideram múltiplós fatores ou variáveis em estudo, mas usam do teste t para inferência de coeficientes de modelos de regressão. Portanto, é essencial compreender os conceitos deste capítulo.\nNeste capítulo são utilizados os pacotes asbio, DescTools, ggpplot2 para gráficos, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "02-Testes.html#teste-t-para-média-de-uma-amostra",
    "href": "02-Testes.html#teste-t-para-média-de-uma-amostra",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "2.2 Teste t para média de uma amostra",
    "text": "2.2 Teste t para média de uma amostra\nSeja uma amostra aleatória de \\(n\\) observações, \\(x_1, x_2, ..., x_n\\), retirada de uma va que segue a distribuição normal, um problema comum de decisão é o teste de hipóteses. Neste tipo de teste pode-se inferir, por exemplo, se o parâmetro em estudo é igual a um determinado valor de interesse ou não. No caso da média de uma determinada amostra de interesse, o teste \\(t\\) pode ser utilizado.\n\nExemplo 2.1 Considere uma amostra de 12 observações da circularidade total \\(Ron_t\\) de furos obtidos por fresamento helicoidal no aço inox superduplex UNS S32760. A Figura 2.1 apresenta um boxplot de Ront. Um engenheiro ou pesquisador pode desejar inferir se a média de Ront é menor que 10 \\(\\mu m\\) por considerar este limite superior como aceitável para uma determinada aplicação.\n\nA seguir apresenta-se a amostra com 12 observações da circularidade total.\n\n# dados\nRont &lt;- c(6.7249, 7.8566, 7.5466, 12.0763, 7.6331, 6.1340, \n          9.9053, 10.4416, 11.3306, 7.0836, 9.5623, 9.1118)\n\n# quartis (quantis que dividem a amostra em quatro partes)\n# summary(Ront)\n\n\n\n\n\n\n\n\n\nFigura 2.1: Box-plot de Ront \\([\\mu m]\\)\n\n\n\n\n\nPara responder à pergunta do experimentador, deve-se formular as hipóteses a serem testadas, sendo \\(H_0\\) a hipótese nula e \\(H_1\\) a hipótese alternativa, conforme segue.\n\\[\n\\begin{align}\n  H_0:& \\mu = 10 \\\\\n  H_1:& \\mu &lt; 10\n\\end{align}\n\\]\nO valor de interesse testado na hipótese é denotado \\(\\mu_0\\). Uma vez que o analista já coletou a amostra para testar sua hipótese, pode-se seguir com o cláculo da estatística do teste. Como ele coletou uma amostra de tamanho pequeno, além de a variância populacional ser desconhecida, deve-se utilizar o teste \\(t\\) para uma amostra, baseado na distribuição \\(t\\) de Student. A estatística do teste para testar uma hipótese sobre a média de uma amostra neste caso é apresentada na Equação 2.1. Por este cálculo padroniza-se a distribuição amostral obtida em relação ao valor hipotético, havendo mais evidência para rejeição da hipótese nula, quanto maior for o desvio negativo de \\(t_0\\) em relação a zero. Deve-se recordar que, pelo TCL, o desvio-padrão da média é \\(s_{\\bar{x}} = s/\\sqrt{n}\\).\n\\[\n  t_0 = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\n\\tag{2.1}\\]\nPara o exemplo esta estatística pode ser facilmente calculada no R como segue.\n\n# média de Ront\nx_bar &lt;- mean(Ront)\n\n# desvio-padrão de Ront\ns &lt;- sd(Ront)\n\n# tamanho amostral \nn &lt;- length(Ront)\n\n# valor da hipótese\nmu_0 &lt;- 10\n\n# estatística do teste t\nt_0 &lt;- (x_bar - mu_0)/(s/sqrt(n))\nt_0\n\n[1] -2.211601\n\n\nPara julgar se a hipótese nula deve ser rejeitada em favor da alternativa ou não, deve-se definir uma região crítica ou região de rejeição de \\(H_0\\). Para tal, deve-se definir um nível de significância \\(\\alpha\\) de interesse. O nível de significância consiste em uma probabilidade de erro na rejeição da hipótese nula que se assume ao testar a hipótese. Quanto menor, menor a probabilidade de rejeitar a hipótese nula erroneamente caso esta seja verdadeira. Entretanto, quanto menor o nível de significância \\(\\alpha\\), mais difícil é a rejeição da hipótese nula. É comum adotar-se em pesquisas \\(\\alpha = 0,05\\), mas alguns pesquisadores mais criteriosos costumam adotar \\(\\alpha = 0,01\\), ou valores inferiores. O nível de confiança \\(\\gamma\\) do teste é o complementar do nível de significância, \\(\\gamma = 1 - \\alpha\\). A Figura 2.2 ilustra a distribuição \\(t\\) com 11 graus de liberdade e região crítica em vermelho para o teste em questão, considerando \\(\\alpha = 0,05\\).\n\n\n\n\n\n\n\n\nFigura 2.2: Região crítica para o teste t, com \\(\\alpha = 0,05\\), \\(n-1=11\\) graus de liberdade\n\n\n\n\n\nConsiderando a distribição \\(t\\) com 11 graus de liberdade, pode-se obter o valor \\(t_\\alpha\\), o qual garante uma probabilidade igual a 0,05 à sua esquerda, conforme segue. Este valor \\(t_\\alpha\\) é comumente conhecido como valor crítico.\n\n# valor t para uma probabilidade acumulada \n# igual à 0,05, com 11 graus de liberdade \nqt(0.05, 11)\n\n[1] -1.795885\n\n\nPara decidir deve-se comparar o valor da estatística do teste com o valor crítico. Neste caso, como a hipótese alternativa é \\(H_0: \\mu &lt; \\mu_0\\), se \\(t_0 &lt; t_\\alpha\\), rejeita-se \\(H_0\\) em favor de \\(H_1\\). Logo, neste caso como \\(t_0 = -2,21 &lt; -1,796 = t_\\alpha\\), rejeita-se a hipótese nula, com \\(\\alpha = 0,05\\) de significância, podendo-se concluir que a média da circularidade total, \\(\\overline{Ron_t}\\), é menor que \\(10 \\mu m\\).\nA função t.test() do R pode ser utilizada para realizar o teste \\(t\\) para uma amostra. Para o caso do Exemplo 2.1, pode-se utilizar sintaxe que segue.\n\nt.test(x = Ront,\n       mu=10,\n       alternative = \"less\")\n\n\n    One Sample t-test\n\ndata:  Ront\nt = -2.2116, df = 11, p-value = 0.02454\nalternative hypothesis: true mean is less than 10\n95 percent confidence interval:\n     -Inf 9.771407\nsample estimates:\nmean of x \n 8.783892 \n\n\nA saída fornece o valor de \\(t_0\\) calculado, o número de graus de liberdade do teste, e o p-valor (p-value), que consiste na probabilidade associada ao valor calculado. A saída também especifíca a hipótese testada, além de fornecer um intervalo de confiança associado ao teste realizado e a estimativa pontual do parâmetro testado, isto é, a média. O intervalo de confiança consiste em limites de confiança para média, neste caso apenas o superior, uma vez que foi realizado um teste unilateral à esquerda. A média está abaixo deste limite com \\(\\gamma = 1 - \\alpha = 0,95\\) de confiança.\nNo teste unilateral à esquerda realizado o limite superior de confiança é calculado conforme Equação Equação 2.2. Para o Exemplo 2.1 este limite é de \\(9,77\\), indicando que a média é menor que este valor com \\(\\gamma = 0,95\\) de confiança.\n\\[\n\\begin{align}\n  \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}} &lt;& t_{(\\alpha,n-1)} \\\\\n  \\mu_0 &lt;& \\bar{x} - t_{(\\alpha,n-1)}\\frac{s}{\\sqrt{n}}\n\\end{align}\n\\tag{2.2}\\]\nSendo o p-valor a probabilidade associada ao valor calculado, ele também pode ser utilizado na tomada de decisão em inferência. A Figura 2.3 ilustra o p-valor, sendo neste caso a área sob a curva à esquerda do valor calculado \\(t_0\\), isto é \\(p-valor = P(t &lt; t_0) = \\Phi(t_0)\\). Pode-se constatar que, para hipótese unilateral à esquerda, \\(H_1: \\mu &lt; \\mu_0\\), se \\(t_0 &lt; t_\\alpha\\) implica em \\(p-valor &lt; \\alpha\\). Quanto menor o p-valor, maior a evidência na rejeição da hipótese nula. Caso o analista queira obter o p-valor utilizando a função pt base do R, pode-se utilizar o código à seguir.\n\n# p-valor\npvalor &lt;- pt(t_0, df = n-1)\npvalor\n\n[1] 0.02454049\n\n\nA vantagem de tomar a decisão considerando o p-valor é que para um \\(\\alpha\\) fixo, basta comparar as probabilidades. Se o experimentador deseja, entretanto, tomar a decisão considerando o valor \\(t_0\\), ele deve conhecer o valor crítico \\(t_\\alpha\\) e este muda conforme o número de graus de liberdade associado ao teste. Deve-se atentar para o fato de que se o valor calculado \\(t_0\\) cresce à medida que o tamanho amostral aumenta, o p-valor diminui no mesmo sentido. Deste modo, um pesquisador mal intencionado pode manipular seu estudo aumentado o tamanho amostral para rejeitar a hipótese nula, ou de outra forma, mudar o nível de significância para respaldar as conclusões almejadas. É importante dizer que o p-valor não pode ser usado como critério de sucesso ou fracasso, um p-valor mesmo que abaixo do nível de significância, mas próximo deste pode representar um risco considerávelmente alto de erro na rejeição da hipótese nula.\n\n\n\n\n\n\n\n\nFigura 2.3: p-valor associado ao valor calculado \\(t_0\\)\n\n\n\n\n\nO teste de hipóteses para média de uma amostra, considerando variância populacional desconhecida e amostras pequenas, pode ser realizado utilizando-se a distribuição \\(t\\) de Student. Além da hipótese alternativa unilateral à esquerda, há outras duas possibilidades a serem elucidadas. Há também pressuposições a serem observadas para condução do teste. Antes, porém, é razoável apresentar conceitos relacionados aos erros que podem ser cometidos ao se testar uma hipótese, visando o planejamento do teste de forma a minimizar estes erros.\nUm analista que deseja testar uma determinada hipótese não conhece a realidade acerca do parâmetro que deseja testar a partir de uma amostra limitada. Neste sentido, em inferência há dois tipos de erros que podem ser cometidos. O primeiro, chamado de erro do tipo I, consiste na rejeição da hipótese nula \\(H_0\\), quando esta é verdadeira. A probabilidade de ocorrência deste erro consiste no próprio nível de significância \\(\\alpha\\), sendo este erro denotado utilizando probabilidade condicional, conforme segue.\n\\[\n  \\alpha = P(Erro \\: tipo \\: I) = P(rejeitar \\: H_0 | H_0 \\: é \\: verdadeira)\n\\]\nAo se adotar portanto, um determinado nível de significância \\(\\alpha\\), assume-se o risco de cometer o erro do tipo I com probabilidade \\(\\alpha\\).\nO erro do tipo II, denotado \\(\\beta\\) consiste na probabilidade de não rejeitar \\(H_0\\), dado que \\(H_0\\) é falsa. Este erro é denotado conforme segue.\n\\[\n  \\beta = P(Erro \\: tipo \\: II) = P(não \\: rejeitar \\: H_0 | H_0 \\: é \\: falsa)\n\\]\nConsiderando ainda o Exemplo 2.1, com teste unilateral à esquerda, isto é, \\(H_1: \\mu &lt; \\mu_0\\), supondo que a hipótese nula seja falsa, a média verdadeira pode ser descrita como \\(\\mu = \\mu_0 - \\delta\\), \\(\\delta &gt; 0\\). Logo, somando e subtraindo \\(\\delta\\) na estatística do teste e, sabendo que em uma amostra bem coletada resultará em \\(\\bar{x} \\rightarrow \\mu_0 - \\delta\\), tem-se:\n\\[\n\\begin{align}\nt_0 =& \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}} +\\frac{\\delta- \\delta}{s/\\sqrt{n}} \\\\\nt_0 =& \\underbrace{\\frac{\\bar{x}-(\\mu_0 - \\delta)}{s/\\sqrt{n}}}_{0, \\: pois \\: \\bar{x} \\rightarrow \\mu_0 - \\delta} -\\frac{\\delta \\sqrt{n}}{s}\n\\end{align}\n\\]\nLogo, se \\(H_0\\) é falsa, \\(t_0\\) segue a distribuição \\(t\\) não centrada, com \\(n-1\\) graus de liberdade e parâmetro de não centralidade \\(-\\delta \\sqrt{n}/s\\), conforme segue.\n\\[\nt_0 \\sim t(n-1,-\\frac{\\delta \\sqrt{n}}{s})\n\\tag{2.3}\\]\nEste teste unilateral à esquerda com a hipótese nula falsa pode ser ilustrado conforme a Figura 2.4.\n\n\n\n\n\n\n\n\nFigura 2.4: Erro do tipo II, teste t unilateral à esquerda\n\n\n\n\n\nTomando a curva sob a hipótese nula \\(H_0\\), na Figura 2.4, pode-se definir \\(\\beta\\) como a probabilidade de o valor calculado \\(t_0\\) estar à direita do valor \\(t\\) ilustrado, sendo este t relacionado à curva de \\(H_0\\), isto é, \\(-t_{(\\alpha,n-1)}\\), negativo, uma vez que está à esquerda de \\(\\mu_0\\).\n\\[\n\\beta = P(t_0 \\geq -t_{(\\alpha,n-1)}|H_0)\n\\]\nTomando o valor de \\(t_0\\) considerando, a existência de um deslocamento na média à esquerda, conforme a Equação 2.3, tem-se:\n\\[\n\\begin{align}\n\\beta =& P(-\\frac{\\delta \\sqrt{n}}{s} \\geq -t_{(\\alpha,n-1)}|H_0) \\\\\n\\beta =& P(-\\frac{\\delta \\sqrt{n}}{s} +t_{(\\alpha,n-1)} \\geq 0 |H_0) \\\\\n\\beta =& 1 - P(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)} \\leq 0 |H_0) \\\\\n\\beta =& 1 - \\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)})\n\\end{align}\n\\tag{2.4}\\]\nDe modo análogo, pode-se definir \\(\\beta\\) considerando a curva sob a hipótese alternativa \\(H_1\\), na Figura 2.4, que neste suposto caso corresponde à realidade.\n\\[\n\\beta = 1 - \\Phi(t_{(\\beta,n-1)})\n\\tag{2.5}\\]\nTomando as Equações Equação 2.4 e Equação 2.5, pode-se derivar o tamanho amostral necessário para garantir um erro do tipo II mínimo, dado o nível de significância \\(\\alpha\\) adotado, o desvio-padrão amostral \\(S\\) e o deslocamento \\(\\delta\\) que deseja-se detectar no teste, conforme Equação Equação 2.6.\n\\[\n\\begin{align}\n1 - \\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)}) =& 1 - \\Phi(t_{(\\beta,n-1)}) \\\\\n\\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)}) =& \\Phi(t_{(\\beta,n-1)}) \\\\\n\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)} =& t_{(\\beta,n-1)} \\\\\nn =& \\left[\\frac{(t_{(\\alpha,n-1)}+t_{(\\beta,n-1)})s }{\\delta}\\right]^2\n\\end{align}\n\\tag{2.6}\\]\nEnquanto o erro do tipo I, \\(\\alpha\\), depende da escolha do analista, o erro do tipo II depende de como o teste foi planejado, isto é, qual o tamanho amostral adotado, considerando determinada variabilidade amostral e determinado deslocamento a ser detectado. O erro do tipo I é mais grave que o erro do tipo II, por isso, geralmente recomenda-se um valor mais baixo deste, por exemplo \\(\\alpha = 0,05\\). Logicamente também é desejável um erro do tipo II baixo, entretanto, para determinados valores de \\(s\\) e \\(\\delta\\), pode ser necessário um tamanho amostral muito alto para minimizar \\(\\beta\\), aumentando os custos experimentais. Na prática recomenda-se tentar garantir \\(\\beta&lt;0,2\\).\nA probabilidade \\(1 -\\beta\\) ilustrada na Figura 2.4 é chamada de poder do teste. O poder do teste consiste na capacidade do teste estatístico de detectar um deslocamento na média, isto é, de rejeitar a hipótese nula, quando ela é falsa, não cometendo o erro do tipo II. A Figura 2.5 apresenta as possibilidades quanto a decisão em testes de hipóteses em relação à realidade, que supõe-se desconhecida por parte do analista. Ao recomendar \\(\\beta =0,2\\), procura-se um poder do teste \\(1- \\beta = 0,8\\).\n\n\n\n\n\n\n\n\nFigura 2.5: Erros em testes de hipóteses\n\n\n\n\n\nPode-se utilizar o comando power.t.test para calcular o tamanho amostral, dado um poder do teste, \\(1-\\beta\\), desejado conforme segue. Com este comando pode-se também obter o poder do teste, dado um tamanho amostral disponível. Pode-se constatar que, para garantir um poder do teste \\(1-\\beta = 0,8\\) para o Exemplo 2.1 detectar uma diferença de \\(2 \\mu m\\), seria necessário coletar uma amostra com 8 observações.\n\n# Para obter o tamanho amostral \n# para um determinado poder(power)\n# s já calculado anteriormente\npower.t.test(delta = 2, \n             sd = s, \n             sig.level = 0.05, \n             power = 0.8, \n             type = \"one.sample\", \n             alternative = \"one.sided\")\n\n\n     One-sample t test power calculation \n\n              n = 7.168914\n          delta = 2\n             sd = 1.904829\n      sig.level = 0.05\n          power = 0.8\n    alternative = one.sided\n\n\nComo no teste realizado no Exemplo 2.1 foi utilizado \\(n=12\\), para detectar uma diferença menor, \\(\\delta = 1,22\\), o poder do teste foi menor, \\(1-\\beta = 0,67\\), porém suficiente, uma vez que a hipótese nula foi rejeitada. Para obter este resultado no R, deve-se usar a sintaxe à seguir.\n\n# Para saber o poder o teste, considerando \n# o tamanho amostral realizado\npower.t.test(n = n, \n             delta = d, \n             sd = s, \n             sig.level = 0.05, \n             type = \"one.sample\", \n             alternative = \"one.sided\")\n\n\n     One-sample t test power calculation \n\n              n = 12\n          delta = 1.216108\n             sd = 1.904829\n      sig.level = 0.05\n          power = 0.6656294\n    alternative = one.sided\n\n\nÉ interessante avaliar graficamente o poder do teste em função do tamanho amostral, conforme Figura 2.6 e código relacionado à seguir.\n\n\n\n\n\n\n\n\nFigura 2.6: Poder do teste em função do tamanho amostral\n\n\n\n\n\nDe forma análoga, pode ser interessante saber o poder do teste, \\(1-\\beta\\), em função do deslocamento na média (efeito), a ser detectado. Pode-se traçar no mesmo gráfico curvas considerando tamanhos amostrais distintos. A Figura 2.7 ilustra curvas de poder do teste em função do efeito a ser detectado, com código relacionado à seguir.\n\n\n\n\n\n\n\n\nFigura 2.7: Poder do teste em função do deslocamento na média\n\n\n\n\n\nTomando as curvas na Figura 2.7 pode-se constatar que quanto menor o efeito a ser detectado, menor o poder do teste e, consequentemente, maior a probabilidade de erro do tipo II, para um tamanho amostral fixo. De outra forma, fixando o deslocamento a ser detectado, quanto maior o tamanho amostral, maior o poder do teste.\nO Exemplo 2.1 apresentou um teste unilateral à esquerda, entretanto há outras possibilidades. A Figura 2.8 ilustra, da esquerda para direita os testes unilateral à esquerda, unilateral à direita e bilateral. Neste último o analista deseja apenas contestar se a média \\(\\mu\\) é diferente do valor de referência \\(\\mu_0\\), sendo a região de rejeição de \\(H_0\\) dividida pelas duas caldas, cada uma com área igual a \\(\\alpha/2\\). Para \\(H_1: \\mu &lt; \\mu_0\\), rejeita-se \\(H_0\\) se \\(t_0&lt;-t_{(\\alpha,n-1)}\\). Já para \\(H_1: \\mu &gt; \\mu_0\\), rejeita-se \\(H_0\\) se \\(t_0&gt;t_{(\\alpha,n-1)}\\). Por fim, para \\(H_1: \\mu \\ne \\mu_0\\), rejeita-se \\(H_0\\) se \\(|t_0|&gt;t_{(\\alpha/2,n-1)}\\).\n\n\n\n\n\n\n\n\nFigura 2.8: Tipos de regiões de rejeição em testes de hipóteses para média de uma amostra\n\n\n\n\n\nA Figura 2.9 ilustra a interpretação do p-valor para os três tipos de hipóteses. Para qualquer caso, a interpretação utilizando o p-valor é a mesma. Se \\(p-valor &lt; \\alpha\\), rejeita-se \\(H_0\\) em favor de \\(H_1\\).\n\n\n\n\n\n\n\n\nFigura 2.9: p-valor para diferentes casos do teste t para média de uma amostra\n\n\n\n\n\nNo caso do teste bilateral, com \\(H_1: \\mu \\ne \\mu_0\\), o intervalo de confiança associado ao teste de hipótese para média com \\(\\gamma\\) de confiança é obtido conforme Equação 2.7.\n\\[\n\\text{IC[} \\gamma=1-\\alpha \\text{]  p/ } \\mu : [\\bar{X} - t_{(\\alpha/2,n-1)}\\frac{s}{\\sqrt{n}};\\bar{X} + t_{(1-\\alpha/2,n-1)}\\frac{s}{\\sqrt{n}}]\n\\tag{2.7}\\]\nPara os casos onde deseja-se testar a hipótese para média de forma bilateral, o tamanho amostral para um determinado poder do teste deve ser calculado conforme Equação 2.8, a seguir.\n\\[\nn = \\biggl[\\frac{(t_{\\alpha/2,n-1}+t_{\\beta,n-1})s}{\\delta}\\biggr]^2\n\\tag{2.8}\\]\nPara utilizar o teste \\(t\\) para a média de uma amostra, é desejável que a amostra obtida seja normalmente distribuída. Para testar a normalidade dos dados, pode-se utilizar o teste de Shapiro. A hipótese nula do teste de normalidade \\(H_0\\) é que os dados são normalmente distribuídos. Para o Exemplo 2.1, pode-se utilizar a linha de código que segue.\n\n# Teste de normalidade de Ront\nshapiro.test(Ront)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Ront\nW = 0.9518, p-value = 0.6634\n\n\nComo \\(p-valor &gt; \\alpha\\), não se rejeita a hipótese nula \\(H_0\\), concluindo-se que a amostra de circularidade segue a distribuição normal. Pode-se avaliar a normalidade através do gráfico quantil-quantil. Este gráfico plota as \\(n\\) observações padronizadas e ordenadas em função de \\(n\\) quantis teóricos da distribuição normal-padrão \\(z \\sim N(0,1)\\). Uma boa aproximação dos pontos à reta, demonstra uma boa aproximação dos dados à distribuição normal. A Figura 2.10 expõe o gráfico quantil-quantil para o Exemplo 2.1.\n\n\n\n\n\n\n\n\nFigura 2.10: Gráfico qq para Ront",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "02-Testes.html#teste-z-para-média-de-uma-amostra",
    "href": "02-Testes.html#teste-z-para-média-de-uma-amostra",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "2.3 Teste z para média de uma amostra",
    "text": "2.3 Teste z para média de uma amostra\nNos raros casos onde a variância populacional é conhecida, pode-se utilizar a distribuição normal padrão para testar hipóteses sobre a média de uma população a partir de uma amostra disponível. Recomenda-se também para um tamanho amostral \\(n\\) suficientemente grande, utilizar este procedimento, visto que a distribuição \\(t\\) se aproxima da distribuição \\(z\\) à medida que \\(n\\) cresce. Em geral, uma amostra com tamanho a partir de \\(n = 30\\) é suficiente. Para realizar o teste \\(z\\) para média de uma amostra, deve-se calcular a estatística do teste conforme Equação 2.9.\n\\[\n  Z_0 = \\frac{\\bar{X}-\\mu_0}{\\sigma/\\sqrt{n}}\n\\tag{2.9}\\]\n\nExemplo 2.2 Considere uma amostra com \\(n = 30\\) observações da dureza de corpos de prova de aço ABNT H13 temperado. Deseja-se testar se a média é diferente de 55 HRC.\n\nPara planejar este teste considerou-se a necessidade de detectar uma diferença de 0,5 HRC na dureza, supondo um desvio-padrão de 1 HRC, baseado em dados históricos. O analista requer um poder mínimo \\(1-\\beta= 0,8\\). Pode-se utilizar o comando power.z.test do pacote asbio. O argumento test = \"two.tail\", é usado para o teste bilateral, \\(H_1: \\mu \\ne \\mu_0\\). Pelos resultados da análise, é necessária uma amostra com \\(n = 32\\) observações para garantir um poder do teste de 0,8. O analista considerou o tamanho amostral \\(n = 30\\) suficiente.\n\n# carregando pacote\nlibrary(asbio)\n\n# definindo tamanho amostral\npower.z.test(sigma = 1, \n             power = 0.8, \n             alpha = 0.05, \n             effect = 0.5, \n             test = \"two.tail\")\n\n$sigma\n[1] 1\n\n$n\n[1] 31.39552\n\n$power\n[1] 0.8\n\n$alpha\n[1] 0.05\n\n$effect\n[1] 0.5\n\n$test\n[1] \"two.tail\"\n\n\nAs trinta observações de dureza são expostas a seguir. Um boxplot é exposto na Figura 2.11 para ilustrar a variabilidade dos dados.\n\n# dados\ndureza &lt;- c(57.00, 58.00, 58.00, 57.50, 58.25, 58.00, 58.50, \n            57.25, 58.75, 57.00, 56.50, 57.25, 57.25, 58.00, \n            58.50, 58.00, 57.50, 58.25, 56.25, 57.25, 58.50, \n            57.00, 58.50, 58.75, 57.50, 56.00, 58.25, 58.25, \n            58.75, 57.25)\n# summary(dureza)\n\n\n\n\n\n\n\n\n\nFigura 2.11: Boxplot para dureza\n\n\n\n\n\nO teste de normalidade é realizado à seguir, indicando não haver indícios para rejeição da hipótese nula de normalidade da variável dureza, \\(p-valor &gt; \\alpha\\). O gráfico q-q da Figura 2.12 confirma a normalidade da dureza.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  dureza\nW = 0.9363, p-value = 0.07236\n\n\n\n\n\n\n\n\n\n\nFigura 2.12: Gráfico qq para dureza\n\n\n\n\n\nAs hipóteses para o Exemplo 2.2 são expostas à seguir, onde \\(\\mu_0 = 55\\). O teste realizado é, portanto, bilateral. Para testar tais hipóteses, uma vez que tem-se um tamanho amostral considerável, pode-se utilizar do teste \\(Z\\) para média amostral. A função ZTest() do pacote DescTools é utilizada.\n\\[\n\\begin{align}\n  H_0:& \\mu = \\mu_0 \\\\\n  H_1:& \\mu \\ne \\mu_0\n\\end{align}\n\\]\n\n# Carregando pacote\nlibrary(DescTools)\n\n# Teste z para dureza\nZTest(dureza, \n      mu = 55,\n      alternative = \"two.sided\", \n      sd_pop = sd(dureza))\n\n\n    One Sample z-test\n\ndata:  dureza\nz = 19.761, Std. Dev. Population = 0.7553, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 55\n95 percent confidence interval:\n 57.45473 57.99527\nsample estimates:\nmean of x \n   57.725 \n\n\nPelos resultados obtidos, rejeita-se a hipótese nula de que a dureza média é igual a 55 HRC. Apesar de a hipótese alternativa ser \\(H_1: \\mu \\ne 55\\), como \\(z_0 = 19.761\\) e pelos limites de confiança serem ambos maiores que 55, pode-se constatar especificamente que a média é maior que 55 HRC.\nConsiderando o tamanho amostral, desvio-padrão amostral e efeito detectado, o poder do teste pode ser calculado com a sintaxe à seguir. Portanto, o teste apresentou poder unitário, com probabilidade nula de erro do tipo II. Uma alta razão entre o efeito (deslocamento na média) a ser detectado e o desvio-padrão da variável estudada aumenta o poder do teste.\n\n\n$sigma\n[1] 0.7552974\n\n$n\n[1] 30\n\n$power\n[1] 1\n\n$alpha\n[1] 0.05\n\n$effect\n[1] 2.725\n\n$test\n[1] \"two.tail\"\n\n\nA curva para o poder do teste Exemplo 2.2 é exposta na Figura 2.13. Pode-se observar que para um efeito superior a 0,65 é possível realizar o teste com \\(1-\\beta = 1\\).\n\n\n\n\n\n\n\n\nFigura 2.13: Curva de poder do teste para média da dureza",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "02-Testes.html#teste-t-para-médias-de-duas-amostras-independentes",
    "href": "02-Testes.html#teste-t-para-médias-de-duas-amostras-independentes",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "2.4 Teste t para médias de duas amostras independentes",
    "text": "2.4 Teste t para médias de duas amostras independentes\nEm diversas situações é de interesse do pesquisador realizar inferência sobre a média de duas amostras. Este tipo de teste pode ser realizado para comparar a diferença entre médias de dois tratamentos em uma resposta de interesse. O teste baseado na distribuição \\(t\\) pode ser utilizado para amostras pequenas quando as variâncias populacionais são desconhecidas. Há testes distintos para médias para amostras com variâncias iguais e para amostras com variâncias diferentes.\nAntes de entender os testes para média de duas amostras, é importante entender o que significa a independência e como testá-la estatisticamente. Duas amostras são ditas independentes quando são originadas de populações distintas. Uma forma de quantificar a dependência entre duas amostras é através da covariância e da correlação. Por estas medidas pode-se quantificar se a dependência entre duas variáveis de interesse é forte ou fraca. A covariância entre duas variáveis \\(xX\\) e \\(y\\), \\(Cov(x,y)=\\sigma_{xy}\\) pode ser definida conforme Equação 2.10, enquanto a correlação é definida conforme a Equação 2.11. Logo, pode-se constatar que a correlação é a covariância padronizada. Enquanto a covariância tem domínio em toda escala de números reais, \\(\\sigma_{xy} \\in (-\\infty,+\\infty)\\), a correlação tem domínio entre -1 e 1, \\(\\rho_{xy} \\in \\{-1,+1\\}\\), sendo mais fácil entender via correlação se o relacionamento linear é forte ou fraco.\n\\[\n  \\sigma_{xy} =  E((x_i-\\mu_x)(y_i-\\mu_y)) = E(xy) - \\mu_x\\mu_y\n\\tag{2.10}\\]\n\\[\n  \\rho_{xy} =  \\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}\n\\tag{2.11}\\]\nA Figura 2.14 apresenta diagramas de dispersão entre duas variáveis que ilustram padrões distintos de dependência (ou não) entre duas variáveis. Na Figura 2.14 à esquerda as variáveis \\(x\\) e \\(y\\) apresentam correlação positiva, com \\(\\rho \\rightarrow 1\\). Já na Figura 2.14 do meio as variáveis \\(x\\) e \\(y\\) apresentam correlação negativa, com \\(\\rho \\rightarrow -1\\). Por fim, na Figura 2.14 à direita as variáveis \\(x\\) e \\(y\\) apresentam ausência de correlação positiva, com \\(\\rho \\rightarrow 0\\).\n\n\n\n\n\n\n\n\nFigura 2.14: Diferentes padrões de correlação\n\n\n\n\n\nA correlação amostral \\(r_{xy}=\\hat{\\rho}\\) entre duas variáveis \\(x\\) e \\(y\\) pode ser calculada conforme Equação 2.12, ou pela Equação 2.13, onde \\(s_{xy} = \\hat{\\sigma}_{xy}\\) é a covariância amostral entre as variáveis \\(x\\) e \\(y\\) enquanto \\(s_{x}\\) e \\(s_{y}\\) são os desvios-padrões amostrais destas variáveis. A covariância amostral entre \\(x\\) e \\(y\\) pode ser estimada conforme Equação 2.14.\n\\[\n  r_{xy} = \\frac{\\sum_{i}(x_i-\\bar{x})\\sum_{i}(y_i-\\bar{y})}{\\sqrt{\\sum_{i}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i}(y_i-\\bar{y})^2}}\n\\tag{2.12}\\] \\[\n  r_{xy} = \\frac{s_{xy}}{s_xs_y}\n\\tag{2.13}\\] \\[\n  s_{xy} = \\frac{\\sum_{i}(x_i-\\bar{x})\\sum_{i}(y_i-\\bar{y})}{n-1}\n\\tag{2.14}\\]\n\nExemplo 2.3 Um tratamento a base de diclorometano é aplicado em uma amostra de fios de nanotubos de carbono. A resistência à tração (MPa) da amostra tratada é comparada com a resistência à tração de uma amostra sem tratamento. Os dados de trinta observações de cada caso são expostos à seguir.\n\n\n# amostra sem tratamento, x\nX &lt;- c(103.07251, 111.58047, 123.60685, 109.08819, 101.15997,\n       110.81570, 115.01119, 120.90489, 139.00266, 112.23041,\n       113.51231, 107.87118, 118.95093, 121.14550, 112.09335,\n       124.51045, 143.41912, 147.07329,  87.66812, 115.83727,\n       120.75799, 135.29565, 114.94833, 106.86862, 106.26170,\n       119.59667, 113.43255, 124.69555,  98.18949, 115.72124)\n\n# amostra com tratamento, y\nY &lt;- c(131.5811, 131.4042, 137.8762, 146.3840, 151.6944, 142.3577,\n       159.6285, 148.1704, 157.7661, 136.2317, 162.3226, 149.6494,\n       158.7077, 150.4730, 151.3008, 155.1563, 143.8435, 147.5971,\n       151.2632, 137.5846, 146.7573, 145.0630, 158.3956, 129.1484,\n       153.8584, 145.1890, 137.9211, 150.6881, 143.4069, 131.7691)\n\nO teste de correlação de Pearson, pode ser utilizado para avaliar a significância estatística da correlação entre duas amostras. A hipótese nula do teste garante que a correlação é igual a zero, isto é, \\(H_0: \\rho=0\\). Para realizar o teste de correlação de Pearson entre a amostra de controle e a amostra tratada do Exemplo 2.3, denotadas \\(x\\) e \\(y\\), respectivamente, pode-se utilizar a sintaxe à seguir. O teste é baseado na distribuição \\(t\\) e fornece como resultado o valor da estatística \\(t_0\\) a qual pode ser comparada com o valor crítico \\(t_{(\\alpha/2,n-2)}\\), onde \\(n = n_x + n_y\\). Se \\(t_0 &gt; t_{(\\alpha/2,n-1)}\\), rejeita-se \\(H_0\\). Considernado \\(\\alpha = 0,05\\), para \\(n = 58\\), \\(t_{(0,025;58)}=2.001717\\), qt(0.95+.05/2, 58). Logo, como \\(t_0 = 0,73203 &lt; 2.001717 = t_{(\\alpha/2,n-1)}\\), não há indícios para rejeição de \\(H_0\\), ou seja, a correlação entre as amostras é nula. A independência entre tais amostras é trivial, por terem sido retiradas de populações distintas. Entretanto, é importante confirmar a independência para posteriormente realizar o teste de hipóteses adequado para diferença entre médias das amostras.\n\n# Cálculo da correlação\ncor(X,Y)\n\n[1] 0.1370349\n\n# teste de correlação\ncor.test(X,Y, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  X and Y\nt = 0.73203, df = 28, p-value = 0.4702\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2348276  0.4739076\nsample estimates:\n      cor \n0.1370349 \n\n\nAntes de realizar o teste \\(t\\) para averiguar a diferença entre médias entre as variáveis \\(x\\) e \\(y\\) do Exemplo 2.3, é importante testar a homocedasticidade, isto é, a homogeneidade de variâncias entre as duas amostras. Primeiramente, é necessário organizar os dados de forma tabular utilizando o comando data.frame().\nPosteriormente, pode-se plotar alguns gráficos para visualizar a variabilidade dos dados. A Figura 2.15 ilustra boxplots, enquanto a Figura 2.16 ilustra gráficos de densidade da distribuição amostral para a resistência à tração em função das amostras de controle e tratada. Em ambos os casos, pode-se constatar que a variabilidade dos dados parece similar e que a resistência média da amostra tratada é superior. Pelos gráficos de densidade, pode-se verificar que as distribuições amostrais aparentam ter normalidade. Todas estas evidências gráficas podem ser estatísticamente confirmados.\n\n\n\n\n\n\n\n\nFigura 2.15: Boxplots para resistância à tração das amostras de controle e tratada\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 2.16: Histogramas e densidades amostrais para resistância à tração das amostras de controle e tratada\n\n\n\n\n\nO teste de homocedasticidade de Bartlett para o Exemplo 2.3 é apresentado à seguir. A hipótese nula do teste postula a igualdade de variâncias entre as amostras, isto é, \\(H_0: \\sigma_1^2 = \\sigma_2^2\\). Pelos resultados, como \\(p-value = 0,07128 &gt; 0,05 = \\alpha\\), não se rejeita \\(H_0\\), podendo-se confirmar a homogeneidade entre as variâncias amostrais.\n\n# Teste de homocedasticidade de Bartlett\nbartlett.test(resistencia ~ grupo, data = dados)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  resistencia by grupo\nBartlett's K-squared = 3.2534, df = 1, p-value = 0.07128\n\n\nO teste de normalidade das duas amostras também deve ser realizado. Pode-se constatar, pelos resultados abaixo, \\(p-value&lt;\\alpha\\), que não há indícios para rejeição da hipótese nula de normalidade das amostras. A Figura 2.17 ilustra os gráficos q-q para as amostras.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resistencia[grupo == \"Controle\"]\nW = 0.95678, p-value = 0.2557\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resistencia[grupo == \"Tratada\"]\nW = 0.96465, p-value = 0.4049\n\n\n\n\n\n\n\n\n\n\nFigura 2.17: Gráficos q-q para resistência à tração das amostras controle e tratada\n\n\n\n\n\nA hipótese nula do teste \\(t\\) para média de duas amostras é exposta à seguir.\n\\[\nH_0: \\mu_1 = \\mu_2\n\\]\nJá a hipótese alternativa pode ser bilateral, \\(\\ne\\), ou unilateral à esquerda ou a direita, conforme segue.\n\\[\nH_0: \\mu_1 \\ne \\mu_2\n\\] \\[\nH_0: \\mu_1 &lt; \\mu_2\n\\] \\[\nH_0: \\mu_1 &gt; \\mu_2\n\\]\nA estatística do teste \\(t\\) para duas amostras com variâncias amostrais iguais é calculada conforme Equação 2.15, onde o desvio-padrão combinado \\(S\\) é obtido conforme a Equação 2.16.\n\\[\nt_0 = \\frac{\\bar{x_1}-\\bar{x_2}}{s\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}\n\\tag{2.15}\\]\n\\[\ns = \\sqrt{\\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\n\\tag{2.16}\\]\nO cálculo da estatística \\(t_0\\) é trivial e pode ser facilmente realizado utilizando o R como uma calculadora. Entretanto, é mais interessante utilizar a função t.test(), por apresentar um resultado mais estruturado, cofnorme segue. Comparando o valor da estatística calculada com o valor crítico, \\(|t_0| = 10.393 &gt; 2.0003 = t_{\\alpha/2}\\), ou pelo p-valor, \\(p-valor = 7,3 \\times10^{-15} &lt; 0,05 = \\alpha\\), constata-se que há indícios para rejeição da hipótese nula, garantindo que as resistências das amostras são diferentes.\n\n# Teste t para comparar amostras de controle e tratada\nt.test(resistencia ~ grupo, \n       data = dados,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  resistencia by grupo\nt = -10.393, df = 58, p-value = 7.3e-15\nalternative hypothesis: true difference in means between group Controle and group Tratada is not equal to 0\n95 percent confidence interval:\n -35.73313 -24.19135\nsample estimates:\nmean in group Controle  mean in group Tratada \n              116.4774               146.4396 \n\ntcritico &lt;- qt(.95+.05/2,dim(dados)[1])\ntcritico\n\n[1] 2.000298\n\n# outra sintaxe possível\n# retirar # para testar\n# t.test(X, \n       # Y,\n       # alternative = \"two.sided\",\n       # var.equal = TRUE)\n\nO poder do teste pode ser obtido utilizando a função power.t.test, conforme segue. Pode-se observar que o poder do teste foi unitário.\n\n# médias\nm1 &lt;- with(dados, mean(resistencia[grupo == \"Controle\"]))\nm2 &lt;- with(dados, mean(resistencia[grupo == \"Tratada\"]))\n\n# desvios-padrões\ns1 &lt;- with(dados, sd(resistencia[grupo == \"Controle\"]))\ns2 &lt;- with(dados, sd(resistencia[grupo == \"Tratada\"]))\n\n# tamanhos amostrais\nn1 &lt;- with(dados, length(resistencia[grupo == \"Controle\"]))\nn2 &lt;- with(dados, length(resistencia[grupo == \"Tratada\"]))\n\n# desvio-padrão da diferença\ns &lt;- sqrt(((n1-1)*s1^2+(n2-1)*s2^2)/(n1+n2-2))\n\n# poder do teste\npower.t.test(n = 30, \n             delta = m1 - m2,\n             sd = s,\n             sig.level = 0.05,\n             type = \"two.sample\",\n             alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 30\n          delta = 29.96224\n             sd = 11.1657\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nA Figura 2.18 apresenta a curva de poder do teste em função do deslocamento a ser detectado para o Exemplo 2.3. A alta diferença entre médias, relativamente aos desvios-padrões amostrais, garantiu \\(1-\\beta \\backsimeq 1\\) no Exemplo 2.3.\n\n\n\n\n\n\n\n\nFigura 2.18: Curva de poder do teste, n1 = n2 = 30, sd = 11.17, teste bilateral",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "02-Testes.html#teste-t-para-médias-de-duas-amostras-dependentes",
    "href": "02-Testes.html#teste-t-para-médias-de-duas-amostras-dependentes",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "2.5 Teste t para médias de duas amostras dependentes",
    "text": "2.5 Teste t para médias de duas amostras dependentes\nO teste \\(t\\) para amostras pareadas (ou emparelhadas) é aplicado em estudos onde cada objeto é medido em duas diferentes ocasiões, antes e depois de um determinado tratamento, por exemplo. Este tipo de teste pode também ser aplicado em pares de indivíduos similares, sendo um tratamento aplicado a um elemento de cada par, enquanto o outro elemento dos pares é submetido a outro tratamento, ou não é submetido a tratamento algum (controle). Devido à possível dependência entre as amostras tomadas aos pares, utilizar os procedimentos anteriormente propostos para testar a diferença entre médias de duas amostras violaria a hipótese de independência estatística entre as amostras. Por conseguinte, o teste \\(t\\) pareado é utilizado para testar a diferença entre médias de amostras dependentes.\n\nExemplo 2.4 Um estudo foi realizado para avaliar se há diferença nos resultados de umidade de amostras de carvão vegetal submetidas aos dois procedimentos de preparação. De cada uma das 30 amostras de fração de carvão vegetal uma parte foi triturada e outra foi pulverizada, garantindo a dependência entre as amostras. Os dados das duas amostras são expostos à seguir.\n\n\n# A ordem das observações importa, pois estão pareadas\n\n# Amostra pulverizada\nPulverizada &lt;- c(10.5, 12.8, 11.1, 6.5, 6.2, 6.3, 7.5, 8.2, 7.8, 9.3,\n                 9, 10.2, 7.6, 6.8, 6.3, 7.3, 9.7, 10.9, 7.8, 9.8, 9,\n                 9.4, 9.4, 8.4, 8.5, 7.8, 9.1, 5.1, 5.7, 6.3)\n\n# Amostra granulada\nGranulada &lt;- c(10.7, 14.3, 11.2, 6.5, 6.6, 6.8, 7.1, 9.7, 7.2, 9, 9,\n               9.5, 5.3, 5.4, 5.9, 7.3, 9, 11.7, 6.3, 9.6, 9, \n               8.3, 9.8, 10.1, 9.2, 8.2, 8.7, 4.5, 6.4, 7.1)\n\nPara realizar o teste \\(t\\) para amostras pareadas, é importante confirmar a dependência entre as amostras. Para isto pode-se realizar o teste de correlação de Pearson, conforme segue. A Figura 2.19 apresenta um diagrama de dispersão, confirmando a correlação positiva entre as amostras de humidade do carvão vegetal pulverizado e granulado.\n\n\n\n    Pearson's product-moment correlation\n\ndata:  Pulverizada and Granulada\nt = 11.704, df = 28, p-value = 2.677e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8201861 0.9572343\nsample estimates:\n      cor \n0.9112053 \n\n\n\n\n\n\n\n\n\n\nFigura 2.19: Diagrama de dispersão para humidade das amostras de carvão vegetal pulverizada e granulada\n\n\n\n\n\nO teste \\(t\\) pareado é realizado considerando a diferença em relação às amostras pareadas. A hipótese nula consiste em testar se a diferença é igual a um valor de interesse, isto é, \\(H_0: \\mu_d = \\mu_{d0}\\). Já a hipótese alternativa pode ser bilateral ou unilateral à direita ou à esquerda. A estatística do teste \\(t\\) pareado é exposta na Equação 2.17, onde \\(n\\) é o número de pares. Logo, o teste consiste no mesmo teste \\(t\\) para uma amostra, de forma que a hipótese de normalidade para as diferenças deve ser confirmada.\n\\[\nt_0 = \\frac{\\bar{x}_d-\\mu_d}{s_d/\\sqrt{n}}\n\\tag{2.17}\\]\nO código à seguir calcula as diferenças entre os pares das duas amostras e, posteriormente a normalidade das diferenças.\n\n# calculando as diferenças\nd &lt;- Pulverizada - Granulada\n\n# teste de normalidade de Shapiro \nshapiro.test(d)\n\n\n    Shapiro-Wilk normality test\n\ndata:  d\nW = 0.9786, p-value = 0.7871\n\n# gráfico q-q\n# qqnorm(d)\n# qqline(d)\n\nFinalmente o teste \\(t\\) pareado é realizado através do código à seguir. Pode-se constatar que, como \\(p-valor = 0,8562 &gt; 0,05 = \\alpha\\), não se rejeita a hipótese nula de igualdade entre os métodos de preparação da amostra para medição de umidade do carvão vegetal. Como conclusão prática, não é necessário triturar o carvão para medir sua umidade.\n\n# Teste t pareado\nt.test(x = Pulverizada, y = Granulada,\n       alternative = \"two.sided\",\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  Pulverizada and Granulada\nt = 0.18284, df = 29, p-value = 0.8562\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3055859  0.3655859\nsample estimates:\nmean difference \n           0.03 \n\n# outra possibilidade fazer o teste t para uma amostra das diferenças\n# t.test(d)\n\nO cálculo do poder do teste pode ser realizado com a sintaxe que segue. Como a diferença é muito pequena considerando o desvio-padrão e o tamanho amostral, o poder do teste foi baixíssimo.\n\n\n\n     Paired t test power calculation \n\n              n = 30\n          delta = 0.03\n             sd = 0.8987156\n      sig.level = 0.05\n          power = 0.03728679\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "02-Testes.html#análise-de-variância",
    "href": "02-Testes.html#análise-de-variância",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "2.6 Análise de variância",
    "text": "2.6 Análise de variância\nQuando deseja-se testar a diferença entre médias para três ou mais amostras ou tratamentos, deve-se utilizar a análise de variância (ANOVA). A presença de três ou mais tratamentos é comum em diversos estudos experimentais, tornando a análise de variância umas das técnicas mais importantes em inferência estatística.\nExistem diversos tipos de ANOVA, considerando o número de fatores em avaliação, efeitos fixos ou aleatórios, etc. Neste primeiro momento será abordada a ANOVA para um fator (ou one-way) com modelo de efeitos fixos.\nSeja o conjunto geral de dados resumido na Tabela @ref(tab:anova-data). Neste conjunto tem-se \\(a\\) tratamentos de interesse e \\(n\\) observações ou replicações experimentais em cada tratamento. De forma geral, cada observação pode ser denotada como \\(y_{ij}\\), com \\(i = 1, ..., a\\) e \\(j = 1, ..., n\\).\n\n(#tab:anova-data) Dados de um experimento com \\(a\\) tratamentos e \\(n\\) observações em cada tratamento\n\n\n\n\n\n\n\n\nTratamentos\nObservações\nSomas\nMédias\n\n\n\n\n1\n\\(y_{11}\\), \\(y_{12}\\), …, \\(y_{1n}\\)\n\\(y_{1.} = \\sum_{j=1}^{n}{y_{1j}}\\)\n\\(\\bar{y}_{1.} = y_{1.}/n\\)\n\n\n2\n\\(y_{21}\\), \\(y_{22}\\), …, \\(y_{2n}\\)\n\\(y_{2.} = \\sum_{j=1}^{n}{y_{2j}}\\)\n\\(\\bar{y}_{2.} = y_{2.}/n\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\na\n\\(y_{a1}\\), \\(y_{a2}\\), …, \\(y_{an}\\)\n\\(y_{a.} = \\sum_{j=1}^{n}{y_{aj}}\\)\n\\(\\bar{y}_{a.} = y_{a.}/n\\)\n\n\n\nAinda na Tabela @ref(tab:anova-data) é importante obter os totais e as médias de cada tratamento, \\(y_{i.}\\) e \\(\\bar{y}_{i.}\\), \\(i = 1, ..., a\\), para facilitar os cálculos necessários à análise.\nCada observação experimental \\(y_{ij}\\) pode ser discriminada conforme o modelo apresentado na Equação @ref(eq:anova-model), o modelo de efeitos fixos da ANOVA. Neste modelo a média geral ou grande média denotada \\(\\mu\\) e calculada conforme a Equação @ref(eq:medg). O efeito de cada tratamento \\(\\alpha_{i}\\) consiste na diferença entre médias do tratamento e a média geral, \\(i = 1, ..., a\\), segundo Equação @ref(eq:eftrat). Por fim, o termo de erro \\(\\varepsilon_{ij}\\) consiste na diferença entre cada observação e a média dentro do seu tratamento, \\(i = 1, ..., a\\), \\(j = 1, ..., n\\), conforme Equação @ref(eq:erroanova). Sobre o termo de erro residem as hipóteses de que este seja normalmente e independentemente distribuído com média nula e variância \\(\\sigma^2_\\varepsilon\\), ou seja, \\(\\varepsilon_{ij} \\sim N(0,\\sigma^2_\\varepsilon)\\).\nA média logicamente pode variar de tratamento para tratamento, sendo esta hipotética variação testada estatísticamente. Já a variância dentro dos tratamentos é assumida constante.\n\\[\\begin{equation}\ny_{ij} = \\mu + \\alpha_{i} + \\varepsilon_{ij}\n(\\#eq:anova-model)\n\\end{equation}\\] \\[\\begin{equation}\n\\mu = \\bar{y}_{..} = \\frac{\n\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}{y_{ij}}}{an}\n(\\#eq:medg)\n\\end{equation}\\] \\[\\begin{equation}\n\\alpha_{i} = \\bar{y}_{i.} - \\bar{y}_{..}\n(\\#eq:eftrat)\n\\end{equation}\\] \\[\\begin{equation}\n\\varepsilon_{ij} = y_{ij} - \\bar{y}_{i.}\n(\\#eq:erroanova)\n\\end{equation}\\]\nEste modelo é chamado de modelo de efeitos fixos, com cada efeito dentro dos tratamentos fixo porém desconhecido a ser estimado. Este tipo de modelo é o mais comum na análise de variância, sendo utilizado quando deseja-se conhecer apenas o efeito dos tratamentos considerados. No caso onde se selecionam de forma aleatória \\(a\\) tratamentos de uma ampla população, desejando-se conhecer o efeito para toda população de origem, deve-se utilizar o modelo de efeitos aleatórios.\nAs hipóteses testadas na análise de variância são relacionadas aos efeito dos tratamentos e de forma análoga à média destes. A hipótese nula consiste na nulidade dos efeitos, enquanto a hipótese alternativa garante que ao menos um dos efeitos é não nulo, ou de outra forma ao menos uma média dos tratamentos é distinta dos demais. As hipóteses são formuladas à seguir.\n\\[\\begin{equation}\nH_0: \\alpha_1= \\alpha_2 = ... = \\alpha_a = 0\n\\end{equation}\\] \\[\\begin{equation}\nH_0: \\alpha_i \\ne 0, \\text{para ao menos um $i$}\n\\end{equation}\\]\nA análise de variância é um teste para diferença entre médias baseado no particionamento da soma dos quadrados total, na soma dos quadrados entre tratamentos e na soma dos quadrados dentro dos tratamentos, conforme Equação @ref(eq:vartotal). A variância total das observações experimentais da Tabela @ref(tab:anova-data) é expressa conforme Equação @ref(eq:vartotal). O numerador do cálculo, \\(SS_T\\), é a soma dos quadrados total, enquanto o denominador, \\(DF_T\\), consiste nos graus de liberdade total.\n\\[\\begin{equation}\ns_T^2 = s_{Entre}^2 + s_{Dentro}^2\n(\\#eq:sigmatotal)\n\\end{equation}\\] \\[\\begin{equation}\ns_T^2 = \\frac{SS_T}{DF_T} =  \\frac{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}{an-1}\n(\\#eq:vartotal)\n\\end{equation}\\]\nTomando a soma dos quadrados total, \\(SS_T\\), é possível particioná-la na soma dos quadrados entre os tratamentos, \\(SS_{Trat}\\), e na soma dos quadrados dentro dos tratamentos, \\(SS_{Erro}\\), conforme a Equação @ref(eq:ident-anova). Pode-se observar que a soma dos quadrados dos tratamentos e a soma dos quadrados dos erros são as somas dos quadrados dos efeitos expostos nas Equações @ref(eq:eftrat) e @ref(eq:erroanova), respectivamente. Na Tabela @ref(tab:anova-data) estas quantidades estão relacionados à variabilidade entre as linhas e dentro das linhas.\n\\[\\begin{equation}\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}_{SS_T}=\n\\underbrace{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}_{SS_{Trat}}+\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}_{SS_{Erro}}\n(\\#eq:ident-anova)\n\\end{equation}\\]\nOs graus de liberdade dos tratamentos estão relacionados ao número de tratamentos em estudo, \\(DF_{Trat} = a-1\\). Tomando a razão entre a soma dos quadrados e os graus de liberdade dos tratamentos, conforme Equação @ref(eq:mstrat) tem-se a média dos quadrados dos tratamentos, \\(MS_{Trat}\\). Esta medida é a estimativa da variância entre os tratamentos, \\(\\sigma_{Trat}^2=MS_{Trat}\\). Quanto maior esta medida, maior a diferença entre médias dos tratamentos. Entretanto, esta diferença deve ser avaliada relativamente à variância dentro dos tratamentos, isto é, em relação à variância experimental.\n\\[\\begin{equation}\nMS_{Trat} =  \\frac{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}{a-1}\n(\\#eq:mstrat)\n\\end{equation}\\]\nOs graus de liberdade dos erros devem ser avaliados com mais cuidado. Para o i-ésimo tratamento a i-ésima variância é calculada conforme a Equação @ref(eq:i-var). Combinando todas as variâncias dos \\(a\\) tratamentos, tem-se o resultado da Equação @ref(eq:mse). A média dos quadrados dos erros, \\(MS_E\\), é a estimativa da variância experimental na ANOVA, \\(\\sigma_\\varepsilon^2=MS_E\\). As médias dos quadrados são distribuídas pela distribuição \\(\\chi^2\\), por constarem de somas de desvios quadráticos em relação à média, isto é, soma dos quadrados de quantidades distribuídas pela normal-padrão \\(Z\\).\n\\[\\begin{equation}\ns_i^2 =  \\frac{\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{n-1}\n(\\#eq:i-var)\n\\end{equation}\\] \\[\\begin{equation}\nMS_E =  \\frac{\\displaystyle\\sum_{i=1}^{a}\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{a(n-1)}\n(\\#eq:mse)\n\\end{equation}\\]\nA estatística do teste ANOVA, \\(F_0\\), é calculada conforme Equação @ref(eq:f-anova), como a razão entre as médias dos quadrados dos tratamentos e dos erros. Quanto maior esta razão, maior a diferença entre os efeitos, relativamente ao erro experimental. Como esta quantidade consiste na razão entre médias dos quadrados, isto é, entre estimativas de variâncias ela é distribuída pela distribuição \\(F\\), \\(F_0 \\sim F_{(a-1,a(n-1))}\\). A hipótese \\(H_0\\) de nulidade e igualdade dos efeitos é rejeitada se \\(F_0 &gt; F_{(\\alpha,a-1,a(n-1))}\\). A Tabela @ref(tab:res-anova) resume os cálculos da ANOVA. Geralmente os resultados obtidos via ANOVA são apresentados neste formato.\n\\[\\begin{equation}\nF_0 =  \\frac{MS_{Trat}}{MS_{Erro}}\n(\\#eq:f-anova)\n\\end{equation}\\]\n\n(#tab:res-anova) Tabela resumo ANOVA\n\n\n\n\n\n\n\n\n\nFonte\nDF\nSS\nMS\n\\(F_0\\)\n\n\n\n\nTratamentos\n\\(a-1\\)\n\\(SS_{Trat}\\)\n\\(SS_{Trat}/(a-1)\\)\n\\(F_0 = MS_{Trat}/MS_{Erro}\\)\n\n\nErro\n\\(a(n-1)\\)\n\\(SS_{Erro}\\)\n\\(SS_{Erro}/[a(n-1)]\\)\n-\n\n\nTotal\n\\(an - 1\\)\n\\(SS_{T}\\)\n-\n-\n\n\n\nExistem algumas medidas de ajuste usadas para averiguar a efetividade do modelo obtido via ANOVA. O coeficiente de determinação simples \\(R^2\\) é calculado conforme a Equação @ref(eq:R2), como a razão entre a soma dos quadrados dos tratamentos e a soma dos quadrados total. Esta medida deve ser usada com cautela, por não levar em consideração o número de graus de liberdade do modelo. neste sentido, o coeficiente de determinação ajustado \\(R_{aj}^2\\) é obtido conforme a Equação @ref(eq:R2aj).\n\\[\\begin{equation}\nR^2 = \\frac{SS_{Trat}}{SS_T}\n(\\#eq:R2)\n\\end{equation}\\] \\[\\begin{equation}\nR_{aj}^2 = 1 - \\frac{MS_{Trat}}{SS_T/(an-1)}\n(\\#eq:R2aj)\n\\end{equation}\\]\nA ANOVA para três ou mais tratamentos é comumente chamada de ANOVA one-way. Para conduzir este tipo de análise, deve-se utilizar o chamado planejamento totalmente aleatorizado ou delineamento inteiramente casualizado. Neste planejamento todas as \\(N = an\\) observações experimentais são conduzidas em ordem e alocação de materiais totalmente aleatória. A aleatorização auxilia na garantia das hipóteses de normalidade e independencia dos resíduos. Ao aleatorizar os experimentos garante-se que fontes externas incontroláveis de variação, chamadas de ruídos, tenham interferência mínima ou ao menos tenham efeito diluido de maneira aleatória nos resultados experimentais. As replicações viabilizam a estimativa do erro experimental. Sem a replicação não é possível testar a significância dos efeitos avaliados, visto que estes são sempre avaliados relativamente ao erro experimental.\n\n\n\nPlanejamento totalmente aleatorizado para microdureza HV em [GPa] em função do método de resfriamento de cerâmicas de zirconia\n\n\nordem\ncooling\nhardness\n\n\n\n\n10\nslow\n5.34\n\n\n3\nslow\n5.43\n\n\n12\nslow\n5.42\n\n\n7\nslow\n5.40\n\n\n2\nslow\n5.38\n\n\n15\nnormal\n5.20\n\n\n6\nnormal\n5.22\n\n\n8\nnormal\n5.15\n\n\n14\nnormal\n5.25\n\n\n9\nnormal\n5.24\n\n\n13\nfast\n5.20\n\n\n11\nfast\n5.15\n\n\n5\nfast\n5.19\n\n\n4\nfast\n5.17\n\n\n1\nfast\n5.18\n\n\n\n\n\nPara obter este planejamento pode-se utilizar o código à seguir no R.\nPara realizar a análise é utilizado o comando aov(). Pelos resultados, como \\(F_0 = 62,84 &gt; 3,89 = F_{(0,05,2,12)}\\), ou como \\(p-value = 4,38 \\times 10^{-7} &lt; 0,05 = \\alpha\\), rejeita-se \\(H_0\\). Deste modo, há ao menos um dos tratamentos com efeito diferente, de forma que há influência do tipo de resfriamento na microdureza. A estatística de ajuste \\(R_{aj}^2=0,898\\), garante que a maior parte da variabilidade dos dados é explicada pelo efeito dos tratamentos e não pelo erro experimental.\n\n\n            Df  Sum Sq Mean Sq F value   Pr(&gt;F)    \ncooling      2 0.13489 0.06745   62.84 4.38e-07 ***\nResiduals   12 0.01288 0.00107                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[1] 3.885294\n\n\n\nCall:\nlm(formula = hardness ~ cooling, data = plan)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-0.062 -0.013  0.006  0.024  0.038 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    5.17800    0.01465 353.411  &lt; 2e-16 ***\ncoolingnormal  0.03400    0.02072   1.641    0.127    \ncoolingslow    0.21600    0.02072  10.425 2.28e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03276 on 12 degrees of freedom\nMultiple R-squared:  0.9128,    Adjusted R-squared:  0.8983 \nF-statistic: 62.84 on 2 and 12 DF,  p-value: 4.384e-07\n\n\nA Figura @ref(fig:Fcritico) ilustra a região crítica do teste, com regão de rejeição de \\(H_0\\) destacada em vermelho.\n\n\n\n\n\nRegião crítica ANOVA, \\(\\alpha = 0,05, DF1 = 2, DF2 = 12\\)\n\n\n\n\nPara testar as pressuposições de normalidade e homocedasticidade pode-se utilizar os blocos de código à seguir. Para ambos os testes obteve-se \\(p-value &gt; \\alpha\\), não havendo indícios para rejeição da hipótese nula \\(H_0\\), implicando na normalidade dos resíduos e na igualdade de variâncias dos tratamentos.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuos\nW = 0.92867, p-value = 0.2607\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  hardness by cooling\nBartlett's K-squared = 1.831, df = 2, p-value = 0.4003\n\n\nA Figura @ref(fig:resi-anova), com sintaxe à seguir, ilustra alguns gráficos dos resíduos que auxiliam na visualização das pressuposições da ANOVA. O gráfico superior esquerdo plota os resíduos \\(\\varepsilon_{ij}\\) em relação aos valores previstos ou ajustados (fitted), \\(\\hat{y}_i=\\mu+\\alpha_i=\\bar{y}_{i.}\\). Um padrão de aleatoriedade, sem crescimento ou decrescimento de \\(\\varepsilon_{ij}\\) em função de \\(\\hat{y}_i\\) deve ser observado. Para o caso estudado não há indícios de dependência entre resíduos e valores ajustados. O gráfico superior direito é o gráfico quantil-quantil que plota os resíduos ordenados em função dos quantis teóricos da normal padrão. Quanto mais próximo da reta, melhor os resíduos se ajustam à distribuição normal. O gráfico inferior esquerdo plota a raiz quadrada dos resíduos padronizados em função dos valores ajustados. Este é um auxílio para ver, além da independência entre resíduos e ajustados, a homocedasticidade. No caso estudado, já confirmado estatísticamente, visualiza-se a homogeneidade da raiz dos resíduos padronizados em relação às médias dos tratamentos. O último gráfico, plotado no canto inferior direito, plota os resíduos em função dos níveis (tratamentos) experimentais. Deve-se averiguar por este gráfico a homogeneidade e independência dos resíduos em função dos níveis, além da possível presença de outliers, isto é, de valores discrepantes. Em caso de um ajuste baixo, isto é, um \\(R_{aj}^2\\) insuficiente, alguns experimentos com resíduos extremos destacados neste gráfico poderiam ser repetidos. No caso estudado não seria necessário.\n\n\n\n\n\nGráficos de resíduos para ANOVA, dureza ~ resfriamento\n\n\n\n\nA Figura @ref(fig:bp-anova) apresenta um box-plot da dureza em função do tipo de resfriamento, com código relacionado à seguir. O resfriamento lento garante maior microdureza da cerâmica.\n\n\n\n\n\nBoxplot para dureza ~ resfriamento\n\n\n\n\nA Figura @ref(fig:efeitos-anova) apresenta a média com intervalos de confiança. Ao rejeitar a hipótese nula através da ANOVA, o analista apenas constata que há ao menos um efeito distinto dos demais, em conformidade com a hipótese alternativa \\(H_1\\). Entretanto, pode ser desejado investigar as diferenças específicas.\n\n\n\n\n\nAjustados ~ resfriamento\n\n\n\n\nPosteriormente à ANOVA pode-se utilizar de testes de comparação de médias, ou testes de comparações múltiplas para testar as diferenças específicas. Nestes tipo de teste todas as comparações aos pares são realizadas entre as médias dos \\(a\\) tratamentos testados na ANOVA. A hipótese nula de cada comparação é sempre \\(H_0:\\mu_i = \\mu_j\\). Um teste bastante utilizado é o teste de Tukey HSD (honestly significant difference), por apresentar um bom controle da probabilidade de erro do tipo I. Entretanto, este teste é conhecido por apresentar alta probabilidade de erro do tipo II (baixo poder do teste). Outras opções disponíveis para comparações múltiplas como os testes de Duncan, teste t, teste de Newman-Keuls, teste t-bayesiano, entre outros.\nO código à seguir pode ser utilizado para realizar o teste de Tukey. Pode-se confirmar que o resfriamento lento é diferente do resfriamento normal e do resfriamento rápido, enquanto estes dois não são estatísticamente diferentes.\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = hardness ~ cooling, data = plan)\n\n$cooling\n             diff        lwr       upr     p adj\nnormal-fast 0.034 -0.0212791 0.0892791 0.2670508\nslow-fast   0.216  0.1607209 0.2712791 0.0000006\nslow-normal 0.182  0.1267209 0.2372791 0.0000040\n\n\nÉ possível obter o poder do teste para ANOVA com o comando power.anova.test, conforme sintaxe à seguir. Pode-se observar que o poder foi unitário, o que já era esperado, uma vez que rejeitou-se a hipótese nula pela ANOVA.\n\n\n\n     Balanced one-way analysis of variance power calculation \n\n         groups = 3\n              n = 5\n    between.var = 0.06745\n     within.var = 0.00107\n      sig.level = 0.05\n          power = 1\n\nNOTE: n is number in each group\n\n\nCaso o experimentador deseje encontrar o número de réplicas adequado para um determinado poder do teste antes de planejar seu experimento, deve-se ter uma estimativa de \\(SS_{Trat}\\) e \\(SS_{Erro}\\), o que geralmente é difícil de conseguir, especialmente quando não se tem conhecimento da variabilidade acerca dos tratamentos em estudo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "02-Testes.html#bibliografia",
    "href": "02-Testes.html#bibliografia",
    "title": "2  Testes de hipóteses para média de uma e duas amostras",
    "section": "Bibliografia",
    "text": "Bibliografia\nALMEIDA JUNIOR, Antonio Alves de et al. Effect of the cooling rate on the properties of veneer porcelain. 2017.\nBUSSAB, Wilton de Oliveira; MORETTIN, Pedro Alberto. Estatística básica. 2009.\nCASELLA, George; BERGER, Roger L. Statistical inference. 2002.\nCOCHRAN, William G. The distribution of quadratic forms in a normal system. 1934.\nFISHER, Ronald Aylmer et al. Statistical methods for research workers. 1934.\nGRONOW, D. G. C. Test for the significance of the difference between means. 1951.\nGURLAND, John; MCCULLOUGH, Roger S. Testing equality of means. 1962.\nHALD, Anders. A history of parametric statistical inference. 2008.\nJOHNSON, N. L.; WELCH, B. L. Applications of the non-central t-distribution. 1940.\nKEMPTHORNE, Oscar. The randomization theory of experimental inference. 1955.\nKENDALL, Maurice George et al. The advanced theory of statistics. 1946.\nKOTZ, Samuel; JOHNSON, Norman L. Breakthroughs in statistics. 2012.\nLEHMANN, Erich L.; ROMANO, Joseph P. Testing statistical hypotheses. 2006.\nMCCULLOUGH, Roger S.; GURLAND, John; ROSENBERG, Lloyd. Small sample behaviour. 1960.\nMEHTA, J. S.; GURLAND, John. Testing equality of means in the presence of correlation. 1969.\nMONTGOMERY, Douglas C. Design and analysis of experiments. 2013.\nMONTGOMERY, Douglas C.; RUNGER, George C. Applied statistics and probability for engineers. 2011.\nNEYMAN, Jerzy; PEARSON, Egon S. The testing of statistical hypotheses in relation to probabilities a priori. 1933.\nNEYMAN, Jerzy; TOKARSKA, B. Errors of the second kind in testing “Student’s” hypothesis. 1936.\nOWEN, D. B. The power of Student’s t-test. 1965.\nSNEDECOR, George W.; COCHRAN, Witiiam G. Statistical methods. 1967.\nSCARIANO, Stephen M.; DAVENPORT, James M. The effects of violations of independence assumptions. 1987.\nSTUDENT. The probable error of a mean. 1908.\nWASSERMAN, Larry. All of statistics: a concise course in statistical inference. 2013.\nWELCH, Bernard L. The significance of the difference between two means. 1938.\nWILSON, Edwin B.; WORCESTER, Jane. Note on the t-Test. 1942.\nYATES, Frank. The analysis of multiple classifications. 1934.\nZUEV, Konstantin. Statistical Inference. 2018.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Testes de hipóteses para média de uma e duas amostras</span>"
    ]
  },
  {
    "objectID": "01-Dists.html",
    "href": "01-Dists.html",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "",
    "text": "1.1 Introdução\nInferência é o ramo da estatística que trata da obtenção de informações acerca de um parâmetro populacional a partir de dados amostrais. Em outras palavras, pode-se dizer que inferência constiste no aprendizado sobre a população considerando um conjunto limitado, porém suficiente, de observações retiradas desta. Em diversas situações deseja-se obter informações de parâmetros desconhecidos de uma população de interesse. Por exemplo, de um lote de tubos sem costura produzidos em um determinado horizonte de produção, por uma determinada empresa metalúrgica. Neste caso é viável coletar uma amostra para inspecionar e inferir sobre o diâmetro médio da população de tubos produzida em relação a um valor alvo de interesse. Em outros procedimentos, podem ser comparados processos, materiais, métodos de preparação, entre outras fontes de variação de interesse científico e industrial.\nNeste capítulo serão abordadas algumas distribuições essenciais à modelagem e análise de experimentos. Tais funções serão usadas em diversos testes estatísticos para inferência e avaliação da significância dos efeitos de variáveis de interesse em diversos planejamentos explicitados neste livro.\nNeste capítulo é utilizado apenas o pacote ggpplot2 para gráficos, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#distribuição-normal",
    "href": "01-Dists.html#distribuição-normal",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.2 Distribuição normal",
    "text": "1.2 Distribuição normal\nSeja uma amostra aleatória de \\(n\\) observações,\\(x_1\\), \\(x_2\\), …, \\(x_n\\), retirada de uma população de tamanho \\(N\\). Cada observação amostral é retirada de forma independente. Se a população de origem é dita normal, ela é descrita pela função densidade de probabilidade (fdp) da Equação 1.1. Uma variável aleatória (va) \\(x\\) descrita por esta distribuição é dita normal com média \\(\\mu\\) e variância \\(\\sigma^2\\), isto é \\(x \\sim N(\\mu,\\sigma^2)\\).\n\\[\n  f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^{2}}\n\\tag{1.1}\\]\nA Figura 1.1 ilustra a função densidade de probabilidade da distribuição normal de uma variável aleatória (va) \\(x \\sim N(100,1)\\), enquanto a Figura 1.2 expõe um histograma de uma amostra com n = 1000 observações retirada de tal va. O código para obter tais gráficos no R são expostos à seguir.\n\n# Carregar a biblioteca ggplot2\nlibrary(ggplot2)\ntheme_set(theme_bw())\n\n# Dados para eixo horizontal\nx &lt;- seq(from = 95, to = 105, length = 500)\n\n# Avaliando cada valor de x na fdp da distribuição normal\ny &lt;- dnorm(x = x, mean = 100, sd = 1)\n\n# Criar um data frame para o ggplot\ndata &lt;- data.frame(x = x, y = y)\n\n# Plotando a fdp com ggplot2\nggplot(data, aes(x = x, y = y)) +\n  geom_line() +\n  ylab(\"densidade\")\n\n\n\n\n\n\n\nFigura 1.1: fdp normal, \\(\\mu = 100\\), \\(\\sigma^2 = 1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 1.2: histograma de uma amostra com n = 1000 observações retirada de uma população \\(N(100,1)\\)\n\n\n\n\n\nA Figura 1.3 expõe gráficos de densidade de probabilidade da função normal com variação nos parâmetros de posição (média) e dispersão (variância). Pode-se observar que o aumento na média apenas desloca a distribuição para a direita, enquanto o aumento na variância resulta em uma distribuição com maior probabilidade nas caudas e menor probabilidade na média. Quando duas vas tem médias diferentes, com variância igual, diz-se haver um viés ou vício entre estas, enquanto duas vas com médias iguais e variâncias distintas, são ditas com erro aleatório distinto. A distribuição normal é simétrica e assíntota, tendo portanto domínio \\(x \\in (-\\infty, +\\infty)\\).\n\n\n\n\n\n\n\n\nFigura 1.3: Variação dos parâmetros da distribuição normal\n\n\n\n\n\nOs parâmetos populacionais da distribuição normal podem ser calculados conforme a Equação 1.2 e a Equação 1.3. A variância populacional \\(\\sigma^2\\) tem unidade de medida igual ao quadrado da unidade de medida da va em avaliação. Neste sentido, uma outra medida é comumente utilizada como medida de dispersão, o desvio-padrão, \\(\\sigma\\), sendo calculado conforme a Equação 1.4. O desvio-padrão, \\(\\sigma\\), tem sua unidade de medida igual à da va de interesse, sendo de interpretação mais fácil como medida de dispersão em situações práticas. Uma propriedade importante do desvio-padrão é que no gráfico da função densidade de probabilidade os pontos de inflexão estão à distância de um desvio-padrão em relação à média, conforme ilustrado na Figura 1.4.\n\\[\n  \\mu = \\frac{\\sum_{i = 1}^{N}x_i}{N} = \\frac{x_1+x_2+\\dots+x_N}{N}\n\\tag{1.2}\\]\n\\[\n  \\sigma^2 = \\frac{\\sum_{i = 1}^{N}(x_i - \\mu)^2}{N}\n\\tag{1.3}\\]\n\\[\n  \\sigma = \\sqrt{\\frac{\\sum_{i = 1}^{N}(x_i - \\mu)^2}{N}}\n\\tag{1.4}\\]\n\n\n\n\n\n\n\n\nFigura 1.4: Desvio-padrão \\(\\sigma\\), \\(N(0, 1)\\)\n\n\n\n\n\nAo obter uma amostra de uma distribuição normal com parâmetros desconhecidos é importante estimar os parâmetros populacionais. A estimativa para a média, \\(\\hat{\\mu} = \\bar{x}\\), é obtida conforme a Equação 1.5, tomando, portanto, a razão entre a soma das \\(n\\) observações, \\(x_1, x_2, ..., x_n\\), e o tamanho amostral \\(n\\). Já a variância amostral \\(\\hat{\\sigma}^2 = s^2\\) é estimada considerando o quadrado da soma dos desvios em relação à média, dividido pelo número de graus de liberdade da amostra \\(n - 1\\), conforme Equação 1.6. O desvio-padrão amostral também pode ser obtido tomando a raiz quadrada da variância amostral, conforme Equação 1.7.\n\\[\n  \\bar{x} = \\frac{\\sum_{i = 1}^{n}x_i}{n} = \\frac{x_1+x_2+...+x_n}{n}\n\\tag{1.5}\\]\n\\[\n  s^2 = \\frac{\\sum_{i = 1}^{n}(x_i - \\bar{x})^2}{n - 1}\n\\tag{1.6}\\]\n\\[\n  s = \\sqrt{\\frac{\\sum_{i = 1}^{n}(x_i - \\bar{x})^2}{n - 1}}\n\\tag{1.7}\\]\nEm uma distribuição de probabilidade contínua, como a normal, a probabilidade consiste na área sob a curva, enquanto as distribuições discretas admitem a probabilidade pontual, conforme expresso na Tabela 1.1. A Figura 1.5 ilustra o conceito de probabilidade pontual em distribuição discreta e de probabilidade em um intervalo de interesse, consistindo na área sob a curva da função densidade de probabilidade, no caso contínuo.\n\n\n\n\nTabela 1.1: Probabilidade em distribuição discreta e contínua\n\n\n\n\n\n\n\n\n\n\nDistribuição discreta\nDistribuição contínua\n\n\n\n\n0 \\(\\leq p(x_j) \\leq 1\\)\n\\(p(a \\leq x \\leq b) = \\int_a^b f(x)dx\\)\n\n\n\\(\\sum_{j=1}^{n} p(x_j) = 1\\)\n\\(\\int_{-\\infty}^{+\\infty} f(x)dx = 1\\)\n\n\n\\(\\mu = E(x) = \\sum_{j=1}^{n} x_jp(x_j)\\)\n\\(\\mu = E(x) = \\int_{-\\infty}^{+\\infty} xf(x)dx\\)\n\n\n\\(\\sigma^2 = Var(x) = \\sum_{j=1}^{n} (x_j-\\mu)^2p(x_j)\\)\n\\(\\sigma^2 = Var(x) = \\int_{-\\infty}^{+\\infty} (x-\\mu)^2f(x)dx\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 1.5: Probabilidade em (a) distribuição discreta e (b) contínua\n\n\n\n\n\nAinda conforme expresso na Tabela 1.1, para o caso discreto o total de todos os eventos deve ser unitário. De maneira análoga, a integral de uma função densidade de probabilidade contínua em todo o seu domínio deve ser igual à unidade. A média de uma va pode ser descrita utilizando o operador de esperança \\(\\mu = E(x)\\). No caso discreto a média consiste na soma do produto entre os eventos e suas respectivas probabilidades em todo o espaço amostral. Já no caso contínuo, a média consiste na integral do produto entre o valor da va e sua fdp em todo o domínio da função. A variância de uma va pode ser descrita através do operador de variância, que por sua vez, pode ser descrito usando o operador de esperança, isto é, \\(\\sigma^2= Var(x) = E[(x-\\mu)^2]\\). A Tabela 1.1 finaliza expondo o cálculo da variância para os casos discreto e contínuo.\nAlgumas propriedades dos operadores de média ou esperança e variância são essenciais à análise, modelagem e otimização de experimentos, sendo resumidas na Tabela 1.2, sendo \\(x\\) uma va com média \\(E(x)=\\mu_x\\) e variância \\(V(x)=\\sigma_x^2\\). Seja \\(a\\) uma constante \\(a \\in \\Re\\). Seja também uma va \\(y\\) com média \\(E(y)=\\mu_y\\) e variância \\(V(y)=\\sigma_y^2\\), sendo \\(x\\) e \\(y\\) vas independentes, é possível provar as propriedades resumidas na Tabela 1.2.\n\n\n\n\nTabela 1.2: Propriedades dos operadores de média e variância\n\n\n\n\n\n\nOperador de média ou esperança\nOperador de variâncias\n\n\n\n\n\\(E(x)=\\mu_x\\)\n\\(V(x)=E[(x-\\mu_x)^2]=E(x^2)−E^2(x)\\)\n\n\n\\(E(a)=a\\)\n\\(V(a)=0\\)\n\n\n\\(E(a+x) = a + E(x)\\)\n\\(V(a+x) = V(x)\\)\n\n\n\\(E(ax) = aE(x)\\)\n\\(V(ax) = a^2V(x)\\)\n\n\n\\(E(x + y) = E(x) + E(y)\\)\n\\(V(x+y)=V(x-y)=V(x)+V(y)\\)\n\n\n\n\n\n\n\n\nTomando uma variável aleatória que segue a distribuição normal com parâmetros \\(\\mu\\) e \\(\\sigma^2\\), isto é, \\(x \\sim N(\\mu,\\sigma^2)\\), é possível calcular probabilidades considerando valores de interesse do investigador, conforme o Exemplo a seguir.\nSeja um processo de trefilação de aço que produz arames com diâmetro médio mm \\(\\mu\\) = 3,40 e variância \\(\\sigma^2 = 0,10^2 mm^2\\). Deseja-se calcular a probabilidade de o diâmetro ser menor que 3,30 mm.\nNo R é fácil calcular esta probabilidade através do comando pnorm, conforme segue. Logo, \\(P(x &lt; 3,3) = 0.1586553\\). A Figura 1.6 ilustra esta probabilidade.\n\n# P(x &lt; 3,3)\npnorm(q = 3.3, mean = 3.4, sd = 0.1)\n\n[1] 0.1586553\n\n\n\n\n\n\n\n\n\n\nFigura 1.6: \\(P(x&lt;3,3), x \\sim N(3,4; 0,1^2)\\)\n\n\n\n\n\nPara obter o gráfico da função densidade de probabilidade com a área relacionada à probabilidade hachurada, similar ao da Figura 1.6, deve-se utilizar o código a seguir.\n\ndf &lt;- data.frame(\n  x = seq(3, 3.8, length = 500),\n  y = dnorm(seq(3, 3.8, length = 500), mean = 3.4, sd = 0.1)\n)\nshaded_area &lt;- data.frame(\n  x = seq(3, 3.3, length = 100),\n  y = dnorm(seq(3, 3.3, length = 100), mean = 3.4, sd = 0.1)\n)\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\", linewidth = 0.8) +\n  geom_ribbon(\n    data = shaded_area,\n    aes(ymin = 0, ymax = y),\n    fill = \"seagreen3\", alpha = 0.5\n  ) +\n  annotate(\"text\", x = 3.15, y = 1, \n           label = \"P(x &lt; 3.3)\", color = \"green4\", size = 5) +\n  labs(x = \"x\", y = \"Probabilidade\")\n\nUm caso particular da distribuição normal é a normal padrão \\(z \\sim N(0,1)\\). É comum utilizá-la como referência para obter escores da distribuição normal, isto é valores \\(Z\\) em relação à uma probabilidade de interesse. Além disso, a padronização deixa a va normal adimensional e centrada em zero e com desvio-padrão unitário. São facilmente encontradas tabelas para estes valores considerando probabilidades distintas. Entretanto, o advento dos pacotes computacionais estatísticos diminui a necessidade destas. Qualquer variável aleatória normalmente distribuída, \\(x \\sim N(\\mu,\\sigma^2)\\), pode ser padronizada utilizando-se a Equação 1.8.\n\\[\n  z = \\frac{x-\\mu}{\\sigma}\n\\tag{1.8}\\]\nA Equação 1.9 expõe a função densidade de probabilidade da distribuição normal padrão \\(z\\). O coeficiente \\(\\frac{1}{\\sqrt{2\\pi}}\\) garante que a área sob a curva seja unitária. A probabilidade à esquerda de um valor de interesse é denotada \\(\\Phi(\\zeta) = P(z \\leq \\zeta)\\), sendo calculada conforme a Equação 1.10. A Figura 1.7 ilustra três exemplos com probabilidade de 0,25, 0,5 e 0,75.\n\\[\n  f(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}z^{2}}\n\\tag{1.9}\\]\n\\[\n  \\Phi(\\zeta) = \\int_{-\\infty}^{\\zeta} f(z) dz\n\\tag{1.10}\\]\n\n\n\n\n\n\n\n\nFigura 1.7: quantil \\(\\phi(z_q) = q\\)\n\n\n\n\n\nPara encontrar no R o valor da probabilidade à esquerda associada a um determinado valor \\(z_p\\), deve-se utilizar o comando pnorm(zq), enquanto para determinar o valor \\(z_p\\) associado a uma probabilidade \\(p\\) de interesse, deve-se utilizar o comando qnorm(p), conforme exemplos à seguir.\n\n# probabilidade phi(z_q) para z = 0.6744898\npnorm(0.6744898)\n\n[1] 0.75\n\n# valor z_q associado à probabilidade p = 0.75, P(Z &lt; z_q) = 0.5\nqnorm(0.75)\n\n[1] 0.6744898\n\n# probabilidade p para z_p = 0 \npnorm(0)\n\n[1] 0.5\n\n# valor z_p associado à probabilidade p = 0.5\nqnorm(0.5)\n\n[1] 0\n\n# probabilidade q para z_p = -0.6744898 \npnorm(-0.6744898)\n\n[1] 0.25\n\n# valor z associado à probabilidade p = 0.25\nqnorm(0.25)\n\n[1] -0.6744898\n\n\nUma regra usual da distribuição normal é a regra 68-95-99%. Por esta regra sabe-se que na distribuição normal a probabilidade entre \\(\\pm 1\\) desvio-padrão em relação à média é igual a 0,6827, enquanto a probabilidade entre \\(\\pm 2\\) desvios-padrões em relação à média é igual a 0,9545. Por fim, a probabilidade entre \\(\\pm 3\\) desvios é igual a 0,9973, conforme ilustrado na Figura 1.8. Em metrologia é comum a incerteza de medição ser calculada considerando mais ou menos dois desvios-padrões em relação à média do mensurando corrigida, sendo considerado 0.9545 de confiança ara encontrar o erro de medição. Em controle estatístico de qualidade é comum o uso de mais ou menos três desvios-padrões em relação à média em cartas de controle, sendo o nível de confiança de 0.9973 o mais usado em tais aplicações. Para calcular tais probabilidades na linguagem R, pode-se utilizar o código abaixo.\n\n# P(-1&lt;z&lt;1)\npnorm(q = 1)-pnorm(q = -1)\n\n[1] 0.6826895\n\n# P(-2&lt;z&lt;2)\npnorm(q = 2)-pnorm(q = -2)\n\n[1] 0.9544997\n\n# P(-3&lt;z&lt;3)\npnorm(q = 3)-pnorm(q = -3)\n\n[1] 0.9973002\n\n\n\n\n\n\n\n\n\n\nFigura 1.8: Regra 68-95-99.7\n\n\n\n\n\nApós todas estas constatações, é viável apresentar o Teorema 1.1, denominado central do limite (TCL), sendo este essencial à inferência e estatística experimental.\n\nTeorema 1.1 (Teorema central do limite) Sejam \\(n\\) variáveis aleatórias \\(x_1, x_2, ..., x_n\\), sendo estas independentes e identicamente distribuídas (iid), com média \\(\\mu\\) e variância \\(\\sigma^2\\). A média amostral \\(\\bar{x}\\) é aproximadamente normal com média \\(\\mu\\) e variância \\(\\sigma^2/n\\):\n\\(\\bar{x} \\sim N(\\mu,\\frac{\\sigma^2}{n})\\)\nDe maneira análoga,\n\\(P(\\frac{\\mu - \\bar{x}}{\\sigma/\\sqrt{n}} \\leq z) \\rightarrow \\Phi(z)\\)\n\nPelo TCL, para um \\(n\\) suficientemente grande, pode-se afirmar que a média amostral é aproximadamente normalmente distribuída com média \\(\\mu\\) e variância \\(\\frac{\\sigma^2}{n}\\). Ademais, o desvio-padrão da média amostral é igual \\(\\sigma/\\sqrt{n}\\). O enunciado do TCL tem diversas implicações em modelagem e otimização de experimentos planejados, sendo, portanto, essencial sua compreensão.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#distribuição-chi-quadrado",
    "href": "01-Dists.html#distribuição-chi-quadrado",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.3 Distribuição Chi-quadrado",
    "text": "1.3 Distribuição Chi-quadrado\nA distribuição da variância amostral \\(s^2\\) é de interesse em muitos problemas de inferência. A distribuição chi-quadrado, denotada \\(\\chi^2\\), com \\(k\\) graus de liberdade é utilizada para descrever a soma dos quadrados de \\(k\\) vas normais-padrão independentes, \\(z_i \\sim N(0,1)\\), conforme segue. Uma vez que, ao calcular a variância amostral, conforme a Equação 1.6, toma-se a soma dos quadrados dos desvios das observações em relação à média, isto é, a soma dos quadrados de vas normais-padrão, pode-se inferir que a variância é distribuída pela va segue a distribuição \\(\\chi^2\\).\n\\[\n  z_1^2 + z_2^2 + ... + z_k^2 \\sim \\chi^2\n\\]\nA Equação 1.11 expõe a função densidade de probabilidade da distribuição \\(\\chi^2\\), onde \\(\\Gamma(k/2)\\) denota a função gamma, \\(\\Gamma(n) = (n-1)!\\). A Figura 1.9 expõe gráficos da fdp \\(\\chi^2\\) com variação do número de graus de liberdade.\n\\[\n  f(x) = \\frac{1}{\\Gamma(k/2)2^{k/2}} x^{(k/2)-1} e^{-x/2}\n\\tag{1.11}\\]\n\n\n\n\n\n\n\n\nFigura 1.9: Distribuição chi-quadrado com \\(k\\) graus de liberdade\n\n\n\n\n\nPara obter um gráfico da fdp da distribuição \\(\\chi^2\\) pode-se utilizar um código similar ao que segue.\n\ndf &lt;- data.frame(\n  x = rep(seq(0, 20, length = 500), 5),\n  y = c(dchisq(seq(0, 20, length = 500), 1),\n        dchisq(seq(0, 20, length = 500), 2),\n        dchisq(seq(0, 20, length = 500), 3), \n        dchisq(seq(0, 20, length = 500), 5),\n        dchisq(seq(0, 20, length = 500), 9)),\n  k = factor(rep(c(1, 2, 3, 5, 9), each = 500))\n)\n\nggplot(df, aes(x, y, color = k)) + \n  geom_line() +\n  scale_color_manual(values = c(\"1\" = \"darkgreen\", \n                              \"2\" = \"blue\",\n                              \"3\" = \"red\",\n                              \"5\" = \"orange\", \n                              \"9\" = \"purple\"),\n                    labels = c(\"k=1\", \"k=2\", \"k=3\", \"k=5\", \"k=9\")) +\n  labs(x = \"x\", y = \"densidade\", color = NULL) +\n  coord_cartesian(ylim = c(0, 0.5))\n\nPara obter uma determinada probabilidade à esquerda de um determinado valor na distribuição Chi-quadrado, pode-se utilizar o comando pchisq(), conforme segue.\n\n# probabilidade à esquerda de x = 5\n# na distribuição Chi-quadrado com 3 graus de liberdade\n# lower.tail = TRUE indica P(X &lt;= x)\npchisq(5, 3, lower.tail=TRUE)\n\n[1] 0.8282029\n\n\nCaso o analista deseje obter a probabilidade à direita do valor de interesse, deve-se utilizar o argumento lower.tail = FALSE.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#distribuição-t-de-student",
    "href": "01-Dists.html#distribuição-t-de-student",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.4 Distribuição t de Student",
    "text": "1.4 Distribuição t de Student\nNem sempre é possível garantir que a população de origem de uma determinada amostra coletada de uma va de interesse é normalmente distribuída, especialmente quando o tamanho amostral é limitado. Tomando uma amostra aleatória \\(x_1, x_2, ..., x_n\\) de uma distribuição \\(N(\\mu,\\sigma^2)\\), a quantidade\n\\[\n  \\frac{\\bar{x}- \\mu}{s / \\sqrt{n}} \\sim t_{n-1}\n\\]\nsegue a distribuição \\(t\\) de Student com \\(n-1\\) graus de liberdade. A função densidade de probabilidade da distribição \\(t\\) de Student, com \\(p=n-1\\) graus de liberdade, é exposta na Equação 1.12. A Figura 1.10 expõe a variação no formato da função com a variação no número de graus de liberdade da distribuição \\(t\\). Pode-se observar que à medida que \\(p=n-1\\) aumenta, a distribuição se aproxima da normal padrão. Neste sentido, muitos pesquisadores admitem que em procedimentos de inferência com amostras com \\(n \\geq 30\\), pode-se utilizar a distribuição \\(z \\sim N(0,1)\\).\n\\[\n  f(t) = \\frac{\\Gamma(\\frac{p-1}{2})}{\\Gamma(\\frac{p}{2})}\\frac{1}{p\\pi^{1/2}}\\frac{1}{(1+t^2/p)^{(p+1)/2}}\n\\tag{1.12}\\]\n\n\n\n\n\n\n\n\nFigura 1.10: Distribuição t de Student e normal padrão\n\n\n\n\n\nA distribuição t, assim como a normal é simétrica em relação à média, tem domínio \\(t \\in (-\\infty, +\\infty)\\), sendo, portanto, assíntota ao eixo horizontal.\nPara encontrar uma determinada probabilidade à esquerda de um valor de interesse da distribuição \\(t\\) com \\(\\nu=n-1\\) graus de liberdade pode-se utilizar no R o comando pt(), conforme segue.\n\n# Probabilidade à esquerda do valor t = 2, com n-1 = 19\npt(q = 2, df = 19)\n\n[1] 0.969999\n\n# Probabilidade à direita do valor t = 2, com n-1 = 19\npt(q = 2, df = 19, lower.tail = FALSE)\n\n[1] 0.03000102\n\n# Probabilidade entre t=-2 e t=2, com n-1 = 9\npt(q = 2, df = 9) - pt(q = -2, df = 9)\n\n[1] 0.9234472\n\n\nDe outra forma, para se encontrar o valor \\(t\\) de interesse considerando uma determinada probabilidade, deve-se utilizar no R o comando qt(), conforme à seguir.\n\n# valor t para a probabilidade acumulada à esquerda de 0,9 com n-1 = 29\nqt(p = 0.8, df = 29)\n\n[1] 0.854192\n\n# pode-se fornecer um vetor de probabilidades como argumento\nqt(p = c(0.9, 0.925, 0.95, 0.975), df = 29)\n\n[1] 1.311434 1.478705 1.699127 2.045230\n\n\nPara obter um gráfico da fdp da distribuição \\(t\\) pode-se utilizar um código similar ao que segue.\n\n# Criando o dataframe para o gráfico\ndf &lt;- data.frame(\n  x = seq(from = -5, to = 5, length = 500),\n  y = dt(seq(from = -5, to = 5, length = 500), df = 29)\n)\n\n# Criando dataframe para a área sombreada\ndf_area &lt;- df %&gt;% \n  filter(x &lt;= -2)\n\n# Criando o gráfico com ggplot2\nggplot(df, aes(x = x, y = y)) +\n  # Adicionando a área sombreada\n  geom_area(data = df_area, fill = \"lightblue\", color = \"blue\", alpha = 0.7) +\n  # Adicionando a linha da distribuição\n  geom_line(color = \"blue\", linewidth = .8) +\n  # Adicionando rótulos\n  labs(\n    x = \"t\",\n    y = \"densidade\" #,\n    # title = \"Distribuição t com 29 graus de liberdade\",\n    # subtitle = \"Área à esquerda de t = -2 destacada\"\n  ) +\n  # Ajustando limites do eixo y\n  coord_cartesian(ylim = c(0, max(df$y) * 1.05)) +\n  # Adicionando uma linha vertical em t = -2\n  geom_vline(xintercept = -2, linetype = \"dashed\", color = \"darkblue\", alpha = 0.7)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#distribuição-f-de-fisher-snedecor",
    "href": "01-Dists.html#distribuição-f-de-fisher-snedecor",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.5 Distribuição F de Fisher-Snedecor",
    "text": "1.5 Distribuição F de Fisher-Snedecor\nA distribuição F é utilizada para descrever a razão entre vas que seguem a distribuição chi-quadrado, isto é, a razão entre variâncias. Sejam duas amostras aleatórias \\(x_1, x_2, ..., x_n\\) e \\(y_1, y_2, ..., y_m\\) retiradas, respectivamente de populações normais \\(N(\\mu_x,\\sigma_x^2)\\) e \\(N(\\mu_y,\\sigma_y^2)\\). Pode ser de interesse inferir sobre a razão entre as variâncias populacionais, \\(\\sigma_x^2 / \\sigma_y^2)\\), a partir de estimativas amostrais, \\(s_x^2 / s_y^2)\\). A quantidade\n\\[\n  \\frac{s_x^2 / \\sigma_x^2}{s_y^2 / \\sigma_y^2} \\sim F_{n-1,m-1}\n\\]\nsegue a distribuição \\(F\\) de Fisher-Snedecor com \\(n-1\\) e \\(m-1\\) graus de liberdade. A razão entre variâncias pode seguir esta distribuição mesmo se as populações de origem apresentam desvios de normalidade. Analogamente à distribuição \\(t\\), a distribuição \\(F\\) deriva da normal, sendo um caso específico da distribuição \\(F\\) derivado da distribuição \\(t\\). A distribuição \\(F\\) apresenta domínio \\(F \\in [0, +\\infty)\\), por descrever a razão entre variâncias, sendo também assíntota. A Equação 1.13 descreve a função densidade de probabilidade F, com \\(p=n-1\\) graus de liberdade e \\(q=m-1\\) graus de liberdade. Esta fdp é plotada com variação dos graus de liberdade na Figura 1.11.\n\\[\n  f(X) = \\frac{\\Gamma(\\frac{p+q}{2})}{\\Gamma(\\frac{p}{2})\\Gamma(\\frac{q}{2})}(\\frac{p}{q})^{p/2}\\frac{x^{(p/2)-1}}{[1+(p/q)x]^{(p+q)/2}}\n\\tag{1.13}\\]\n\n\n\n\n\n\n\n\nFigura 1.11: Distribuição F com n-1,m-1 graus de liberdade\n\n\n\n\n\nPara obter a probabilidade associada a um determinado valor de interesse da distribuição \\(F\\) com \\(p\\) e \\(q\\) graus de liberdade, pode-se utilizar a sintaxe que segue.\n\n# probabilidade à direita de 2.13 na distribuição F\n# com p = 1 e q = 8 graus de liberdade\npf(2.13, df1 = 2, df2 = 8, lower.tail = FALSE)\n\n[1] 0.1813001\n\n\nDe outra forma, pode ser interessante obter o valor associado a uma determinada probabilidade de interesse.\n\n# Valor associado à probabilidade de 0.05\n# na calda direita, com p = 1 e q = 8 graus de liberdade \nqf(0.05, 1, 8, lower.tail = F)\n\n[1] 5.317655\n\n\nO código à seguir serve para obtenção da fdp da distribuição \\(F\\).\n\n# Sequência para o eixo horizontal\nx &lt;- seq(from = 0, to = 10, length = 500)\n\n# Criando o data frame com a distribuição F(1,8)\ndados &lt;- data.frame(\n  x = x,\n  y = df(x, 1, 8)\n)\n\n# Valor crítico F para alpha = 0.05\nf_crit &lt;- qf(0.05, 1, 8, lower.tail = FALSE)\n\n# Dados para a região crítica (área verde clara)\nx_critico &lt;- seq(f_crit, 10, length = 500)\ndados_critico &lt;- data.frame(\n  x = x_critico,\n  y = df(x_critico, 1, 8)\n)\n\n# Criando o gráfico com ggplot2\nggplot() +\n  # Plotando a curva da distribuição F\n  geom_line(data = dados, aes(x = x, y = y), linewidth = 1) +\n  \n  # Adicionando a área sombreada para a região crítica\n  geom_area(data = dados_critico, aes(x = x, y = y), fill = \"lightgreen\", alpha = 0.7) +\n  \n  # Configurando os limites dos eixos e os rótulos\n  scale_y_continuous(limits = c(0, 0.5)) +\n  labs(\n    x = \"x\",\n    y = \"densidade\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#teste-t-para-média-de-uma-amostra",
    "href": "01-Dists.html#teste-t-para-média-de-uma-amostra",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.6 Teste t para média de uma amostra",
    "text": "1.6 Teste t para média de uma amostra\nAinda em relação a amostra aleatória de \\(n\\) observações, \\(x_1, x_2, ..., x_n\\), retirada de uma va que segue a distribuição normal, um problema comum de decisão é o teste de hipóteses. Neste tipo de teste pode-se inferir, por exemplo, se o parâmetro em estudo é igual a um determinado valor de interesse ou não. No caso da média de uma determinada amostra de interesse, o teste \\(t\\) pode ser utilizado.\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  6.134   7.431   8.484   8.784  10.039  12.076 \n\n\n\n\n\n\n\nBox-plot de Ront \\([\\mu m]\\)\n\n\n\n\nPara responder à pergunta do experimentador, deve-se formular as hipóteses a serem testadas, sendo \\(H_0\\) a hipótese nula e \\(H_1\\) a hipótese alternativa, conforme segue.\n\\[\\begin{equation}\n  H_0: \\mu = 10\n\\end{equation}\\] \\[\\begin{equation}\n  H_0: \\mu &lt; 10\n\\end{equation}\\]\nO valor de interesse testado na hipótese é denotado \\(\\mu_0\\). Uma vez que o experimentador já coletou a amostra para testar sua hipótese, pode-se agora calcular a estatística do teste. Como ele coletou uma amostra de tamanho pequeno, além de a variância populacional ser desconhecida, deve-se utilizar o teste \\(t\\) para uma amostra, baseado na distribuição \\(t\\) de Student. A estatística do teste para testar uma hipótese sobre a média de uma amostra neste caso é apresentada na Equação @ref(eq:ttest). Por este cálculo padroniza-se a distribuição amostral obtida em relação ao valor hipotético, havendo mais evidência para rejeição da hipótese nula, quanto maior for o desvio negativo de \\(t_0\\) em relação a zero. Deve-se recordar que, pelo TCL, o desvio-padrão da média é \\(s_{\\bar{x}} = s/\\sqrt{n}\\).\n\\[\\begin{equation}\n  t_0 = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\n  (\\#eq:ttest)\n\\end{equation}\\]\nPara o exemplo esta estatística pode ser facilmente calculada como segue.\n\n\n[1] -2.211601\n\n\nPara julgar se a hipótese nula deve ser rejeitada em favor da alternativa ou não, deve-se definir uma região crítica ou região de rejeição de \\(H_0\\). Para tal, deve-se definir um nível de significância \\(\\alpha\\) de interesse. O nível de significância consiste em uma probabilidade que se assume ao testar a hipótese. Quanto menor, menor a probabilidade de cometer o erro de rejeitar a hipótese nula caso esta seja verdadeira. Neste caso, maior o nível de confiança do teste, \\(\\gamma = 1 - \\alpha\\). Entretanto, quanto menor o nível de significância \\(\\alpha\\), mais difícil é a rejeição da hipótese nula. É comum adotar-se em pesquisas \\(\\alpha = 0,05\\), mas alguns pesquisadores mais criteriosos costumam adotar \\(\\alpha = 0,01\\), ou valores inferiores. A Figura @ref(fig:regcrit) ilustra a distribuição \\(t\\) com 11 graus de liberdade e região crítica em vermelho para o teste em questão, considerando \\(\\alpha = 0,05\\).\n\n\n\n\n\nRegião crítica para o teste t, com \\(\\alpha = 0,05\\), \\(n-1=11\\) graus de liberdade\n\n\n\n\nConsiderando a distribição \\(t\\) com 11 graus de liberdade, pode-se obter o valor \\(t_\\alpha\\), o qual garante uma probabilidade igual a 0,05 à sua esquerda, conforme segue. Este valor \\(t_\\alpha\\) é comumente conhecido como valor crítico.\n\n\n[1] -1.795885\n\n\nPara decidir deve-se comparar o valor da estatística do teste com o valor crítico. Neste caso, como a hipótese alternativa é \\(H_0: \\mu &lt; \\mu_0\\), se \\(t_0 &lt; t_\\alpha\\), rejeita-se \\(H_0\\) em favor de \\(H_1\\). Logo, neste caso como \\(t_0 = -2,21 &lt; -1,796 = t_\\alpha\\), rejeita-se a hipótese nula, com \\(\\alpha = 0,05\\) de significância, podendo-se concluir que a média da circularidade total \\(Ron_t\\) é menor que \\(10 \\mu m\\).\nA função t.test() do R pode ser utilizada para realizar o teste \\(t\\) para uma amostra. Para o caso do Exemplo @ref(exm:t1), pode-se utilizar sintaxe que segue.\n\n\n\n    One Sample t-test\n\ndata:  Ront\nt = -2.2116, df = 11, p-value = 0.02454\nalternative hypothesis: true mean is less than 10\n95 percent confidence interval:\n     -Inf 9.771407\nsample estimates:\nmean of x \n 8.783892 \n\n\nO resultado fornece o valor de \\(t_0\\) calculado, o número de graus de liberdade do teste, e o p-valor (p-value), que consiste na probabilidade associada ao valor calculado. O resultado obtido deixa claro na saída a hipótese testada, além de fornecer um intervalo de confiança associado ao teste realizado e a estimativa pontual do parâmetro testado, isto é, a média. O intervalo de confiança consiste em limites de confiança para média, neste caso apenas o inferior, uma vez que foi realizado o teste unilateral à esquerda. A média esta acima deste limite com \\(\\gamma = 1 - \\alpha = 0,95\\) de confiança.\nNo teste unilateral à esquerda realizado o limite superior de confiança é calculado conforme Equação @ref(eq:liminf). Para o Exemplo @ref(exm:t1) este limite é de \\(9,77\\), indicando que a média é menor que este valor com \\(\\gamma = 0,95\\) de confiança.\n\\[\\begin{equation}\n  \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}} &lt; t_{(\\alpha,n-1)}\n\\end{equation}\\] \\[\\begin{equation}\n  \\mu &lt; \\bar{x} + t_{(1-\\alpha,n-1)}\\frac{s}{\\sqrt{n}}\n(\\#eq:liminf)\n\\end{equation}\\]\nSendo o p-valor a probabilidade associada ao valor calculado, ele também pode ser utilizado na tomada de decisão em inferência. A Figura @ref(fig:pvaluet) ilustra o p-valor, sendo neste caso a área sob a curva à esquerda do valor calculado \\(t_0\\), isto é \\(p-valor = P(t &lt; t_0) = \\Phi(t_0)\\). Pode-se constatar que, para hipótese unilateral à esquerda, \\(H_1: \\mu &lt; \\mu_0\\), \\(t_0 &lt; t_\\alpha\\) implica em \\(p-valor &lt; \\alpha\\). Quanto menor o p-valor, maior a evidência na rejeição da hipótese nula. Caso o analista queira obter o p-valor utilizando a função pt base do R, pode-se utilizar o código à seguir.\n\n\n[1] 0.02454049\n\n\nA vantagem de tomar a decisão considerando o p-valor é que para um \\(\\alpha\\) fixo, basta comparar tais probabilidades para tomar a decisão. Se o experimentador deseja, entretanto, tomar a decisão considerando o valor \\(t_0\\), ele deve conhecer o valor crítico \\(t_\\alpha\\) e este muda conforme o número de graus de liberdade associado ao teste. Deve-se atentar para o fato de que se o valor calculado \\(t_0\\) cresce à medida que o tamanho amostral aumenta, o p-valor diminui no mesmo sentido. Deste modo, um pesquisador mal intencionado pode manipular seu estudo aumentado o tamanho amostral para rejeitar a hipótese nula, ou de outra forma, mudar o nível de significância para respaldar as conclusões almejadas.\n\n\n\n\n\np-valor associado ao valor calculado \\(t_0\\)\n\n\n\n\nO teste de hipóteses para média de uma amostra, considerando variância populacional desconhecida e amostras pequenas, pode ser realizado utilizando-se a distribuição \\(t\\) de Student. Além da hipótese alternativa unilateral à esquerda, há outras duas possibilidades a serem elucidadas, além de pressuposições a serem observadas para condução do teste. Antes, porém, é razoável apresentar conceitos relacionados aos erros que podem ser cometidos ao se testar uma hipótese, além de como planejar o teste de forma a minimizar estes erros.\nUm analista que deseja testar uma determinada hipótese não conhece a realidade acerca do parâmetro que deseja testar a partir de uma amostra limitada. Neste sentido, em inferência há dois tipos de erros que podem ser cometidos. O primeiro, chamado de erro do tipo I, consiste na rejeição da hipótese nula \\(H_0\\), quando esta é verdadeira. A probabilidade de ocorrência deste erro consiste no próprio nível de significância \\(\\alpha\\), sendo este erro denotado utilizando probabilidade condicional, conforme segue.\n\\[\\begin{equation}\n  \\alpha = P(Erro \\: tipo \\: I) = P(rejeitar \\: H_0 | H_0 \\: é \\: verdadeira)\n\\end{equation}\\]\nAo se adotar portanto, um determinado nível de significância \\(\\alpha\\), assume-se o risco de cometer o erro do tipo I com probabilidade \\(\\alpha\\).\nO erro do tipo II, denotado \\(\\beta\\) consiste na probabilidade de não rejeitar \\(H_0\\), dado que \\(H_0\\) é falsa. Este erro é denotado conforme segue.\n\\[\\begin{equation}\n  \\beta = P(Erro \\: tipo \\: II) = P(não \\: rejeitar \\: H_0 | H_0 \\: é \\: falsa)\n\\end{equation}\\]\nConsiderando ainda o Exemplo @ref(exm:t1), com teste unilateral à esquerda, isto é, \\(H_1: \\mu &lt; \\mu_0\\), supondo que a hipótese nula seja falsa a média verdadeira pode ser descrita como \\(\\mu = \\mu_0 - \\delta\\), \\(\\delta &gt; 0\\). Logo, somando e subtraindo \\(\\delta\\) na estatística do teste e sabendo que em uma amostra bem coletada \\(\\bar{X} \\rightarrow \\mu_0 - \\delta\\), tem-se:\n\\[\\begin{equation}\nt_0 = \\frac{\\bar{x}-\\mu_0 + \\delta}{s/\\sqrt{n}} -\\frac{\\delta}{s/\\sqrt{n}}\n\\end{equation}\\] \\[\\begin{equation}\nt_0 = \\underbrace{\\frac{\\bar{x}-(\\mu_0 - \\delta)}{s/\\sqrt{n}}}_{0, \\: pois \\: \\bar{x} \\rightarrow \\mu_0 - \\delta} -\\frac{\\delta \\sqrt{n}}{s}\n\\end{equation}\\]\nLogo, se \\(H_0\\) é falsa, \\(t_0\\) segue a distribuição \\(t\\) não central, com \\(n-1\\) graus de liberdade e parâmetro de não centralidade \\(-\\delta \\sqrt{n}/s\\), conforme segue.\n\\[\\begin{equation}\nt_0 \\sim t(n-1,-\\frac{\\delta \\sqrt{n}}{s})\n  (\\#eq:t0)\n\\end{equation}\\]\nEste teste unilateral à esquerda com a hipótese nula falsa pode ser ilustrado conforme a Figura @ref(fig:pwrt).\n\n\n\n\n\nErro do tipo II, teste t unilateral à esquerda\n\n\n\n\nTomando a curva sob a hipótese nula \\(H_0\\), na Figura @ref(fig:pwrt), pode-se definir \\(\\beta\\) como a probabilidade de o valor calculado \\(t_0\\) estar à direita do valor \\(t\\) ilustrado, sendo este t relacionado à curva de \\(H_0\\), isto é, \\(-t_{(\\alpha,n-1)}\\), negativo, uma vez que está à esquerda de \\(\\mu_0\\).\n\\[\\begin{equation}\n\\beta = P(t_0 \\geq -t_{(\\alpha,n-1)}|H_0)\n\\end{equation}\\]\nTomando o valor de \\(t_0\\) considerando, a existência de um deslocamento na média à esquerda, conforme a Equação @ref(eq:t0), tem-se:\n\\[\\begin{equation}\n\\beta = P(-\\frac{\\delta \\sqrt{n}}{s} \\geq -t_{(\\alpha,n-1)}|H_0)\n\\end{equation}\\] \\[\\begin{equation}\n\\beta = P(-\\frac{\\delta \\sqrt{n}}{s} +t_{(\\alpha,n-1)} \\geq 0 |H_0)\n\\end{equation}\\] \\[\\begin{equation}\n\\beta = 1 - P(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)} \\leq 0 |H_0)\n\\end{equation}\\] \\[\\begin{equation}\n\\beta = 1 - \\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)})\n  (\\#eq:beta)\n\\end{equation}\\]\nDe modo análogo, pode-se definir \\(\\beta\\) considerando a curva sob a hipótese alternativa \\(H_1\\), na Figura @ref(fig:pwrt), que neste suposto caso corresponde à realidade.\n\\[\\begin{equation}\n\\beta = 1 - \\Phi(t_{(\\beta,n-1)})\n  (\\#eq:beta2)\n\\end{equation}\\]\nTomando as Equações @ref(eq:beta) e @ref(eq:beta2), pode-se derivar o tamanho amostral necessário para garantir um erro do tipo II mínimo, dado o nível de significância \\(\\alpha\\) adotado, o desvio-padrão amostral \\(S\\) e o deslocamento \\(\\delta\\) que deseja-se detectar no teste, conforme Equação @ref(eq:npwr).\n\\[\\begin{equation}\n1 - \\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)}) = 1 - \\Phi(t_{(\\beta,n-1)})\n\\end{equation}\\] \\[\\begin{equation}\n\\Phi(\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)}) = \\Phi(t_{(\\beta,n-1)})\n\\end{equation}\\] \\[\\begin{equation}\n\\frac{\\delta \\sqrt{n}}{s} -t_{(\\alpha,n-1)} = t_{(\\beta,n-1)}\n\\end{equation}\\] \\[\\begin{equation}\nn = \\left[\\frac{(t_{(\\alpha,n-1)}+t_{(\\beta,n-1)})s}{\\delta}\\right]^2\n  (\\#eq:npwr)\n\\end{equation}\\]\nPela Equação na Figura @ref(eq:npwr) pode-se constatar que quanto maior o desvio-padrão amostral, quanto menor o deslocamento da média a ser detectado e quanto menor o nível de significância adotado, maior será o tamanho amostral necessário para manter o erro do tipo II em um valor mínimo almejado. Enquanto o erro do tipo I, \\(\\alpha\\), depende da escolha do analista, o erro do tipo II depende de como o teste foi planejado, isto é, qual o tamanho amostral adotado, considerando determinada variabilidade amostral e determinado deslocamento a ser detectado. O erro do tipo I é mais grave que o erro do tipo II, por isso, geralmente recomenda-se um valor mais baixo deste, por exemplo \\(\\alpha = 0,05\\). Logicamente também é desejável um erro do tipo II baixo, entretanto, para determinados valores de \\(s\\) e \\(\\delta\\), pode ser necessário um tamanho amostral muito alto para minimizar \\(\\beta\\), aumentando os custos experimentais.\nA probabilidade \\(1 -\\beta\\) ilustrada na Figura @ref(fig:pwrt) é chamada de poder do teste. O poder do teste consiste na capacidade do teste estatístico de detectar um deslocamento na média, isto é, de rejeitar a hipótese nula, quando ela é falsa, não cometendo o erro do tipo II. A Figura @ref(fig:erros) apresenta as possibilidades quanto a decisão em testes de hipóteses em relação à realidade, que supõe-se desconhecida por parte do analista. Ao recomendar \\(\\beta =0,2\\), procura-se um poder do teste \\(1- \\beta = 0,8\\).\n\n\n\n\n\nErros em testes de hipóteses\n\n\n\n\nPode-se utilizar o comando power.t.test para calcular o tamanho amostral, dado um poder do teste, \\(1-\\beta\\), desejado conforme segue. Com este comando pode-se também obter o poder do teste, dado um tamanho amostral disponível. Pode-se constatar que, para garantir um poder do teste \\(1-\\beta = 0,8\\) para o Exemplo @ref(exm:t1) detectar uma diferença de \\(2 \\mu m\\), seria necessário coletar uma amostra com 8 observações.\n\n\n\n     One-sample t test power calculation \n\n              n = 7.168914\n          delta = 2\n             sd = 1.904829\n      sig.level = 0.05\n          power = 0.8\n    alternative = one.sided\n\n\nComo no teste realizado no Exemplo @ref(exm:t1) foi utilizado \\(n=12\\), para detectar uma diferença menor, \\(\\delta = 1,22\\), o poder do teste foi menor, \\(1-\\beta = 0,67\\), porém suficiente, uma vez que a hipótese nula foi rejeitada. Para obter este resultado no R, deve-se usar a sintaxe à seguir.\n\n\n\n     One-sample t test power calculation \n\n              n = 12\n          delta = 1.216108\n             sd = 1.904829\n      sig.level = 0.05\n          power = 0.6656294\n    alternative = one.sided\n\n\nÉ interessante avaliar graficamente o poder do teste em função do tamanho amostral, conforme Figura @ref(fig:pwrcurve) e código relacionado à seguir.\n\n\n\n\n\nPoder do teste em função do tamanho amostral\n\n\n\n\nDe forma análoga, pode ser interessante saber o poder do teste, \\(1-\\beta\\), em função do deslocamento na média (efeito), a ser detectado. Pode-se traçar no mesmo gráfico curvas considerando tamanhos amostrais distintos. A Figura @ref(fig:pwrcurve2) ilustra curvas de poder do teste em função do efeito a ser detectado, com código relacionado à seguir.\n\n\n\n\n\nPoder do teste em função do deslocamento na média\n\n\n\n\nTomando as curvas na Figura @ref(fig: pwrcurve2) pode-se constatar que quanto menor o efeito a ser detectado, menor o poder do teste e, consequentemente, maior a probabilidade de erro do tipo II, para um tamanho amostral fixo. De outra forma, fixando o deslocamento a ser detectado, quanto maior o tamanho amostral, maior o poder do teste.\nO Exemplo @ref(exm:t1) apresentou um teste unilateral à esquerda, entretanto há outras possibilidades. A Figura @ref(fig:hip) ilustra, da esquerda para direita os testes unilateral à esquerda, unilateral à direita e bilateral. Neste último o analista deseja apenas contestar se a média \\(\\mu\\) é diferente do valor de referência \\(\\mu_0\\), sendo a região de rejeição de \\(H_0\\) dividida pelas duas caldas, cada uma com área igual a \\(\\alpha/2\\). Para \\(H_1: \\mu &lt; \\mu_0\\), rejeita-se \\(H_0\\) se \\(t_0&lt;-t_{(\\alpha,n-1)}\\). Já para \\(H_1: \\mu &gt; \\mu_0\\), rejeita-se \\(H_0\\) se \\(t_0&gt;t_{(\\alpha,n-1)}\\). Por fim, para \\(H_1: \\mu \\ne \\mu_0\\), rejeita-se \\(H_0\\) se \\(|t_0|&gt;t_{(\\alpha/2,n-1)}\\).\n\n\n\n\n\nTipos de hipóteses\n\n\n\n\nA Figura @ref(fig:pvalue) ilustra a interpretação do p-valor para os três tipos de hipóteses. Para qualquer caso, a interpretação utilizando o p-valor é a mesma. Se \\(p-valor &lt; \\alpha\\), rejeita-se \\(H_0\\) em favor de \\(H_1\\).\n\n\n\n\n\nInterpretação do p-valor\n\n\n\n\nNo caso do teste bilateral, com \\(H_1: \\mu \\ne \\mu_0\\), o intervalo de confiança associado ao teste de hipótese para média com \\(\\gamma\\) de confiança é obtido conforme Equação @ref(eq:icmedia).\n\\[\\begin{equation}\n\\text{IC[$\\gamma=1-\\alpha$] p/ $\\mu$} : [\\bar{X} - t_{(\\alpha/2,n-1)}\\frac{s}{\\sqrt{n}};\\bar{X} + t_{(1-\\alpha/2,n-1)}\\frac{s}{\\sqrt{n}}]\n(\\#eq:icmedia)\n\\end{equation}\\]\nPara os casos onde deseja-se a hipótese para média de forma bilateral, o tamanho amostral para um determinado poder do teste deve ser calculado conforme Equação @ref(eq:npwrbil), a seguir.\n\\[\\begin{equation}\nn = \\lbrack\\frac{(t_{\\alpha/2,n-1}+t_{\\beta,n-1})s}{\\delta}\\rbrack^2\n  (\\#eq:npwrbil)\n\\end{equation}\\]\nPara utilizar o teste \\(t\\) para a média de uma amostra, é desejável que a amostra obtida seja normalmente distribuída. Para testar a normalidade dos dados, pode-se utilizar o teste de Shapiro. A hipótese nula do teste de normalidade \\(H_0\\) é que os dados são normalmente distribuídos. Para o exemplo @ref(exm:t1), pode-se utilizar a linha de código que segue.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  Ront\nW = 0.9518, p-value = 0.6634\n\n\nComo \\(p-valor &gt; \\alpha\\), não se rejeita a hipótese nula \\(H_0\\), concluindo-se que os dados de circularidade seguem a distribuição normal. Pode-se ilustrar o teste de normalidade através do gráfico quantil-quantil. Este gráfico plota as \\(n\\) observações ordenadas em função de \\(n\\) quantis teóricos da distribuição normal-padrão \\(z \\sim N(0,1)\\). Uma boa aproximação dos pontos à reta, demonstra uma boa aproximação dos dados à distribuição normal. A Figura @ref(fig:qqt1) expõe o gráfico quantil-quantil para o exemplo @ref(exm:t1).\n\n\n\n\n\nGráfico para Ront",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#teste-z-para-média-de-uma-amostra",
    "href": "01-Dists.html#teste-z-para-média-de-uma-amostra",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.7 Teste z para média de uma amostra",
    "text": "1.7 Teste z para média de uma amostra\nNos raros casos onde a variância populacional é conhecida, pode-se utilizar a distribuição normal padrão para testar hipóteses sobre a média de uma população a partir de uma amostra disponível. Recomenda-se também para um tamanho amostral \\(n\\) suficientemente grande, utilizar este procedimento, visto que a distribuição \\(t\\) se aproxima da distribuição \\(z\\) à medida que \\(n\\) cresce. Em geral, uma amostra com tamanho a partir de \\(n = 30\\) é suficiente. Para realizar o teste \\(z\\) para média de uma amostra, deve-se calcular a estatística do teste conforme Equação @ref(eq:ztest).\n\\[\\begin{equation}\n  Z_0 = \\frac{\\bar{X}-\\mu_0}{\\sigma/\\sqrt{n}}\n  (\\#eq:ztest)\n\\end{equation}\\]\nPara planejar este teste considerou-se a necessidade de detectar uma diferença de 0,5 HRC na dureza, supondo um desvio-padrão de 1 HRC, baseado em dados históricos. O analista requer um poder mínimo \\(1-\\beta= 0,8\\). Pode-se utilizar o comando power.z.test do pacote asbio. O argumento test = \"two.tail\", é usado para o teste bilateral, \\(H_1: \\mu \\ne \\mu_0\\). Pelos resultados da análise, é necessária uma amostra com \\(n = 32\\) observações para garantir um poder do teste de 0,8. O analista considerou o tamanho amostral \\(n = 30\\) suficiente.\n\n\n$sigma\n[1] 1\n\n$n\n[1] 31.39552\n\n$power\n[1] 0.8\n\n$alpha\n[1] 0.05\n\n$effect\n[1] 0.5\n\n$test\n[1] \"two.tail\"\n\n\nAs trinta observações de dureza são expostas a seguir. Um boxplot é exposto na Figura @ref(fig:bpdureza) para ilustrar a variabilidade dos dados.\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  56.00   57.25   58.00   57.73   58.25   58.75 \n\n\n\n\n\n\n\nBoxplot para dureza\n\n\n\n\nO teste de normalidade é realizado à seguir, indicando não haver indícios para rejeição da hipótese nula de normalidade da variável dureza, \\(p-valor &gt; \\alpha\\). O gráfico q-q da Figura @ref(fig:qqdureza) confirma a normalidade da dureza.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  dureza\nW = 0.9363, p-value = 0.07236\n\n\n\n\n\n\n\nBoxplot para dureza\n\n\n\n\nAs hipóteses para o exemplo @ref(exm:z1) são expostas à seguir, onde \\(\\mu_0 = 55\\). O teste realizado é, portanto, bilateral. Para testar tais hipóteses, uma vez que tem-se um tamanho amostral considerável, pode-se utilizar do teste \\(Z\\) para média amostral. A função ZTest() do pacote DescTools é utilizada.\n\\[\\begin{equation}\n  H_0: \\mu = \\mu_0\n\\end{equation}\\] \\[\\begin{equation}\n  H_1: \\mu \\ne \\mu_0\n\\end{equation}\\]\n\n\n\n    One Sample z-test\n\ndata:  dureza\nz = 19.761, Std. Dev. Population = 0.7553, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 55\n95 percent confidence interval:\n 57.45473 57.99527\nsample estimates:\nmean of x \n   57.725 \n\n\nPelos resultados obtidos, rejeita-se a hipótese nula de que a dureza média é igual a 55 HRC. Apesar de a hipótese alternativa ser \\(H_1: \\mu \\ne 55\\), como \\(z_0 = 19.761\\) e pelos limites de confiança serem ambos maiores que 55, pode-se constatar especificamente que a média é maior que 55 HRC.\nConsiderando o tamanho amostral, desvio-padrão amostral e efeito detectado, o poder do teste pode ser calculado com a sintaxe à seguir. Portanto, o teste apresentou poder unitário, com probabilidade nula de erro do tipo II. Uma alta razão entre o efeito (deslocamento na média) a ser detectado e o desvio-padrão da variável estudada aumenta o poder do teste.\n\n\n$sigma\n[1] 0.7552974\n\n$n\n[1] 30\n\n$power\n[1] 1\n\n$alpha\n[1] 0.05\n\n$effect\n[1] 2.725\n\n$test\n[1] \"two.tail\"\n\n\nA curva para o poder do teste Exemplo @ref(exm:z1) é exposta na Figura @ref(fig:poderz1). Pode-se observar que para um efeito superior a 0,65 é possível realizar o teste com \\(1-\\beta = 1\\).\n\n\n\n\n\nCurva de poder do teste para média da dureza",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#teste-t-para-médias-de-duas-amostras-independentes",
    "href": "01-Dists.html#teste-t-para-médias-de-duas-amostras-independentes",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.8 Teste t para médias de duas amostras independentes",
    "text": "1.8 Teste t para médias de duas amostras independentes\nEm diversas situações é de interesse do pesquisador realizar inferência sobre a média de duas amostras. Este tipo de teste pode ser realizado para comparar a diferença entre médias de dois tratamentos em uma resposta de interesse. O teste baseado na distribuição \\(t\\) pode ser utilizado para amostras pequenas quando as variâncias populacionais são desconhecidas. Há testes distintos para a diferença entre médias para amostras com variâncias iguais e para amostras com variâncias diferentes.\nAntes de entender os testes para média de duas amostras, é importante entender o que significa a independência e como testá-la estatisticamente. Duas amostras são ditas independentes quando são originadas de populações distintas. Uma forma de quantificar a dependência entre duas amostras é através da covariância e da correlação. Por estas medidas pode-se quantificar se a dependência entre duas variáveis de interesse é forte ou fraca. A covariância entre duas variáveis \\(xX\\) e \\(y\\), \\(Cov(x,y)=\\sigma_{xy}\\) pode ser definida conforme Equação @ref(eq:cov1), enquanto a correlação é definida conforme a Equação @ref(eq:cor1). Logo, pode-se constatar que a correlação é a covariância padronizada. Enquanto a covariância tem domínio em toda escala de números reais, \\(\\sigma_{xy} \\in (-\\infty,+\\infty)\\), a correlação tem domínio entre -1 e 1, \\(\\rho_{xy} \\in \\{-1,+1\\}\\), sendo mais fácil entender via correlação se o relacionamento linear é forte ou fraco.\n\\[\\begin{equation}\n  \\sigma_{xy} =  E((x_i-\\mu_x)(y_i-\\mu_y)) = E(xy) - \\mu_x\\mu_y\n  (\\#eq:cov1)\n\\end{equation}\\] \\[\\begin{equation}\n  \\rho_{xy} =  \\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}\n  (\\#eq:cor1)\n\\end{equation}\\]\nAs Figuras @ref(fig:corr), @ref(fig:corr2) e @ref(fig:corr3) são diagramas de dispersão que ilustram padrões de dependência entre variáveis. Na Figura @ref(fig:corr) as variáveis \\(x\\) e \\(y\\) apresentam correlação positiva, com \\(\\rho \\rightarrow 1\\). Já na Figura @ref(fig:corr2) as variáveis \\(x\\) e \\(y\\) apresentam correlação negativa, com \\(\\rho \\rightarrow -1\\). Por fim, na Figura @ref(fig:corr3) as variáveis \\(x\\) e \\(y\\) apresentam ausência de correlação positiva, com \\(\\rho \\rightarrow 0\\).\n\n\n\n\n\nDiagrama de dispersão entre variáveis X e Y com correlação positiva\n\n\n\n\n\n\n\n\n\nDiagrama de dispersão entre variáveis X e Y com correlação negativa\n\n\n\n\n\n\n\n\n\nDiagrama de dispersão entre variáveis X e Y não correlcionadas\n\n\n\n\nA correlação amostral \\(r_{xy}=\\hat{\\rho}\\) entre duas variáveis \\(x\\) e \\(y\\) pode ser calculada conforme Equação @ref(eq:cor), ou pela Equação @ref(eq:cor2), onde \\(S_{XY} = \\hat{\\sigma}_{xy}\\) é a covariância amostral entre as variáveis \\(x\\) e \\(y\\) enquanto \\(S_{x}\\) e \\(S_{y}\\) são os desvios-padrões amostrais destas variáveis. A covariância amostral entre \\(x\\) e \\(y\\) pode ser estimada conforme Equação @ref(eq:cov).\n\\[\\begin{equation}\n  r_{xy} = \\frac{\\sum_{i}(x_i-\\bar{x})\\sum_{i}(y_i-\\bar{y})}{\\sqrt{\\sum_{i}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i}(y_i-\\bar{y})^2}}\n  (\\#eq:cor)\n\\end{equation}\\] \\[\\begin{equation}\n  r_{xy} = \\frac{S_{xy}}{S_xS_y}\n  (\\#eq:cor2)\n\\end{equation}\\] \\[\\begin{equation}\n  S_{xy} = \\frac{\\sum_{i}(x_i-\\bar{x})\\sum_{i}(y_i-\\bar{y})}{n-1}\n  (\\#eq:cov)\n\\end{equation}\\]\nO teste de correlação de Pearson, pode ser utilizado para avaliar a significância estatística da correlação entre duas amostras. A hipótese nula do teste garante que a correlação é igual a zero, isto é, \\(H_0: \\rho=0\\). Para realizar o teste de correlação de Pearson entre a amostra de controle e a amostra tratada do Exemplo @ref(exm:t2), denotadas \\(x\\) e \\(y\\), respectivamente, pode-se utilizar a sintaxe à seguir. O teste é baseado na distribuição \\(t\\) e fornece como resultado o valor da estatística \\(t_0\\) a qual pode ser comparada com o valor crítico \\(t_{(\\alpha/2,n-2)}\\), onde \\(n = n_x + n_y\\). Se \\(t_0 &gt; t_{(\\alpha/2,n-1)}\\), rejeita-se \\(H_0\\). Considernado \\(\\alpha = 0,05\\), para \\(n = 58\\), \\(t_{(0,025,58)}=2.001717\\), qt(0.95+.05/2, 58). Logo, como \\(t_0 = 0,73203 &lt; 2.001717 = t_{(\\alpha/2,n-1)}\\), não há indícios para rejeição de \\(H_0\\), ou seja, a correlação entre as amostras é nula. A independência entre tais amostras é trivial, por terem sido retiradas de populações distintas. Entretanto é importante confirmar a independência para posteriormente realizar o teste de hipóteses para diferença entre médias das amostras adequado.\n\n\n[1] 0.1370349\n\n\n\n    Pearson's product-moment correlation\n\ndata:  X and Y\nt = 0.73203, df = 28, p-value = 0.4702\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2348276  0.4739076\nsample estimates:\n      cor \n0.1370349 \n\n\nAntes de realizar o teste \\(t\\) para averiguar a diferença entre médias entre as variáveis \\(x\\) e \\(y\\) do Exemplo @ref(exm:t2), é importante testar a homocedasticidade, isto é, a homogeneidade de variâncias entre as duas amostras. Primeiramente, é necessário organizar os dados de forma tabular utilizando o comando data.frame().\nPosteriormente, pode-se plotar alguns gráficos para visualizar a variabilidade dos dados. O pacote ggpubr() é uma boa opção. A Figura @ref(fig:bpcarbon) ilustra boxplots, enquanto a Figura @ref(fig:denscarbon) ilustra gráficos de densidade da distribuição amostral para a resistência à tração em função das amostras de controle e tratada. Em ambos os casos, pode-se constatar que a variabilidade dos dados parece similar e que a resistência média da amostra tratada é superior. Pelos gráficos de densidade, pode-se verificar que as distribuições amostrais aparentam ter normalidade. Todas estas evidências gráficas devem ser estatísticamente confirmados.\n\n\n\n\n\nBoxplots para resistância à tração das amostras de controle e tratada\n\n\n\n\n\n\n\n\n\nHistogramas para resistância à tração das amostras de controle e tratada\n\n\n\n\nO teste de homocedasticidade de Bartlett para o Exemplo @ref(exm:t2) é apresentado à seguir. A hipótese nula do teste postula a igualdade de variâncias entre as amostras, isto é, \\(H_0: \\sigma_1^2 = \\sigma_2^2\\). Pelos resultados, como \\(p-value = 0,07128 &gt; 0,05 = \\alpha\\), não se rejeita \\(H_0\\), podendo-se confirmar a homogeneidade entre as variâncias amostrais.\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  resistencia by grupo\nBartlett's K-squared = 3.2534, df = 1, p-value = 0.07128\n\n\nO teste de normalidade das duas amostras também deve ser realizado. Pode-se constatar, pelos resultados abaixo, \\(p-value&lt;\\alpha\\), que não há indícios para rejeição da hipótese nula de normalidade das amostras. A Figura @ref(fig:qq2t) ilustra os gráficos q-q para as amostras.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resistencia[grupo == \"Controle\"]\nW = 0.95678, p-value = 0.2557\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resistencia[grupo == \"Tratada\"]\nW = 0.96465, p-value = 0.4049\n\n\n\n\n\n\n\nGráficos q-q para resistência à tração das amostras controle e tratada\n\n\n\n\nA hipótese nula do teste \\(t\\) para média de duas amostras é exposta à seguir.\n\\[\\begin{equation}\nH_0: \\mu_1 = \\mu_2\n\\end{equation}\\]\nJá a hipótese alternativa pode ser bilateral, \\(\\ne\\), ou unilateral à esquerda ou a direita, conforme segue.\n\\[\\begin{equation}\nH_0: \\mu_1 \\ne \\mu_2\n\\end{equation}\\] \\[\\begin{equation}\nH_0: \\mu_1 &lt; \\mu_2\n\\end{equation}\\] \\[\\begin{equation}\nH_0: \\mu_1 &gt; \\mu_2\n\\end{equation}\\]\nA estatística do teste \\(t\\) para duas amostras com variâncias amostrais iguais é calculada conforme Equação @ref(eq:t2s), onde o desvio-padrão combinado \\(S\\) é obtido conforme a Equação @ref(eq:pooledS).\n\\[\\begin{equation}\nt_0 = \\frac{\\bar{x_1}-\\bar{x_2}}{s\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}\n  (\\#eq:t2s)\n\\end{equation}\\] \\[\\begin{equation}\ns = \\sqrt{\\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\n(\\#eq:pooledS)\n\\end{equation}\\]\nO cálculo da estatística \\(t_0\\) é trivial e pode ser facilmente realizado utilizando o R como uma calculadora. Entretanto, é mais interessante utilizar a função t.test(), por apresentar um resultado mais estruturado, cofnorme segue. Comparando o valor da estatística calculada com o valor crítico, \\(|t_0| = 10.393 &gt; 2.0003 = t_{\\alpha/2}\\), ou pelo p-valor, \\(p-valor = 7,3 \\times10^{-15} &lt; 0,05 = \\alpha\\), constata-se que há indícios para rejeição da hipótese nula, garantindo que as resistências das amostras são diferentes.\n\n\n\n    Two Sample t-test\n\ndata:  resistencia by grupo\nt = -10.393, df = 58, p-value = 7.3e-15\nalternative hypothesis: true difference in means between group Controle and group Tratada is not equal to 0\n95 percent confidence interval:\n -35.73313 -24.19135\nsample estimates:\nmean in group Controle  mean in group Tratada \n              116.4774               146.4396 \n\n\n[1] 2.000298\n\n\nO poder do teste pode ser obtido utilizando a função power.t.test, conforme segue. Pode-se observar que o poder do teste foi unitário.\n\n\n\n     Two-sample t test power calculation \n\n              n = 30\n          delta = 29.96224\n             sd = 11.1657\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nA Figura @ref(fig:powert2) apresenta a curva de poder do teste em função do deslocamento a ser detectado para o Exemplo @ref(exm:t2). A alta diferença entre médias, relativamente aos desvios-padrões amostrais, garantiu \\(1-\\beta \\backsimeq 1\\) no Exemplo @ref(exm:t2).\n\n\n\n\n\nCurva de poder do teste, n1 = n2 = 30, sd = 11.17, teste bilateral",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#teste-t-para-médias-de-duas-amostras-dependentes",
    "href": "01-Dists.html#teste-t-para-médias-de-duas-amostras-dependentes",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.9 Teste t para médias de duas amostras dependentes",
    "text": "1.9 Teste t para médias de duas amostras dependentes\nO teste \\(t\\) para amostras pareadas (ou emparelhadas) é aplicado em estudos onde cada objeto é medido em duas diferentes ocasiões, antes e depois de um determinado tratamento, por exemplo. Este tipo de teste pode também ser aplicado em pares de indivíduos similares, sendo um tratamento aplicado a um elemento de cada par, enquanto o outro elemento dos pares é submetido a outro tratamento, ou não é submetido a tratamento algum (controle). Devido à possível dependência entre as amostras tomadas aos pares, utilizar os procedimentos anteriormente propostos para testar a diferença entre médias de duas amostras violaria a hipótese de independência estatística entre as amostras. Por conseguinte, o teste \\(t\\) pareado é utilizado para testar a diferença entre médias de amostras dependentes.\nPara realizar o teste \\(t\\) para amostras pareadas, é importante confirmar a dependência entre as amostras. Para isto pode-se realizar o teste de correlação de Pearson, conforme segue. A Figura @ref(fig:scattervegetal) apresenta um diagrama de dispersão, confirmando a correlação positiva entre as amostras de humidade do carvão vegetal pulverizado e granulado.\n\n\n\n    Pearson's product-moment correlation\n\ndata:  Pulverizada and Granulada\nt = 11.704, df = 28, p-value = 2.677e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8201861 0.9572343\nsample estimates:\n      cor \n0.9112053 \n\n\n\n\n\n\n\nDiagrama de dispersão para humidade das amostras de carvão vegetal pulverizada e granulada\n\n\n\n\nO teste \\(t\\) pareado é realizado considerando a diferença em relação às amostras pareadas. A hipótese nula consiste em testar se a diferença é igual a um valor de interesse, isto é, \\(H_0: \\mu_d = \\mu_{d0}\\). Já a hipótese alternativa pode ser bilateral ou unilateral à direita ou à esquerda. A estatística do teste \\(t\\) pareado é exposta na Equação @ref(eq:tpaired), onde \\(n\\) é o número de pares. Logo, o teste consiste no mesmo teste \\(t\\) para uma amostra, de forma que a hipótese de normalidade para as diferenças deve ser confirmada.\n\\[\\begin{equation}\nt_0 = \\frac{\\bar{x}_d-\\mu_d}{s_d/\\sqrt{n}}\n  (\\#eq:tpaired)\n\\end{equation}\\]\nO código à seguir calcula as diferenças entre os pares das duas amostras e, posteriormente a normalidade das diferenças.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  d\nW = 0.9786, p-value = 0.7871\n\n\n\n\n\nGráfico quantil-quantil para as diferenças\n\n\n\n\nFinalmente o teste \\(t\\) pareado é realizado através do código à seguir. Pode-se constatar que, como \\(p-valor = 0,8562 &gt; 0,05 = \\alpha\\), não se rejeita a hipótese nula de igualdade entre os métodos de preparação da amostra para medição de umidade do carvão vegetal. Como conclusão prática, não é necessário triturar o carvão para medir sua umidade.\n\n\n\n    Paired t-test\n\ndata:  Pulverizada and Granulada\nt = 0.18284, df = 29, p-value = 0.8562\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3055859  0.3655859\nsample estimates:\nmean difference \n           0.03 \n\n\nO cálculo do poder do teste pode ser realizado com a sintaxe que segue. Como a diferença é muito pequena considerando o desvio-padrão e o tamanho amostral, o poder do teste foi baixíssimo.\n\n\n\n     Paired t test power calculation \n\n              n = 30\n          delta = 0.03\n             sd = 0.8987156\n      sig.level = 0.05\n          power = 0.03728679\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#análise-de-variância",
    "href": "01-Dists.html#análise-de-variância",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "1.10 Análise de variância",
    "text": "1.10 Análise de variância\nQuando deseja-se testar a diferença entre médias para três ou mais amostras ou tratamentos, deve-se utilizar a análise de variância (ANOVA). A presença de três ou mais tratamentos é comum em diversos estudos experimentais, tornando a análise de variância umas das técnicas mais importantes em inferência estatística.\nExistem diversos tipos de ANOVA, considerando o número de fatores em avaliação, efeitos fixos ou aleatórios, etc. Neste primeiro momento será abordada a ANOVA para um fator (ou one-way) com modelo de efeitos fixos.\nSeja o conjunto geral de dados resumido na Tabela @ref(tab:anova-data). Neste conjunto tem-se \\(a\\) tratamentos de interesse e \\(n\\) observações ou replicações experimentais em cada tratamento. De forma geral, cada observação pode ser denotada como \\(y_{ij}\\), com \\(i = 1, ..., a\\) e \\(j = 1, ..., n\\).\n\n(#tab:anova-data) Dados de um experimento com \\(a\\) tratamentos e \\(n\\) observações em cada tratamento\n\n\n\n\n\n\n\n\nTratamentos\nObservações\nSomas\nMédias\n\n\n\n\n1\n\\(y_{11}\\), \\(y_{12}\\), …, \\(y_{1n}\\)\n\\(y_{1.} = \\sum_{j=1}^{n}{y_{1j}}\\)\n\\(\\bar{y}_{1.} = y_{1.}/n\\)\n\n\n2\n\\(y_{21}\\), \\(y_{22}\\), …, \\(y_{2n}\\)\n\\(y_{2.} = \\sum_{j=1}^{n}{y_{2j}}\\)\n\\(\\bar{y}_{2.} = y_{2.}/n\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\na\n\\(y_{a1}\\), \\(y_{a2}\\), …, \\(y_{an}\\)\n\\(y_{a.} = \\sum_{j=1}^{n}{y_{aj}}\\)\n\\(\\bar{y}_{a.} = y_{a.}/n\\)\n\n\n\nAinda na Tabela @ref(tab:anova-data) é importante obter os totais e as médias de cada tratamento, \\(y_{i.}\\) e \\(\\bar{y}_{i.}\\), \\(i = 1, ..., a\\), para facilitar os cálculos necessários à análise.\nCada observação experimental \\(y_{ij}\\) pode ser discriminada conforme o modelo apresentado na Equação @ref(eq:anova-model), o modelo de efeitos fixos da ANOVA. Neste modelo a média geral ou grande média denotada \\(\\mu\\) e calculada conforme a Equação @ref(eq:medg). O efeito de cada tratamento \\(\\alpha_{i}\\) consiste na diferença entre médias do tratamento e a média geral, \\(i = 1, ..., a\\), segundo Equação @ref(eq:eftrat). Por fim, o termo de erro \\(\\varepsilon_{ij}\\) consiste na diferença entre cada observação e a média dentro do seu tratamento, \\(i = 1, ..., a\\), \\(j = 1, ..., n\\), conforme Equação @ref(eq:erroanova). Sobre o termo de erro residem as hipóteses de que este seja normalmente e independentemente distribuído com média nula e variância \\(\\sigma^2_\\varepsilon\\), ou seja, \\(\\varepsilon_{ij} \\sim N(0,\\sigma^2_\\varepsilon)\\).\nA média logicamente pode variar de tratamento para tratamento, sendo esta hipotética variação testada estatísticamente. Já a variância dentro dos tratamentos é assumida constante.\n\\[\\begin{equation}\ny_{ij} = \\mu + \\alpha_{i} + \\varepsilon_{ij}\n(\\#eq:anova-model)\n\\end{equation}\\] \\[\\begin{equation}\n\\mu = \\bar{y}_{..} = \\frac{\n\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}{y_{ij}}}{an}\n(\\#eq:medg)\n\\end{equation}\\] \\[\\begin{equation}\n\\alpha_{i} = \\bar{y}_{i.} - \\bar{y}_{..}\n(\\#eq:eftrat)\n\\end{equation}\\] \\[\\begin{equation}\n\\varepsilon_{ij} = y_{ij} - \\bar{y}_{i.}\n(\\#eq:erroanova)\n\\end{equation}\\]\nEste modelo é chamado de modelo de efeitos fixos, com cada efeito dentro dos tratamentos fixo porém desconhecido a ser estimado. Este tipo de modelo é o mais comum na análise de variância, sendo utilizado quando deseja-se conhecer apenas o efeito dos tratamentos considerados. No caso onde se selecionam de forma aleatória \\(a\\) tratamentos de uma ampla população, desejando-se conhecer o efeito para toda população de origem, deve-se utilizar o modelo de efeitos aleatórios.\nAs hipóteses testadas na análise de variância são relacionadas aos efeito dos tratamentos e de forma análoga à média destes. A hipótese nula consiste na nulidade dos efeitos, enquanto a hipótese alternativa garante que ao menos um dos efeitos é não nulo, ou de outra forma ao menos uma média dos tratamentos é distinta dos demais. As hipóteses são formuladas à seguir.\n\\[\\begin{equation}\nH_0: \\alpha_1= \\alpha_2 = ... = \\alpha_a = 0\n\\end{equation}\\] \\[\\begin{equation}\nH_0: \\alpha_i \\ne 0, \\text{para ao menos um $i$}\n\\end{equation}\\]\nA análise de variância é um teste para diferença entre médias baseado no particionamento da soma dos quadrados total, na soma dos quadrados entre tratamentos e na soma dos quadrados dentro dos tratamentos, conforme Equação @ref(eq:vartotal). A variância total das observações experimentais da Tabela @ref(tab:anova-data) é expressa conforme Equação @ref(eq:vartotal). O numerador do cálculo, \\(SS_T\\), é a soma dos quadrados total, enquanto o denominador, \\(DF_T\\), consiste nos graus de liberdade total.\n\\[\\begin{equation}\ns_T^2 = s_{Entre}^2 + s_{Dentro}^2\n(\\#eq:sigmatotal)\n\\end{equation}\\] \\[\\begin{equation}\ns_T^2 = \\frac{SS_T}{DF_T} =  \\frac{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}{an-1}\n(\\#eq:vartotal)\n\\end{equation}\\]\nTomando a soma dos quadrados total, \\(SS_T\\), é possível particioná-la na soma dos quadrados entre os tratamentos, \\(SS_{Trat}\\), e na soma dos quadrados dentro dos tratamentos, \\(SS_{Erro}\\), conforme a Equação @ref(eq:ident-anova). Pode-se observar que a soma dos quadrados dos tratamentos e a soma dos quadrados dos erros são as somas dos quadrados dos efeitos expostos nas Equações @ref(eq:eftrat) e @ref(eq:erroanova), respectivamente. Na Tabela @ref(tab:anova-data) estas quantidades estão relacionados à variabilidade entre as linhas e dentro das linhas.\n\\[\\begin{equation}\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}_{SS_T}=\n\\underbrace{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}_{SS_{Trat}}+\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}_{SS_{Erro}}\n(\\#eq:ident-anova)\n\\end{equation}\\]\nOs graus de liberdade dos tratamentos estão relacionados ao número de tratamentos em estudo, \\(DF_{Trat} = a-1\\). Tomando a razão entre a soma dos quadrados e os graus de liberdade dos tratamentos, conforme Equação @ref(eq:mstrat) tem-se a média dos quadrados dos tratamentos, \\(MS_{Trat}\\). Esta medida é a estimativa da variância entre os tratamentos, \\(\\sigma_{Trat}^2=MS_{Trat}\\). Quanto maior esta medida, maior a diferença entre médias dos tratamentos. Entretanto, esta diferença deve ser avaliada relativamente à variância dentro dos tratamentos, isto é, em relação à variância experimental.\n\\[\\begin{equation}\nMS_{Trat} =  \\frac{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}{a-1}\n(\\#eq:mstrat)\n\\end{equation}\\]\nOs graus de liberdade dos erros devem ser avaliados com mais cuidado. Para o i-ésimo tratamento a i-ésima variância é calculada conforme a Equação @ref(eq:i-var). Combinando todas as variâncias dos \\(a\\) tratamentos, tem-se o resultado da Equação @ref(eq:mse). A média dos quadrados dos erros, \\(MS_E\\), é a estimativa da variância experimental na ANOVA, \\(\\sigma_\\varepsilon^2=MS_E\\). As médias dos quadrados são distribuídas pela distribuição \\(\\chi^2\\), por constarem de somas de desvios quadráticos em relação à média, isto é, soma dos quadrados de quantidades distribuídas pela normal-padrão \\(Z\\).\n\\[\\begin{equation}\ns_i^2 =  \\frac{\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{n-1}\n(\\#eq:i-var)\n\\end{equation}\\] \\[\\begin{equation}\nMS_E =  \\frac{\\displaystyle\\sum_{i=1}^{a}\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{a(n-1)}\n(\\#eq:mse)\n\\end{equation}\\]\nA estatística do teste ANOVA, \\(F_0\\), é calculada conforme Equação @ref(eq:f-anova), como a razão entre as médias dos quadrados dos tratamentos e dos erros. Quanto maior esta razão, maior a diferença entre os efeitos, relativamente ao erro experimental. Como esta quantidade consiste na razão entre médias dos quadrados, isto é, entre estimativas de variâncias ela é distribuída pela distribuição \\(F\\), \\(F_0 \\sim F_{(a-1,a(n-1))}\\). A hipótese \\(H_0\\) de nulidade e igualdade dos efeitos é rejeitada se \\(F_0 &gt; F_{(\\alpha,a-1,a(n-1))}\\). A Tabela @ref(tab:res-anova) resume os cálculos da ANOVA. Geralmente os resultados obtidos via ANOVA são apresentados neste formato.\n\\[\\begin{equation}\nF_0 =  \\frac{MS_{Trat}}{MS_{Erro}}\n(\\#eq:f-anova)\n\\end{equation}\\]\n\n(#tab:res-anova) Tabela resumo ANOVA\n\n\n\n\n\n\n\n\n\nFonte\nDF\nSS\nMS\n\\(F_0\\)\n\n\n\n\nTratamentos\n\\(a-1\\)\n\\(SS_{Trat}\\)\n\\(SS_{Trat}/(a-1)\\)\n\\(F_0 = MS_{Trat}/MS_{Erro}\\)\n\n\nErro\n\\(a(n-1)\\)\n\\(SS_{Erro}\\)\n\\(SS_{Erro}/[a(n-1)]\\)\n-\n\n\nTotal\n\\(an - 1\\)\n\\(SS_{T}\\)\n-\n-\n\n\n\nExistem algumas medidas de ajuste usadas para averiguar a efetividade do modelo obtido via ANOVA. O coeficiente de determinação simples \\(R^2\\) é calculado conforme a Equação @ref(eq:R2), como a razão entre a soma dos quadrados dos tratamentos e a soma dos quadrados total. Esta medida deve ser usada com cautela, por não levar em consideração o número de graus de liberdade do modelo. neste sentido, o coeficiente de determinação ajustado \\(R_{aj}^2\\) é obtido conforme a Equação @ref(eq:R2aj).\n\\[\\begin{equation}\nR^2 = \\frac{SS_{Trat}}{SS_T}\n(\\#eq:R2)\n\\end{equation}\\] \\[\\begin{equation}\nR_{aj}^2 = 1 - \\frac{MS_{Trat}}{SS_T/(an-1)}\n(\\#eq:R2aj)\n\\end{equation}\\]\nA ANOVA para três ou mais tratamentos é comumente chamada de ANOVA one-way. Para conduzir este tipo de análise, deve-se utilizar o chamado planejamento totalmente aleatorizado ou delineamento inteiramente casualizado. Neste planejamento todas as \\(N = an\\) observações experimentais são conduzidas em ordem e alocação de materiais totalmente aleatória. A aleatorização auxilia na garantia das hipóteses de normalidade e independencia dos resíduos. Ao aleatorizar os experimentos garante-se que fontes externas incontroláveis de variação, chamadas de ruídos, tenham interferência mínima ou ao menos tenham efeito diluido de maneira aleatória nos resultados experimentais. As replicações viabilizam a estimativa do erro experimental. Sem a replicação não é possível testar a significância dos efeitos avaliados, visto que estes são sempre avaliados relativamente ao erro experimental.\n\n\n\nPlanejamento totalmente aleatorizado para microdureza HV em [GPa] em função do método de resfriamento de cerâmicas de zirconia\n\n\nordem\ncooling\nhardness\n\n\n\n\n10\nslow\n5.34\n\n\n3\nslow\n5.43\n\n\n12\nslow\n5.42\n\n\n7\nslow\n5.40\n\n\n2\nslow\n5.38\n\n\n15\nnormal\n5.20\n\n\n6\nnormal\n5.22\n\n\n8\nnormal\n5.15\n\n\n14\nnormal\n5.25\n\n\n9\nnormal\n5.24\n\n\n13\nfast\n5.20\n\n\n11\nfast\n5.15\n\n\n5\nfast\n5.19\n\n\n4\nfast\n5.17\n\n\n1\nfast\n5.18\n\n\n\n\n\nPara obter este planejamento pode-se utilizar o código à seguir no R.\nPara realizar a análise é utilizado o comando aov(). Pelos resultados, como \\(F_0 = 62,84 &gt; 3,89 = F_{(0,05,2,12)}\\), ou como \\(p-value = 4,38 \\times 10^{-7} &lt; 0,05 = \\alpha\\), rejeita-se \\(H_0\\). Deste modo, há ao menos um dos tratamentos com efeito diferente, de forma que há influência do tipo de resfriamento na microdureza. A estatística de ajuste \\(R_{aj}^2=0,898\\), garante que a maior parte da variabilidade dos dados é explicada pelo efeito dos tratamentos e não pelo erro experimental.\n\n\n            Df  Sum Sq Mean Sq F value   Pr(&gt;F)    \ncooling      2 0.13489 0.06745   62.84 4.38e-07 ***\nResiduals   12 0.01288 0.00107                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[1] 3.885294\n\n\n\nCall:\nlm(formula = hardness ~ cooling, data = plan)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-0.062 -0.013  0.006  0.024  0.038 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    5.17800    0.01465 353.411  &lt; 2e-16 ***\ncoolingnormal  0.03400    0.02072   1.641    0.127    \ncoolingslow    0.21600    0.02072  10.425 2.28e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03276 on 12 degrees of freedom\nMultiple R-squared:  0.9128,    Adjusted R-squared:  0.8983 \nF-statistic: 62.84 on 2 and 12 DF,  p-value: 4.384e-07\n\n\nA Figura @ref(fig:Fcritico) ilustra a região crítica do teste, com regão de rejeição de \\(H_0\\) destacada em vermelho.\n\n\n\n\n\nRegião crítica ANOVA, \\(\\alpha = 0,05, DF1 = 2, DF2 = 12\\)\n\n\n\n\nPara testar as pressuposições de normalidade e homocedasticidade pode-se utilizar os blocos de código à seguir. Para ambos os testes obteve-se \\(p-value &gt; \\alpha\\), não havendo indícios para rejeição da hipótese nula \\(H_0\\), implicando na normalidade dos resíduos e na igualdade de variâncias dos tratamentos.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuos\nW = 0.92867, p-value = 0.2607\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  hardness by cooling\nBartlett's K-squared = 1.831, df = 2, p-value = 0.4003\n\n\nA Figura @ref(fig:resi-anova), com sintaxe à seguir, ilustra alguns gráficos dos resíduos que auxiliam na visualização das pressuposições da ANOVA. O gráfico superior esquerdo plota os resíduos \\(\\varepsilon_{ij}\\) em relação aos valores previstos ou ajustados (fitted), \\(\\hat{y}_i=\\mu+\\alpha_i=\\bar{y}_{i.}\\). Um padrão de aleatoriedade, sem crescimento ou decrescimento de \\(\\varepsilon_{ij}\\) em função de \\(\\hat{y}_i\\) deve ser observado. Para o caso estudado não há indícios de dependência entre resíduos e valores ajustados. O gráfico superior direito é o gráfico quantil-quantil que plota os resíduos ordenados em função dos quantis teóricos da normal padrão. Quanto mais próximo da reta, melhor os resíduos se ajustam à distribuição normal. O gráfico inferior esquerdo plota a raiz quadrada dos resíduos padronizados em função dos valores ajustados. Este é um auxílio para ver, além da independência entre resíduos e ajustados, a homocedasticidade. No caso estudado, já confirmado estatísticamente, visualiza-se a homogeneidade da raiz dos resíduos padronizados em relação às médias dos tratamentos. O último gráfico, plotado no canto inferior direito, plota os resíduos em função dos níveis (tratamentos) experimentais. Deve-se averiguar por este gráfico a homogeneidade e independência dos resíduos em função dos níveis, além da possível presença de outliers, isto é, de valores discrepantes. Em caso de um ajuste baixo, isto é, um \\(R_{aj}^2\\) insuficiente, alguns experimentos com resíduos extremos destacados neste gráfico poderiam ser repetidos. No caso estudado não seria necessário.\n\n\n\n\n\nGráficos de resíduos para ANOVA, dureza ~ resfriamento\n\n\n\n\nA Figura @ref(fig:bp-anova) apresenta um box-plot da dureza em função do tipo de resfriamento, com código relacionado à seguir. O resfriamento lento garante maior microdureza da cerâmica.\n\n\n\n\n\nBoxplot para dureza ~ resfriamento\n\n\n\n\nA Figura @ref(fig:efeitos-anova) apresenta a média com intervalos de confiança. Ao rejeitar a hipótese nula através da ANOVA, o analista apenas constata que há ao menos um efeito distinto dos demais, em conformidade com a hipótese alternativa \\(H_1\\). Entretanto, pode ser desejado investigar as diferenças específicas.\n\n\n\n\n\nAjustados ~ resfriamento\n\n\n\n\nPosteriormente à ANOVA pode-se utilizar de testes de comparação de médias, ou testes de comparações múltiplas para testar as diferenças específicas. Nestes tipo de teste todas as comparações aos pares são realizadas entre as médias dos \\(a\\) tratamentos testados na ANOVA. A hipótese nula de cada comparação é sempre \\(H_0:\\mu_i = \\mu_j\\). Um teste bastante utilizado é o teste de Tukey HSD (honestly significant difference), por apresentar um bom controle da probabilidade de erro do tipo I. Entretanto, este teste é conhecido por apresentar alta probabilidade de erro do tipo II (baixo poder do teste). Outras opções disponíveis para comparações múltiplas como os testes de Duncan, teste t, teste de Newman-Keuls, teste t-bayesiano, entre outros.\nO código à seguir pode ser utilizado para realizar o teste de Tukey. Pode-se confirmar que o resfriamento lento é diferente do resfriamento normal e do resfriamento rápido, enquanto estes dois não são estatísticamente diferentes.\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = hardness ~ cooling, data = plan)\n\n$cooling\n             diff        lwr       upr     p adj\nnormal-fast 0.034 -0.0212791 0.0892791 0.2670508\nslow-fast   0.216  0.1607209 0.2712791 0.0000006\nslow-normal 0.182  0.1267209 0.2372791 0.0000040\n\n\nÉ possível obter o poder do teste para ANOVA com o comando power.anova.test, conforme sintaxe à seguir. Pode-se observar que o poder foi unitário, o que já era esperado, uma vez que rejeitou-se a hipótese nula pela ANOVA.\n\n\n\n     Balanced one-way analysis of variance power calculation \n\n         groups = 3\n              n = 5\n    between.var = 0.06745\n     within.var = 0.00107\n      sig.level = 0.05\n          power = 1\n\nNOTE: n is number in each group\n\n\nCaso o experimentador deseje encontrar o número de réplicas adequado para um determinado poder do teste antes de planejar seu experimento, deve-se ter uma estimativa de \\(SS_{Trat}\\) e \\(SS_{Erro}\\), o que geralmente é difícil de conseguir, especialmente quando não se tem conhecimento da variabilidade acerca dos tratamentos em estudo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "01-Dists.html#bibliografia",
    "href": "01-Dists.html#bibliografia",
    "title": "1  Distribuições importantes à modelagem e otimização de Experimentos",
    "section": "Bibliografia",
    "text": "Bibliografia\nBUSSAB, Wilton de Oliveira; MORETTIN, Pedro Alberto. Estatística básica. 2009.\nCOCHRAN, William G. The distribution of quadratic forms in a normal system, with applications to the analysis of covariance. 1934.\nFELLER, Willliam. An introduction to probability theory and its applications. 2008.\nGRINSTEAD, Charles Miller; SNELL, James Laurie. Introduction to probability. 2012.\nJOHNSON, N. L.; WELCH, B. L. Applications of the non-central t-distribution. 1940.\nKENDALL, Maurice George et al. The advanced theory of statistics. 1946.\nKOTZ, Samuel; JOHNSON, Norman L. Breakthroughs in statistics: methodology and distribution. 2012.\nMEYER, Paul L. Introductory probability and statistical applications. 1965.\nMONTGOMERY, Douglas C.; RUNGER, George C. Applied statistics and probability for engineers. 2011.\nMORAIS, Manuel Cabral. Lecture Notes—Probability Theory.\nPEARSON, Karl. Historical note on the origin of the normal curve of errors. 1924.\nROSS, Sheldon M. Introduction to probability models. 2010.\nSNEDECOR, George W.; COCHRAN, Witiiam G. Statistical methods. 1967.\nSTEYER, Rolf; NAGEL, Werner. Probability and conditional expectation. 2017.\nWHITTLE, Peter. Probability via expectation. 1992.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribuições importantes à modelagem e otimização de Experimentos</span>"
    ]
  },
  {
    "objectID": "03-ANOVA.html",
    "href": "03-ANOVA.html",
    "title": "3  Planejamento totalmente aleatorizado e análise de variância para um fator",
    "section": "",
    "text": "3.1 Introdução\nQuando deseja-se testar a diferença entre médias para três ou mais amostras ou tratamentos, deve-se utilizar a análise de variância (ANOVA). A presença de três ou mais tratamentos é comum em diversos estudos experimentais, tornando a análise de variância umas das técnicas mais importantes em inferência estatística. Este tipo de estudo é geralmente planejado usando o planejamento totalmente aleatorizado.\nExistem diversos tipos de ANOVA, considerando o número de fatores em avaliação, efeitos fixos ou aleatórios, etc. Neste primeiro momento será abordada a ANOVA para um fator ou ANOVA de uma via (one-way) com modelo de efeitos fixos.\nNeste capítulo são utilizados os pacotes dplyr e ggpplot2, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Planejamento totalmente aleatorizado e análise de variância para um fator</span>"
    ]
  },
  {
    "objectID": "03-ANOVA.html#introdução",
    "href": "03-ANOVA.html#introdução",
    "title": "3  Análise de Variância",
    "section": "",
    "text": "(#tab:anova-data) Dados de um experimento com \\(a\\) tratamentos e \\(n\\) observações em cada tratamento\n\n\n\n\n\n\n\n\nTratamentos\nObservações\nSomas\nMédias\n\n\n\n\n1\n\\(y_{11}\\), \\(y_{12}\\), …, \\(y_{1n}\\)\n\\(y_{1.} = \\sum_{j=1}^{n}{y_{1j}}\\)\n\\(\\bar{y}_{1.} = y_{1.}/n\\)\n\n\n2\n\\(y_{21}\\), \\(y_{22}\\), …, \\(y_{2n}\\)\n\\(y_{2.} = \\sum_{j=1}^{n}{y_{2j}}\\)\n\\(\\bar{y}_{2.} = y_{2.}/n\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\na\n\\(y_{a1}\\), \\(y_{a2}\\), …, \\(y_{an}\\)\n\\(y_{a.} = \\sum_{j=1}^{n}{y_{aj}}\\)\n\\(\\bar{y}_{a.} = y_{a.}/n\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(#tab:res-anova) Tabela resumo ANOVA\n\n\n\n\n\n\n\n\n\nFonte\nDF\nSS\nMS\n\\(F_0\\)\n\n\n\n\nTratamentos\n\\(a-1\\)\n\\(SS_{Trat}\\)\n\\(SS_{Trat}/(a-1)\\)\n\\(F_0 = MS_{Trat}/MS_{Erro}\\)\n\n\nErro\n\\(a(n-1)\\)\n\\(SS_{Erro}\\)\n\\(SS_{Erro}/[a(n-1)]\\)\n-\n\n\nTotal\n\\(an - 1\\)\n\\(SS_{T}\\)\n-\n-",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise de Variância</span>"
    ]
  },
  {
    "objectID": "03-ANOVA.html#análise-de-variância-para-um-fator",
    "href": "03-ANOVA.html#análise-de-variância-para-um-fator",
    "title": "3  Planejamento totalmente aleatorizado e análise de variância para um fator",
    "section": "3.2 Análise de variância para um fator",
    "text": "3.2 Análise de variância para um fator\nSeja o conjunto geral de dados resumido na Tabela 3.1. Neste conjunto tem-se \\(a\\) tratamentos de interesse e \\(n\\) observações ou replicações experimentais em cada tratamento. De forma geral, cada observação pode ser denotada como \\(y_{ij}\\), com \\(i = 1, ..., a\\) e \\(j = 1, ..., n\\).\n\n\n\nTabela 3.1: Dados de um experimento com \\(a\\) tratamentos e \\(n\\) observações em cada tratamento\n\n\n\n\n\n\n\n\n\n\n\nTratamentos\nObservações\nSomas\nMédias\n\n\n\n\n1\n\\(y_{11}\\), \\(y_{12}\\), …, \\(y_{1n}\\)\n\\(y_{1.} = \\sum_{j=1}^{n}{y_{1j}}\\)\n\\(\\bar{y}_{1.} = y_{1.}/n\\)\n\n\n2\n\\(y_{21}\\), \\(y_{22}\\), …, \\(y_{2n}\\)\n\\(y_{2.} = \\sum_{j=1}^{n}{y_{2j}}\\)\n\\(\\bar{y}_{2.} = y_{2.}/n\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\na\n\\(y_{a1}\\), \\(y_{a2}\\), …, \\(y_{an}\\)\n\\(y_{a.} = \\sum_{j=1}^{n}{y_{aj}}\\)\n\\(\\bar{y}_{a.} = y_{a.}/n\\)\n\n\n\n\n\n\nAinda na Tabela 3.1 é importante obter os totais e as médias de cada tratamento, \\(y_{i.}\\) e \\(\\bar{y}_{i.}\\), \\(i = 1, ..., a\\), para facilitar os cálculos necessários à análise.\nCada observação experimental \\(y_{ij}\\) pode ser discriminada conforme o modelo apresentado na Equação 3.1, o modelo de efeitos fixos da ANOVA. Neste modelo a média geral ou grande média denotada \\(\\mu\\) e calculada conforme a Equação 3.2. O efeito de cada tratamento \\(\\alpha_{i}\\) consiste na diferença entre médias do tratamento e a média geral, \\(i = 1, ..., a\\), segundo Equação 3.3. Por fim, o termo de erro \\(\\varepsilon_{ij}\\) consiste na diferença entre cada observação e a média dentro do seu tratamento, \\(i = 1, ..., a\\), \\(j = 1, ..., n\\), conforme Equação 3.4. Sobre o termo de erro residem as hipóteses de que este seja normalmente e independentemente distribuído com média nula e variância \\(\\sigma^2_\\varepsilon\\), ou seja, \\(\\varepsilon_{ij} \\sim N(0,\\sigma^2_\\varepsilon)\\).\nA média logicamente pode variar de tratamento para tratamento, sendo esta hipotética variação testada estatísticamente. Já a variância dentro dos tratamentos é assumida constante.\n\\[\ny_{ij} = \\mu + \\alpha_{i} + \\varepsilon_{ij}\n\\tag{3.1}\\] \\[\n\\mu = \\bar{y}_{..} = \\frac{\n\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}{y_{ij}}}{an}\n\\tag{3.2}\\] \\[\n\\alpha_{i} = \\bar{y}_{i.} - \\bar{y}_{..}\n\\tag{3.3}\\] \\[\n\\varepsilon_{ij} = y_{ij} - \\bar{y}_{i.}\n\\tag{3.4}\\]\nEste modelo é chamado de modelo de efeitos fixos, com cada efeito dentro dos tratamentos a ser estimado fixo porém desconhecido. Este tipo de modelo é o mais comum na análise de variância, sendo utilizado quando deseja-se conhecer apenas o efeito dos tratamentos considerados. No caso onde se selecionam de forma aleatória \\(a\\) tratamentos de uma ampla população, desejando-se conhecer o efeito para toda população de origem, deve-se utilizar um modelo de efeitos aleatórios.\nAs hipóteses testadas na análise de variância são relacionadas aos efeito dos tratamentos e de forma análoga à média destes. A hipótese nula consiste na nulidade dos efeitos, enquanto a hipótese alternativa sugere que ao menos um dos efeitos é não nulo ou, de outra forma, ao menos uma média dos tratamentos é distinta dos demais. As hipóteses são formuladas à seguir.\n\\[\nH_0: \\alpha_1= \\alpha_2 = ... = \\alpha_a = 0\n\\] \\[\nH_0: \\alpha_i \\ne 0, \\text{para ao menos um } i\n\\]\nA análise de variância é um teste para diferença entre médias baseado no particionamento da soma dos quadrados total, na soma dos quadrados entre tratamentos e na soma dos quadrados dentro dos tratamentos, conforme Equação 3.6. A variância total das observações experimentais da Tabela 3.1 é expressa conforme Equação Equação 3.6. O numerador do cálculo, \\(SS_T\\), é a soma dos quadrados total, enquanto o denominador, \\(DF_T\\), consiste nos graus de liberdade total.\n\\[\ns_T^2 = s_{Entre}^2 + s_{Dentro}^2\n\\tag{3.5}\\] \\[\ns_T^2 = \\frac{SS_T}{DF_T} =  \\frac{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}{an-1}\n\\tag{3.6}\\]\nTomando a soma dos quadrados total, \\(SS_T\\), é possível particioná-la na soma dos quadrados entre os tratamentos, \\(SS_{Trat}\\), e na soma dos quadrados dentro dos tratamentos, \\(SS_{Erro}\\), conforme a Equação 3.7. Pode-se observar que a soma dos quadrados dos tratamentos e a soma dos quadrados dos erros são as somas dos quadrados dos efeitos expostos nas Equação 3.3 e Equação 3.4, respectivamente. Na Tabela 3.1 estas quantidades estão relacionados à variabilidade entre as linhas e dentro das linhas.\n\\[\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{..}})^2}_{SS_T}=\n\\underbrace{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}_{SS_{Trat}}+\n\\underbrace{\\displaystyle\\sum_{i=1}^{a}\n\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}_{SS_{Erro}}\n\\tag{3.7}\\]\nOs graus de liberdade dos tratamentos estão relacionados ao número de tratamentos em estudo, \\(DF_{Trat} = a-1\\). Tomando a razão entre a soma dos quadrados e os graus de liberdade dos tratamentos, conforme Equação 3.8 tem-se a média dos quadrados dos tratamentos, \\(MS_{Trat}\\). Esta medida é a estimativa da variância entre os tratamentos, \\(\\sigma_{Trat}^2=MS_{Trat}\\). Quanto maior esta medida, maior a diferença entre médias dos tratamentos. Entretanto, esta diferença deve ser avaliada relativamente à variância dentro dos tratamentos, isto é, em relação à variância experimental.\n\\[\nMS_{Trat} =  \\frac{n\\displaystyle\\sum_{i=1}^{a}\n({\\bar{y}_{i.}-\\bar{y}_{..}})^2}{a-1}\n\\tag{3.8}\\]\nOs graus de liberdade dos erros devem ser avaliados com mais cuidado. Para o i-ésimo tratamento a i-ésima variância é calculada conforme a Equação 3.9. Combinando todas as variâncias dos \\(a\\) tratamentos, tem-se o resultado da Equação 5.8. A média dos quadrados dos erros, \\(MS_E\\), é a estimativa da variância experimental na ANOVA, \\(\\sigma_\\varepsilon^2=MS_E\\). As médias dos quadrados são distribuídas pela distribuição \\(\\chi^2\\), por constarem de somas de desvios quadráticos em relação à média, isto é, soma dos quadrados de quantidades distribuídas pela normal-padrão \\(Z\\).\n\\[\ns_i^2 =  \\frac{\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{n-1}\n\\tag{3.9}\\] \\[\nMS_E =  \\frac{\\displaystyle\\sum_{i=1}^{a}\\displaystyle\\sum_{j=1}^{n}({y_{ij}-\\bar{y}_{i.}})^2}{a(n-1)}\n\\tag{3.10}\\]\nA estatística do teste ANOVA, \\(F_0\\), é calculada conforme Equação 3.11, como a razão entre as médias dos quadrados dos tratamentos e dos erros. Quanto maior esta razão, maior a diferença entre os efeitos, relativamente ao erro experimental. Como esta quantidade consiste na razão entre médias dos quadrados, isto é, entre estimativas de variâncias ela é distribuída pela distribuição \\(F\\), \\(F_0 \\sim F_{(a-1,a(n-1))}\\). A hipótese \\(H_0\\) de nulidade e igualdade dos efeitos é rejeitada se \\(F_0 &gt; F_{(\\alpha,a-1,a(n-1))}\\). A Tabela 3.2 resume os cálculos da ANOVA. Geralmente os resultados obtidos via ANOVA são apresentados neste formato.\n\\[\nF_0 =  \\frac{MS_{Trat}}{MS_{Erro}}\n\\tag{3.11}\\]\n\n\n\nTabela 3.2: Tabela resumo ANOVA\n\n\n\n\n\n\n\n\n\n\n\n\nFonte\nDF\nSS\nMS\n\\(F_0\\)\n\n\n\n\nTratamentos\n\\(a-1\\)\n\\(SS_{Trat}\\)\n\\(SS_{Trat}/(a-1)\\)\n\\(F_0 = MS_{Trat}/MS_{Erro}\\)\n\n\nErro\n\\(a(n-1)\\)\n\\(SS_{Erro}\\)\n\\(SS_{Erro}/[a(n-1)]\\)\n-\n\n\nTotal\n\\(an - 1\\)\n\\(SS_{T}\\)\n-\n-\n\n\n\n\n\n\nExistem algumas medidas de ajuste usadas para averiguar a efetividade do modelo obtido via ANOVA. O coeficiente de determinação simples \\(R^2\\) é calculado conforme a Equação 3.12, como a razão entre a soma dos quadrados dos tratamentos e a soma dos quadrados total. Esta medida deve ser usada com cautela, por não levar em consideração o número de graus de liberdade do modelo. neste sentido, o coeficiente de determinação ajustado \\(R_{aj}^2\\) é obtido conforme a Equação 3.13, sendo uma medida mais adequada para mensurar a variabilidade dos dados explicado pelo modelo ANOVA.\n\\[\nR^2 = \\frac{SS_{Trat}}{SS_T}\n\\tag{3.12}\\] \\[\nR_{aj}^2 = 1 - \\frac{MS_{Trat}}{SS_T/(an-1)}\n\\tag{3.13}\\]\nA ANOVA para um fator considerando três ou mais tratamentos é comumente chamada de ANOVA de uma via. Para conduzir este tipo de análise, deve-se utilizar o chamado planejamento totalmente aleatorizado ou delineamento inteiramente casualizado. Neste planejamento todas as \\(N = an\\) observações experimentais são conduzidas em ordem e alocação de materiais totalmente aleatória. A aleatorização auxilia na garantia das hipóteses de normalidade e independência dos resíduos. Ao aleatorizar os experimentos garante-se que fontes externas incontroláveis de variação, chamadas de variáveis de ruídos, tenham interferência mínima ou ao menos tenham efeito diluído de forma aleatória nos resultados experimentais. As replicações viabilizam a estimativa do erro experimental. Sem a replicação não é possível testar a significância dos efeitos avaliados, visto que estes são sempre avaliados relativamente ao erro experimental.\n\nExemplo 3.1 Um estudo foi realizado para o efeito do método de resfriamento na microdureza da porcelana de zircônia para próteses dentárias. Três métodos de resfriamento foram testados. lento: as amostras são deixadas dentro do forno fechado e desligado até atingirem a temperatura ambiente; normal: as amostras são removidas e resfriadas à temperatura ambiente; e rápido: as amostras são imediatamente removidas do forno após o tempo de espera e jateadas por ar comprimido. Os resultados são apresentados na Tabela 3.3.\n\n\n\n\n\nTabela 3.3: Planejamento totalmente aleatorizado para microdureza HV em [GPa] em função do método de resfriamento de cerâmicas de zirconia\n\n\n\n\n\n\nordem\ncooling\nhardness\n\n\n\n\n10\nslow\n5.34\n\n\n3\nslow\n5.43\n\n\n12\nslow\n5.42\n\n\n7\nslow\n5.40\n\n\n2\nslow\n5.38\n\n\n15\nnormal\n5.20\n\n\n6\nnormal\n5.22\n\n\n8\nnormal\n5.15\n\n\n14\nnormal\n5.25\n\n\n9\nnormal\n5.24\n\n\n13\nfast\n5.20\n\n\n11\nfast\n5.15\n\n\n5\nfast\n5.19\n\n\n4\nfast\n5.17\n\n\n1\nfast\n5.18\n\n\n\n\n\n\n\n\nPara obter este planejamento pode-se utilizar o código à seguir no R.\n\n# Valores experimentais de dureza\nhardness &lt;- c(5.34, 5.43, 5.42, 5.40, 5.38, \n              5.20, 5.22, 5.15, 5.25, 5.24, \n              5.20, 5.15, 5.19, 5.17, 5.18)\n\n# Ordem de condução dos ensaios\nset.seed(7) # para \"controlar\" a aleatorização\n# seq é utilizado para obter uma sequencia\n# sample com o argumento replace = FALSE para aleatorização\nrandom &lt;- sample(1:15, size = 15, replace = FALSE)\n\n# Definindo tratamentos\ncooling &lt;- rep(c(\"slow\",\"normal\",\"fast\"),each=5)\n# Tratamentos como fatores\ncooling &lt;- as.factor(cooling)\n\n# reunindo os dados em um data.frame\nplan &lt;- data.frame(random, cooling, hardness)\n\nPara realizar a análise é utilizado o comando aov(). Pelos resultados, como \\(F_0 = 62,84 &gt; 3,89 = F_{(0,05;2;12)}\\), ou como \\(p-value = 4,38 \\times 10^{-7} &lt; 0,05 = \\alpha\\), rejeita-se \\(H_0\\). Deste modo, há ao menos um dos tratamentos com efeito diferente, de forma que há influência do tipo de resfriamento na microdureza. A estatística de ajuste \\(R_{aj}^2=0,898\\), garante que a maior parte da variabilidade dos dados é explicada pelo efeito dos tratamentos e não pelo erro experimental.\n\n# ANOVA para dureza em função do resfriamento\nres.anova &lt;- aov(hardness ~ cooling, data = plan)\nsummary(res.anova)\n\n            Df  Sum Sq Mean Sq F value   Pr(&gt;F)    \ncooling      2 0.13489 0.06745   62.84 4.38e-07 ***\nResiduals   12 0.01288 0.00107                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#F para  0,05 de significância\nF_critico &lt;- qf(.95, df1=2, df2=12)\nF_critico\n\n[1] 3.885294\n\n# Modelo linear associado à ANOVA\n# Importante para obter as medidas de ajuste - R^2\nlm1 &lt;- lm(hardness ~ cooling, data = plan)\nsummary(lm1)\n\n\nCall:\nlm(formula = hardness ~ cooling, data = plan)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-0.062 -0.013  0.006  0.024  0.038 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    5.17800    0.01465 353.411  &lt; 2e-16 ***\ncoolingnormal  0.03400    0.02072   1.641    0.127    \ncoolingslow    0.21600    0.02072  10.425 2.28e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03276 on 12 degrees of freedom\nMultiple R-squared:  0.9128,    Adjusted R-squared:  0.8983 \nF-statistic: 62.84 on 2 and 12 DF,  p-value: 4.384e-07\n\n\nA Figura 3.1 ilustra a região crítica do teste, com regão de rejeição de \\(H_0\\) destacada em vermelho.\n\n\n\n\n\n\n\n\nFigura 3.1: Região crítica ANOVA, \\(\\alpha = 0,05, DF1 = 2, DF2 = 12\\)\n\n\n\n\n\nPara testar as pressuposições de normalidade e homocedasticidade pode-se utilizar os blocos de código à seguir. Para ambos os testes obteve-se \\(p-value &gt; \\alpha\\), não havendo indícios para rejeição da hipótese nula \\(H_0\\), implicando na normalidade dos resíduos e na igualdade de variâncias dos tratamentos.\n\n# Extraindo resíduos\nresiduos &lt;- res.anova$residuals\n# Teste de normalidade dos resíduos\nshapiro.test(residuos)\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuos\nW = 0.92867, p-value = 0.2607\n\n# Teste de homocedasticidade\nbartlett.test(hardness ~ cooling, data = plan)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  hardness by cooling\nBartlett's K-squared = 1.831, df = 2, p-value = 0.4003\n\n\nA Figura 3.2, obtida com sintaxe à seguir, ilustra alguns gráficos dos resíduos que auxiliam na visualização das pressuposições da ANOVA. O gráfico superior esquerdo plota os resíduos \\(\\varepsilon_{ij}\\) em relação aos valores previstos ou ajustados (fitted), \\(\\hat{y}_i=\\mu+\\alpha_i=\\bar{y}_{i.}\\). Um padrão de aleatoriedade, sem crescimento ou decrescimento de \\(\\varepsilon_{ij}\\) em função de \\(\\hat{y}_i\\) deve ser observado. Para o caso estudado não há indícios de dependência entre resíduos e valores ajustados. O gráfico superior direito é o gráfico quantil-quantil que plota os resíduos ordenados em função dos quantis teóricos da normal padrão. Quanto mais próximo da reta, melhor os resíduos se ajustam à distribuição normal. O gráfico inferior esquerdo plota a raiz quadrada dos resíduos padronizados em função dos valores ajustados. Este é um auxílio para ver, além da independência entre resíduos e ajustados, a homocedasticidade. No caso estudado, já confirmado estatísticamente, visualiza-se a homogeneidade da raiz dos resíduos padronizados em relação às médias dos tratamentos. O último gráfico, plotado no canto inferior direito, plota os resíduos em função dos níveis (tratamentos) experimentais. Deve-se averiguar por este gráfico a homogeneidade e independência dos resíduos em função dos níveis, além da possível presença de outliers, isto é, de valores discrepantes. Em caso de um ajuste baixo, isto é, um \\(R_{aj}^2\\) insuficiente, alguns experimentos com resíduos extremos destacados neste gráfico poderiam ser repetidos. No caso estudado não seria necessário.\n\n# painel de 2 linhas e 2 colunas de gráficos\npar(mfrow=c(2,2))\n# gráficos dos resíduos \nplot(res.anova)\n\n\n\n\n\n\n\nFigura 3.2: Gráficos de resíduos para ANOVA, dureza ~ resfriamento\n\n\n\n\n\nA Figura 3.3 apresenta gráficos de caixa ou box-plot da dureza em função do tipo de resfriamento, com código relacionado à seguir. O resfriamento lento garante maior microdureza da cerâmica.\n\n# Box-plot\nggplot(plan, aes(x = cooling, y = hardness, color = cooling)) +\n  # Adicionar boxplot\n  geom_boxplot(width = 0.5, alpha = 0.2) +\n  # Adicionar pontos com jitter para visualizar distribuição dos dados\n  geom_jitter(width = 0.2, height = 0, alpha = 0.7) +\n  # Adicionar títulos aos eixos\n  labs(\n    x = \"Resfriamento\",\n    y = \"Dureza [GPa]\"\n  ) +\n  # Remover legenda que seria redundante\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nFigura 3.3: Boxplot para dureza em função do método de resfriamento\n\n\n\n\n\nA Figura 3.4 apresenta gráficos de médias com intervalos de confiança. Ao rejeitar a hipótese nula através da ANOVA, o analista apenas constata que há ao menos um efeito distinto dos demais, em conformidade com a hipótese alternativa \\(H_1\\). Entretanto, pode ser desejado investigar as diferenças específicas.\n\nlibrary(dplyr)\n\n# Primeiro, vamos calcular a média e o intervalo de confiança para cada grupo\nresumo &lt;- plan %&gt;%\n  group_by(cooling) %&gt;%\n  summarise(\n    mean_hardness = mean(hardness),\n    # cálculo do intervalo de confiança de 95%\n    ci_lower = mean_hardness - qt(0.975, n()-1) * sd(hardness)/sqrt(n()),\n    ci_upper = mean_hardness + qt(0.975, n()-1) * sd(hardness)/sqrt(n())\n  )\n\n# Agora criar o gráfico com ggplot2\nggplot() +\n  # Adicionar os pontos individuais com jitter\n  geom_jitter(data = plan, \n              aes(x = cooling, y = hardness), \n              width = 0.2, alpha = 0.5) +\n  \n  # Adicionar linha conectando as médias\n  geom_line(data = resumo, \n            aes(x = cooling, y = mean_hardness, group = 1), \n            color = \"blue\", linewidth = 1) +\n  \n  # Adicionar pontos para as médias\n  geom_point(data = resumo, \n             aes(x = cooling, y = mean_hardness), \n             color = \"blue\", size = 3) +\n  \n  # Adicionar barras de erro para o intervalo de confiança\n  geom_errorbar(data = resumo, \n                aes(x = cooling, \n                    ymin = ci_lower, \n                    ymax = ci_upper),\n                width = 0.1, color = \"blue\") +\n  # Adicionar títulos aos eixos\n  labs(\n    x = \"Resfriamento\",\n    y = \"Dureza [GPa]\"\n  )\n\n\n\n\n\n\n\nFigura 3.4: Gráfico de médias (ou de efeitos) para a dureza em função do método de resfriamento\n\n\n\n\n\n\n3.2.1 Testes de comparações múltiplas\nPosteriormente à ANOVA pode-se utilizar de testes de comparação de médias, ou de comparações múltiplas para testar as diferenças específicas. Nestes tipo de teste todas as comparações aos pares são realizadas entre as médias dos \\(a\\) tratamentos testados na ANOVA. A hipótese nula de cada comparação é sempre \\(H_0:\\mu_i = \\mu_j\\). Um teste bastante utilizado é o teste de Tukey HSD (honestly significant difference), por apresentar um bom controle da probabilidade de erro do tipo I. Entretanto, este teste é conhecido por apresentar alta probabilidade de erro do tipo II (baixo poder do teste). Outras opções disponíveis para comparações múltiplas como os testes de Duncan, teste t, teste de Newman-Keuls, teste t-bayesiano, entre outros.\nO código à seguir pode ser utilizado para realizar o teste de Tukey. Pode-se confirmar que o resfriamento lento é diferente do resfriamento normal e do resfriamento rápido, enquanto estes dois não são estatísticamente diferentes.\n\n# Teste de Tukey\nTukeyHSD(res.anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = hardness ~ cooling, data = plan)\n\n$cooling\n             diff        lwr       upr     p adj\nnormal-fast 0.034 -0.0212791 0.0892791 0.2670508\nslow-fast   0.216  0.1607209 0.2712791 0.0000006\nslow-normal 0.182  0.1267209 0.2372791 0.0000040\n\n\n\n\n3.2.2 Poder do teste na ANOVA\nÉ possível obter o poder do teste para ANOVA com o comando power.anova.test, conforme sintaxe à seguir. Pode-se observar que o poder foi unitário, o que já era esperado, uma vez que rejeitou-se a hipótese nula pela ANOVA.\n\n# Power and sample size ANOVA\npower.anova.test(groups = 3, \n                 n = 5, \n                 between.var = 0.06745,\n                 within.var = 0.00107,\n                 sig.level = 0.05)\n\n\n     Balanced one-way analysis of variance power calculation \n\n         groups = 3\n              n = 5\n    between.var = 0.06745\n     within.var = 0.00107\n      sig.level = 0.05\n          power = 1\n\nNOTE: n is number in each group\n\n\nCaso o experimentador deseje encontrar o número de réplicas adequado para um determinado poder do teste antes de planejar seu experimento, deve-se ter uma estimativa de \\(SS_{Trat}\\) e \\(SS_{Erro}\\), o que geralmente é difícil de conseguir, especialmente quando não se tem conhecimento da variabilidade acerca dos tratamentos em estudo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Planejamento totalmente aleatorizado e análise de variância para um fator</span>"
    ]
  },
  {
    "objectID": "03-ANOVA.html#bibliografia",
    "href": "03-ANOVA.html#bibliografia",
    "title": "3  Planejamento totalmente aleatorizado e análise de variância para um fator",
    "section": "Bibliografia",
    "text": "Bibliografia\nANDERSON, Kenneth E. Computation of by Analysis of Variance. The American Statistician, v. 15, n. 2, p. 18-19, 1961.\nALMEIDA JUNIOR, Antonio Alves de et al. Effect of the cooling rate on the properties of veneer porcelain for zirconia dental prosthesis. Materials Research, v. 20, n. 5, p. 1418-1424, 2017.\nBOX, George EP et al. Some theorems on quadratic forms applied in the study of analysis of variance problems, I. Effect of inequality of variance in the one-way classification. The annals of mathematical statistics, v. 25, n. 2, p. 290-302, 1954.\nBUSSAB, Wilton de Oliveira; MORETTIN, Pedro Alberto. Estatística básica. 2009.\nCASELLA, George; BERGER, Roger L. Statistical inference. Pacific Grove, CA: Duxbury, 2002.\nCOCHRAN, William G. The distribution of quadratic forms in a normal system, with applications to the analysis of covariance. In: Mathematical Proceedings of the Cambridge Philosophical Society. Cambridge University Press, 1934. p. 178-191.\nCRUMP, S. Lee. The estimation of variance components in analysis of variance. Biometrics Bulletin, v. 2, n. 1, p. 7-11, 1946.\nDANIELS, Henry E. The estimation of components of variance. Supplement to the Journal of the Royal Statistical Society, v. 6, n. 2, p. 186-197, 1939.\nEISENHART, Churchill. The assumptions underlying the analysis of variance. Biometrics, v. 3, n. 1, p. 1-21, 1947.\nFISHER, Ronald Aylmer et al. Statistical methods for research workers. Statistical methods for research workers, 5th Ed, 1934.\nGURLAND, John; MCCULLOUGH, Roger S. Testing equality of means after a preliminary test of equality of variances. Biometrika, v. 49, n. 3-4, p. 403-417, 1962.\nHALD, Anders. A history of parametric statistical inference from Bernoulli to Fisher, 1713-1935. Springer Science & Business Media, 2008.\nKEMPTHORNE, Oscar. The randomization theory of experimental inference. Journal of the American Statistical Association, v. 50, n. 271, p. 946-967, 1955.\nMONTGOMERY, Douglas C. Design and analysis of experiments. John wiley & sons, 2013.\nMONTGOMERY, Douglas C.; RUNGER, George C. Applied statistics and probability for engineers. John Wiley & Sons, 2011.\nPLACKETT, R. L. Models in the analysis of variance. Journal of the Royal Statistical Society: Series B (Methodological), v. 22, n. 2, p. 195-209, 1960.\nSEARLE, Shayle R. Topics in variance component estimation. Biometrics, v. 27, n. 1, p. 1-76, 1971.\nSHAO, Yiqin et al. Interfacial strength and debonding mechanism between aerogel-spun carbon nanotube yarn and polyphenylene sulfide. Composites Part A: Applied Science and Manufacturing, v. 88, p. 98-105, 2016.\nSCHEFFE, Henry et al. Alternative models for the analysis of variance. The Annals of Mathematical Statistics, v. 27, n. 2, p. 251-271, 1956.\nSNEDECOR, George W.; COCHRAN, Witiiam G. Statistical methods, 8thEdn. Ames: Iowa State Univ. Press Iowa, 1967.\nTUKEY, John W. Comparing individual means in the analysis of variance. Biometrics, p. 99-114, 1949.\nWASSERMAN, Larry. All of statistics: a concise course in statistical inference. Springer Science & Business Media, 2013.\nZUEV, Konstantin. Statistical Inference. 2018.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Planejamento totalmente aleatorizado e análise de variância para um fator</span>"
    ]
  },
  {
    "objectID": "04-ANOVA_blocos.html",
    "href": "04-ANOVA_blocos.html",
    "title": "4  Planejamento com blocos completos aleatorizados",
    "section": "",
    "text": "4.1 Introdução\nEm diversos processos industriais e experimentais a presença de variáveis de fontes diversas às quais são inevitáveis, porém não interessam diretamente ao processo ou estudo, pode afetar o desempenho do processo e/ou as características de qualidade ou respostas medidas. Tais variáveis são comumente ditas de ruído e podem estar relacionadas a fatores ambientais, máquina, matéria-prima, entre outras. A aleatorização, conforme já explicado é uma premissa do planejamento de experimentos que auxilia na diluição da variabilidade adivinda de tais fatores em todas as corridas experimentais. Porém, em situações onde existem variáveis de ruído que são conhecidas e podem ser controladas, a blocagem é a técnica mais adequada para retirar do erro experimental a variância devido a tais variáveis.\nO planejamento totalmente aleatorizado com blocos completos aleatorizados pode ser usado em casos onde deseja-se estudar um fator com a possibilidade de alocar cada replicação em cada nível da variável blocada.\nNeste capítulo é utilizado o pacote ggpplot2, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Planejamento com blocos completos aleatorizados</span>"
    ]
  },
  {
    "objectID": "04-ANOVA_blocos.html#formas-de-tratar-variáveis-de-ruído-e-blocagem",
    "href": "04-ANOVA_blocos.html#formas-de-tratar-variáveis-de-ruído-e-blocagem",
    "title": "4  Planejamento com blocos completos aleatorizados",
    "section": "4.2 Formas de tratar variáveis de ruído e blocagem",
    "text": "4.2 Formas de tratar variáveis de ruído e blocagem\nExistem diversas formas de tratar variáveis ou fatores de ruído. O tratamento a ser aplicado depende do nosso conhecimento sobre a variável e da nossa capacidade de controlá-la e/ou medí-la. Em muitas situações é possível eliminar a variável de ruído. Por exemplo em um ambiente fabril ou laboratorial onde a temperatura ambiente influencia na variabilidade do processo e, consequentemente, do produto, caso seja possível controlar a temperatura, de forma que esta permaneça constante durante o horizonte de tempo de produção ou experimentação, este ruído terá seu efeito minimizado ou eliminado. Em muitos casos, entretanto, não é factível a eliminação do efeito da variável de ruído. A Tabela 4.1 resume alguns tratamentos possíveis às variáveis de ruído. Quando a variável de ruído é desconhecida a aleatorização é a única forma de garantir que seu erro não se confunda ou não enviese o efeito de interesse no estudo. Quando a variável de ruído é conhecida, porém não mensurável ou não controlável, a análise de covariância (ANCOVA) pode ser empregada. Por fim, caso a variável de ruído seja conhecida e pode ser controlada, a blocagem é a técnica adequada para remover sua variabilidade do erro aleatório.\n\n\n\nTabela 4.1: Tratamento de variáveis de ruído\n\n\n\n\n\nVariável de ruído\nDesconhecida\nConhecida\n\n\n\n\nNão mensurável\nAleatorização\nANCOVA\n\n\nControlada\n-\nBlocagem\n\n\n\n\n\n\nExistem diveros exemplos de variáveis de ruído presentes em processos industriais e experimentais que podem ser blocadas. Por exemplo, considere o caso onde deseja-se testar o efeito de distintas composições de concreto para aplicação estrutural e não há cimento (ou outra matária-prima) suficiente de um mesmo lote para fazer todas replicações das composições (ou tratamentos) de interesse. O ideal neste caso seria realizar uma replicação com todas as composições fabricadas de forma aleatória com cimento de um lote A, outra replicação com todas as composições fabricadas de forma aleatória com cimento de um lote B e assim sucessivamente. A intenção neste caso seria se precaver de uma possível variabilidade adivinda da diferença entre lotes de cimento. Pode ser que o fabricante garanta o atendimento das especificações do produto e, portanto, mínima variabilidade entre lotes, porém até mesmo o tempo de armazenamento, pode ser fonte de variabilidade neste tipo de produto. O ideal seria usar para todo o rpocedimento o mesmo lote, mas se não é possível a técnica de blocagem será útil para retirar do erro experimental a variabilidade da matéria-prima. A Figura 4.1 ilustra tal delineamento considerando 4 composições de concreto (tratamentos), 3 lotes de matéria-prima e, portanto, 3 réplicas. Os 4 tratamentos devem ser conduzidos de forma aleatória dentro dos blocos.\n\n\n\n\n\n\n\n\nFigura 4.1: Delineamento em blocos completos para o experimento de concreto\n\n\n\n\n\nOutros exemplos de variáveis passívas de blocagem incluem cultivares (área de cultivo), operador/medidor, máquina/equipamento, turno, entre outras. Em alguns casos a blocagem é necessária por indisponibilidade de recursos de uma mesma fonte, em outros para minimizar o tempo de execução dos experimentos, seja em ambiente científico ou industrial.\n\nExemplo 4.1 Um estudo investiga vários métodos teóricos e experimentais para determinar o tamanho de nanopartículas de óxido de zinco (ZnO NPs) e analisa suas características usando espectroscopia UV-Vis. A pesquisa começa com a síntese verde de três amostras de ZnO NPs, utilizando três agentes redutores diferentes: biomassa do fungo Aspergillus niger (AN), folhas de Aloe barbadensis Mill (ABM) e folhas de Ocimum tenuiflorum (OT), com sulfato de zinco como precursor, através do método de precipitação. São aplicados diferentes métodos de medição tamanho das nanopartículas: Aproximação de Massa Efetiva (EMA), Equação de Brus (BE), Modelo de Banda Hiperbólica (HBM), Expressão de Meulenkamp (ME), Modelo de Ligação Forte (TBM) e uma versão simplificada da EMA (SEMA). Os resultados são apresentados na Tabela 4.2, com código para obtê-lo explicitado a seguir.\n\n\n\n\nTabela 4.2: Planejamento com blocos completos totalmente aleatorizados para o estudo do tamanho de nanopartículas de óxido de zinco com distintos métodos de medição\n\n\nZnoAN&lt;- c(2.7,2.7,2.1,2.0,4.6)\nZnoABM&lt;- c(4.2,5.1,3.8,4.5,9.5)\nZnoANOT&lt;- c(5.1,7.7,5.2,7.2,15.7)\n\na &lt;- 3 #número de tratamentos (níveis)\nb &lt;- length(ZnoAN) #número de blocos\nN &lt;- a*b #número de experimentos\n\nset.seed(123)\nOrdem &lt;- unlist(replicate(5, sample(1:3, size = a, replace = FALSE), simplify = FALSE))\n\nmetodo &lt;- as.factor(rep(c(\"BE\", \"SEMA\", \"ME\", \"TBM\", \"HBM\"), each = 3))\n\nReducingAgents &lt;- rep(c(\"ZnoAN\",\"ZnoABM\",\"ZnoANOT\"), 5)\n\nAgente &lt;- as.factor(ReducingAgents) \n\nParticle_size &lt;- matrix(c(ZnoAN,ZnoABM,ZnoANOT),\n                        nrow=3, ncol= 5, byrow=T) # resposta\n\ncolnames(Particle_size) &lt;- c(\"BE\", \"SEMA\", \"ME\", \"TBM\", \"HBM\")\nrownames(Particle_size) &lt;- c(\"ZnoAN\", \"ZnoABM\", \"ZnoANOT\") \n\nBloco &lt;- metodo\n\nTamanho &lt;- c(Particle_size)\n\nplanejamento &lt;- data.frame(Ordem,Agente,Bloco,Tamanho)\n\n\n\nSeja o conjunto geral de dados resumido na Tabela 4.3. Neste conjunto tem-se \\(a\\) tratamentos de interesse e \\(b\\) blocos. De forma geral, cada observação pode ser denotada como \\(y_{ij}\\), com \\(i = 1, ..., a\\) e \\(j = 1, ..., b\\).\n\n\n\nTabela 4.3: Dados de um experimento com \\(a\\) tratamentos e \\(b\\) blocos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTratamentos\nBloco 1\nBloco 2\n…\nBloco b\nSomas\nMédias\n\n\n\n\n1\n\\(y_{11}\\)\n\\(y_{12}\\)\n…\n\\(y_{1b}\\)\n\\(y_{1.} = \\sum_{j=1}^{b}{y_{1j}}\\)\n\\(\\bar{y}_{1.} = y_{1.}/b\\)\n\n\n2\n\\(y_{21}\\)\n\\(y_{22}\\)\n…\n\\(y_{2b}\\)\n\\(y_{2.} = \\sum_{j=1}^{b}{y_{2j}}\\)\n\\(\\bar{y}_{2.} = y_{2.}/b\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\ddots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\na\n\\(y_{a1}\\)\n\\(y_{a2}\\)\n…\n\\(y_{ab}\\)\n\\(y_{a.} = \\sum_{j=1}^{b}{y_{aj}}\\)\n\\(\\bar{y}_{a.} = y_{a.}/b\\)\n\n\nSomas\n\\(y_{.1} = \\sum_{i=1}^{a}{y_{i1}}\\)\n\\(y_{.2} = \\sum_{i=1}^{a}{y_{i2}}\\)\n…\n\\(y_{.b} = \\sum_{i=1}^{a}{y_{ib}}\\)\n\\(y_{..} = \\sum_{i=1}^{a}\\sum_{j=1}^{b}{y_{ij}}\\)\n\n\n\nMédias\n\\(\\bar{y}_{.1} = y_{.1}/a\\)\n\\(\\bar{y}_{.2} = y_{.2}/a\\)\n…\n\\(\\bar{y}_{.b} = y_{.b}/a\\)\n\n\\(\\bar{y}_{..} = y_{..}/(a \\times b)\\)\n\n\n\n\n\n\nPara um delineamento em blocos completos ao acaso o modelo de efeitos para uma observação \\(y_{ij}\\) é exposto na Equação 4.1.\n\\[\ny_{ij} = \\mu + \\tau_i + \\beta_j + \\varepsilon_{ij}\n\\tag{4.1}\\]\nOnde:\n\n\\(y_{ij}\\) é a observação da variável resposta referente ao tratamento \\(i\\) no bloco \\(j\\);\n\\(\\mu\\) é a média geral (constante comum a todas as observações);\n\\(\\tau_i\\) é o efeito do tratamento \\(i\\), isto é: \\(\\tau_i = \\bar{y}_{i.} - \\bar{y}_{..}\\);\n\\(\\beta_j\\) é o efeito do bloco \\(j\\), isto é: \\(\\beta_j = \\bar{y}_{.j} - \\bar{y}_{..}\\);\n\\(\\varepsilon_{ij}\\) é o erro experimental associado à observação \\(y_{ij}\\), assumido como independente e normalmente distribuído com média zero e variância constante \\(\\sigma^2\\);\n\nAdicionalmente, assume-se que: \\(\\varepsilon_{ij} \\sim N(0, \\sigma^2)\\), \\(\\sum_{i=1}^{a} \\tau_i = 0\\) e \\(\\sum_{j=1}^{b} \\beta_j = 0\\).\nAs hipóteses testadas na análise de variância no delineamento em blocos casualizados consideram os efeitos dos tratamentos e dos blocos. A hipótese nula para os tratamentos é a de que todos os efeitos são nulos, enquanto a hipótese alternativa sugere que ao menos um dos efeitos é diferente. Analogamente, assume-se que os blocos têm efeito aleatório e controlam a variabilidade do experimento. As hipóteses para os tratamentos são formuladas da seguinte forma:\n\\[\nH_0: \\alpha_1= \\alpha_2 = \\cdots = \\alpha_a = 0\n\\] \\[\nH_1: \\alpha_i \\ne 0, \\text{ para ao menos um } i\n\\]\nA análise de variância em é baseada no particionamento da soma dos quadrados total em três componentes: soma dos quadrados entre tratamentos (\\(SS_{Trat}\\)), entre blocos (\\(SS_{Bloco}\\)) e dentro dos tratamentos e blocos (erro) (\\(SS_{Erro}\\)), conforme a Equação 4.2.\n\\[\n\\underbrace{\\sum_{i=1}^{a} \\sum_{j=1}^{b} (y_{ij} - \\bar{y}_{..})^2}_{SS_T}\n=\n\\underbrace{b \\sum_{i=1}^{a} (\\bar{y}_{i.} - \\bar{y}_{..})^2}_{SS_{Trat}}\n+\n\\underbrace{a \\sum_{j=1}^{b} (\\bar{y}_{.j} - \\bar{y}_{..})^2}_{SS_{Bloco}}\n+\n\\underbrace{\\sum_{i=1}^{a} \\sum_{j=1}^{b} (y_{ij} - \\bar{y}_{i.} - \\bar{y}_{.j} + \\bar{y}_{..})^2}_{SS_{Erro}}\n\\tag{4.2}\\]\nOs graus de liberdade de cada fonte de variação são:\n\nTratamentos: \\(DF_{Trat} = a - 1\\)\nBlocos: \\(DF_{Bloco} = b - 1\\)\nErro: \\(DF_{Erro} = (a - 1)(b - 1)\\)\nTotal: \\(DF_T = ab - 1\\)\n\nAs médias dos quadrados são obtidas pela razão entre a soma dos quadrados e os respectivos graus de liberdade:\n\\[\nMS_{Trat} = \\frac{SS_{Trat}}{a - 1}, \\quad\nMS_{Bloco} = \\frac{SS_{Bloco}}{b - 1}, \\quad\nMS_{Erro} = \\frac{SS_{Erro}}{(a - 1)(b - 1)}\n\\]\nA estatística do teste F para os tratamentos é dada por:\n\\[\nF_0 = \\frac{MS_{Trat}}{MS_{Erro}} \\sim F_{(a-1; (a-1)(b-1))}\n\\]\nA hipótese \\(H_0\\) é rejeitada se \\(F_0 &gt; F_{(\\alpha; a-1, (a-1)(b-1))}\\). A Tabela 4.4 resume os cálculos da ANOVA para o DBC.\n\n\n\nTabela 4.4: Tabela resumo ANOVA para o planejamento com blocos completos aleatorizados\n\n\n\n\n\n\n\n\n\n\n\n\nFonte\nDF\nSS\nMS\n\\(F_0\\)\n\n\n\n\nTratamentos\n\\(a - 1\\)\n\\(SS_{Trat}\\)\n\\(MS_{Trat}\\)\n\\(F_0 = MS_{Trat}/MS_{Erro}\\)\n\n\nBlocos\n\\(b - 1\\)\n\\(SS_{Bloco}\\)\n\\(MS_{Bloco}\\)\n–\n\n\nErro\n\\((a - 1)(b - 1)\\)\n\\(SS_{Erro}\\)\n\\(MS_{Erro}\\)\n–\n\n\nTotal\n\\(ab - 1\\)\n\\(SS_T\\)\n–\n–\n\n\n\n\n\n\nPara realizar a análise é utilizado o comando aov(). Pelos resultados, como \\(F_0 = 12,057 &gt; 4.45897 = F_{(0,05;2;8)}\\), ou como \\(p-value = 0.00385 &lt; 0,05 = \\alpha\\), rejeita-se \\(H_0\\). Deste modo, há ao menos um dos tratamentos com efeito diferente, de forma que há influência do tipo de agente redutor no tamanho da partícula. É importante notar também que o efeito do método de medição, que consiste neste caso na variável blocada, foi estatísticamente significativo, deixando claro a diferença entre tais métodos e, portanto, a necessidade de blocar tal fonte de variabilidade.\n\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nAgente       2  71.85   35.92  12.057 0.00385 **\nBloco        4  78.37   19.59   6.576 0.01203 * \nResiduals    8  23.83    2.98                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[1] 4.45897\n\n\n\nCall:\nlm(formula = modelo_anova)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.68000 -0.27667 -0.01333  0.22000  3.06000 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     3.9467     1.1791   3.347  0.01012 * \nAgenteZnoAN    -2.6000     1.0917  -2.382  0.04443 * \nAgenteZnoANOT   2.7600     1.0917   2.528  0.03535 * \nBlocoHBM        5.9333     1.4093   4.210  0.00296 **\nBlocoME        -0.3000     1.4093  -0.213  0.83676   \nBlocoSEMA       1.1667     1.4093   0.828  0.43178   \nBlocoTBM        0.5667     1.4093   0.402  0.69815   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.726 on 8 degrees of freedom\nMultiple R-squared:  0.8631,    Adjusted R-squared:  0.7604 \nF-statistic: 8.403 on 6 and 8 DF,  p-value: 0.004185\n\n\nAs medidas de ajuste usadas para averiguar a efetividade do modelo obtido via ANOVA no caso blocado são as mesmas, porém devem considerar a variabilidade relativa ao bloco. O coeficiente de determinação simples, \\(R^2\\), é calculado conforme a Equação 4.3, como a razão entre a soma dos quadrados explicada pelo modelo (tratamentos e blocos) e a soma dos quadrados total. Esta medida quantifica a proporção da variabilidade total explicada pelo modelo, mas deve ser usada com cautela, pois não considera o número de parâmetros incluídos.\n\\[\nR^2 = \\frac{SS_{Trat} + SS_{Bloco}}{SS_T}\n\\tag{4.3}\\]\nO coeficiente de determinação ajustado, \\(R_{aj}^2\\), é apresentado na Equação 4.4. Ele considera os graus de liberdade associados ao modelo e ao erro, penalizando a adição de efeitos que não contribuam de forma significativa para a explicação da variabilidade dos dados. É, portanto, uma métrica mais robusta para avaliar a qualidade do ajuste no contexto da ANOVA com blocos.\n\\[\nR_{aj}^2 = 1 - \\frac{MS_{Erro}}{SS_T/(ab - 1)}\n\\tag{4.4}\\]\nPara o Exemplo 4.1, a estatística de ajuste \\(R_{aj}^2=76,04\\%\\), garante que a maior parte da variabilidade dos dados é explicada pelo efeito dos tratamentos e dos blocos e não pelo erro experimental.\nA Figura 4.2 ilustra alguns gráficos dos resíduos que auxiliam na visualização das pressuposições da ANOVA.\n\n\n\n\n\n\n\n\nFigura 4.2: Gráficos de resíduos para ANOVA com blocos\n\n\n\n\n\nO teste de normalidade de Shapiro-Wilk é realizado conforme segue. Não há indícios para rejeição da hipótese de normalidade dos resíduos.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_anova$residuals\nW = 0.92293, p-value = 0.2134\n\n\nA Figura 4.3 ilustra um gráfico de efeitos dos tratamentos e blocos. A idéia deste gráfico é não somente demonstrar o efeito do agente redutor, mas também do método de medição. Pode-se observar que o agente ZnOAN resulta no menor tamanho de partícula, seguido do ZnOABM e do ZnOANOT. Ademais, fica claro que o método de medição HBM apresenta maior resultado de tamanho de partícula.\n\nggplot(planejamento, \n       aes(y = Tamanho, \n           x = Agente,\n           group = Bloco)) + \n  geom_line(aes(linetype = Bloco, color = Bloco)) +\n  geom_point(aes(shape = Bloco, color = Bloco)) +\n  labs(y = \"Tamanho de partícula (nm)\",\n       x= \"Agente redutor\",\n       color = \"Método\", linetype = \"Método\", shape = \"Método\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigura 4.3: Gráfico de efeitos para o tamanho de partícula em função do tipo de agente redutor e do método de medição\n\n\n\n\n\nUm gráfico de médias dos tratamentos pode ser apresentado conforme Figura 4.4, com código exposto à seguir.\n\nggplot(planejamento |&gt; \n         group_by(Agente) |&gt;\n         summarise(Tamanho = mean(Tamanho)), \n       aes(y = Tamanho, \n           x = Agente, group = 1)) + \n  geom_line() +\n  geom_point() +\n  labs(y = \"Tamanho de partícula (nm)\",\n       x= \"Agente redutor\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigura 4.4: Gráfico de média para o tamanho de partícula em função do tipo de agente redutor\n\n\n\n\n\n\n4.2.1 Teste de comparações múltiplas\nO código à seguir pode ser utilizado para realizar o teste de Tukey para o caso do planejamento com blocos completos aleatorizados. Pode-se confirmar que há diferença apenas entre os métodos de redução ZnOANOT e ZnOAN.\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Tamanho ~ Agente + Bloco, data = planejamento)\n\n$Agente\n                diff        lwr       upr     p adj\nZnoAN-ZnoABM   -2.60 -5.7193731 0.5193731 0.1005971\nZnoANOT-ZnoABM  2.76 -0.3593731 5.8793731 0.0811522\nZnoANOT-ZnoAN   5.36  2.2406269 8.4793731 0.0029844\n\n$Bloco\n               diff        lwr        upr     p adj\nHBM-BE    5.9333333   1.064437 10.8022298 0.0182795\nME-BE    -0.3000000  -5.168896  4.5688965 0.9994366\nSEMA-BE   1.1666667  -3.702230  6.0355631 0.9146298\nTBM-BE    0.5666667  -4.302230  5.4355631 0.9933755\nME-HBM   -6.2333333 -11.102230 -1.3644369 0.0139017\nSEMA-HBM -4.7666667  -9.635563  0.1022298 0.0551913\nTBM-HBM  -5.3666667 -10.235563 -0.4977702 0.0310483\nSEMA-ME   1.4666667  -3.402230  6.3355631 0.8303422\nTBM-ME    0.8666667  -4.002230  5.7355631 0.9685578\nTBM-SEMA -0.6000000  -5.468896  4.2688965 0.9917826",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Planejamento com blocos completos aleatorizados</span>"
    ]
  },
  {
    "objectID": "04-ANOVA_blocos.html#bibliografia",
    "href": "04-ANOVA_blocos.html#bibliografia",
    "title": "4  Planejamento com blocos completos aleatorizados",
    "section": "Bibliografia",
    "text": "Bibliografia\nBUSSAB, Wilton de Oliveira; MORETTIN, Pedro Alberto. Estatística básica. 2009.\nCOCHRAN, William G.; COX, Gertrude M. Experimental designs. John Wiley & Sons, 1957\nFISHER, R. A. The arrangement of field experiments. Journal of the Ministry of Agriculture of Great Britain, 33, 503-513, 1926.\nFISHER, Ronald Aylmer et al. Statistical methods for research workers. 5th Ed, 1934.\nKEMPTHORNE, Oscar. The randomization theory of experimental inference. Journal of the American Statistical Association, v. 50, n. 271, p. 946-967, 1955.\nMONTGOMERY, Douglas C. Design and analysis of experiments. John wiley & sons, 2013.\nSNEDECOR, George W.; COCHRAN, William G. Statistical methods. 8th Edn. Ames: Iowa State Univ. Press Iowa, 1967.\nSTEEL, R. G. D. and TORRIE, J. H. Principles and procedures of statistics. A biometrical approach, 2nd Edition, McGraw-Hill Book Company, New York, 1980.\nYATES, Frank. The design and analysis of factorial experiments. Technical Communication no. 35, Imperial Bureau of Soil Science, 1937.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Planejamento com blocos completos aleatorizados</span>"
    ]
  },
  {
    "objectID": "05-fat2k.html",
    "href": "05-fat2k.html",
    "title": "5  Fatorial de dois níveis",
    "section": "",
    "text": "5.1 Introdução\nOs planejamentos fatoriais são utilizados quando deseja-se obter informações dos efeitos dos fatores de interesse de forma simultânea, bem como estudar o efeito da interação entre dois ou mais fatores na resposta avaliada. O planejamento fatorial \\(2^k\\) permite a experimentação sequencial e econômica utilizando o fatorial fracionado \\(2^{k-p}\\) e o fatorial não replicado, elucidados no capítulo posterior. É possível utilizar esquemas de confundimento e blocagem com a finalidade de diluir possíveis fontes de variação de ruído no planejamento, sem inflar o erro experimental. Por fim, o planejamento fatorial integra estratégias de experimentação sequencial para busca de região de curvatura e obtenção de modelos quadráticos a partir do planejamento composto central, o qual será elucidado no capítulo de metodologia de superfície de resposta.\nPretende-se inicialmente abordar o planejamento fatorial de dois níveis, o conhecido fatorial \\(2^k\\) replicado.\nNeste capítulo são utilizados os pacotes FrF2, pid, vdg e ggpplot2, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fatorial de dois níveis</span>"
    ]
  },
  {
    "objectID": "05-fat2k.html#fatorial-2k-replicado",
    "href": "05-fat2k.html#fatorial-2k-replicado",
    "title": "5  Fatorial de dois níveis",
    "section": "5.2 Fatorial \\(2^k\\) replicado",
    "text": "5.2 Fatorial \\(2^k\\) replicado\nO planejamento fatorial \\(2^k\\) consiste em um projeto experimental onde todos os \\(k\\) fatores de interesse apresentam dois níveis. Este planejamento permite a avaliação de fatores quantitativos ou qualitativos codificando os dois níveis dos fatores em -1 e +1. O número total de experimentos em um planejamento fatorial \\(2^k\\) é \\(N = n2^{k}\\), onde \\(n\\) é o número de replicações do planejamento. Um planejamento fatorial \\(2^k\\) considera todas as \\(2^k\\) combinações dos níveis dos três fatores de interesse \\(x_1, x_2,..., x_k\\). A finalidade de testar todas as combinações dos níveis dos fatores é de averiguar o efeito das interações entre os fatores, isto é, de estimar o efeito da mudança de dois ou mais fatores de forma concomitante.\nA Tabela 5.1 apresenta um planejamento fatorial \\(2^3\\) com \\(N = 8\\) experimentos. O planejamento fatorial \\(2^k\\) é comumente codificado com níveis \\({-1,+1}\\). A codificação evita efeitos de escala e unidades de medida na inferência dos efeitos testados. A ordem padrão dos ensaios garante que todas as \\(2^3\\) combinações dos dois níveis dos \\(k = 3\\) fatores sejam testadas. Para o fator \\(x_1\\) muda-se de nível a cada \\(2^0 = 1\\) linha. Para o fator \\(x_2\\) muda-se de nível a cada cada \\(2^1 = 2\\) linhas. Para o fator \\(x_k\\) muda-se de nível a cada \\(2^{k−1}\\) linhas. E assim sucessivamente, caso o planejamento apresente mais fatores. Um fatorial balanceado deve ter o mesmo número de replicações, \\(n\\), em cada uma das \\(2^k\\) combinações dos níveis dos fatores.\n\n\n\n\nTabela 5.1: Planejamento fatorial \\(2^3\\)\n\n\n\n\n\n\nordem\nx1\nx2\nx3\n\n\n\n\n1\n-1\n-1\n-1\n\n\n2\n1\n-1\n-1\n\n\n3\n-1\n1\n-1\n\n\n4\n1\n1\n-1\n\n\n5\n-1\n-1\n1\n\n\n6\n1\n-1\n1\n\n\n7\n-1\n1\n1\n\n\n8\n1\n1\n1\n\n\n\n\n\n\n\n\nA Figura 5.1 ilustra os planejamentos fatorial \\(2^2\\) e fatorial \\(2^3\\). Pode-se observar a correspondência da ilustração do fatorial \\(2^3\\), Figura 5.1(b), com o planejamento apresentado na Tabela 5.1, de forma que a identificação nos vértices do cubo corresponde com a coluna ordem do planejamento. Observa-se que a distância entre os níveis codificados é igual a 2.\n\n\n\n\n\n\n\n\nFigura 5.1: Representação (a) fatorial \\(2^2\\); (b) fatorial \\(2^3\\)\n\n\n\n\n\nAo se utilizar um planejamento fatorial \\(2^k\\) é possível estimar:\n\n\\(k\\) efeitos principais;\n\\({k \\choose 2}\\) interações de segunda ordem;\n\\({k \\choose 3}\\) interações de terceira ordem;\n\\(\\vdots\\)\n\\({k \\choose (k - 1)}\\) interações de terceira ordem;\n1 interação de ordem \\(k\\).\n\nUm conceito importante para regressão é a matriz do planejamento, ou design matrix, \\(\\mathbf{X}\\), de ordem \\(N \\times r\\). A matriz do planejamento contém uma coluna para cada termo a ser estimado no modelo de regressão, totalizando \\(r\\) colunas. A matriz \\(\\mathbf{X}\\), à seguir, é a matriz do planejamento fatorial \\(2^3\\). A primeira coluna é unitária, estando relacionada à constante. As três colunas seguintes estão relacionadas aos fatores \\(x_1\\), \\(x_2\\) e \\(x_3\\), respectivamente, consistindo no próprio planejamento fatorial \\(2^3\\). Posteriormente, tem-se as três colunas das interações de segunda ordem \\(x_{1}x_{2}\\), \\(x_{1}x_{3}\\) e \\(x_{2}x_{3}\\), sendo cada termo formado pelo produto aos pares dos termos das colunas relacionadas. Finalmente, a última coluna relaciona-se à interação de terceira ordem \\(x_{1}x_{2}x_{3}\\). Portanto, a interação, consiste matematicamente no produto das variáveis que interagem. Caso o analista não deseje um modelo completo, o número de colunas \\(r\\) da matriz \\(\\mathbf{X}\\) pode ser menor. Entretanto, deve-se manter a hierarquia do modelo, de forma que todos os efeitos individuais e interações de menor ordem envolvidos nas interações consideradas estejam presentes. A matriz \\(\\mathbf{X}\\) é ortogonal, de forma que para cada fator (cada coluna), cada nível é repetido o mesmo número de vezes \\(N/2\\), ou de forma análoga, para qualquer coluna \\(i\\), a soma de todos as linhas é nula, isto é, \\(\\sum_{u=1}^{N}x_{iu} = 0\\) e, também, a soma dos produtos dos termos de duas colunas quaisquer é nula, \\(\\sum_{u=1}^{N}x_{iu}x_{ju}\\), tomando duas colunas \\(i, j\\), com \\(i \\ne j\\), e considerando \\(u = 1, ..., N\\) linhas. A ortogonalidade implica na independência na estimativa dos efeitos.\n\\[\\mathbf{X} = \\begin{bmatrix}\n                     1 & -1 & -1 & -1 & +1 & +1 & +1 & -1\\\\\n                     1 & +1 & -1 & -1 & -1 & -1 & +1 & +1\\\\\n                     1 & -1 & +1 & -1 & -1 & +1 & -1 & +1\\\\\n                     1 & +1 & +1 & -1 & +1 & -1 & -1 & -1\\\\\n                     1 & -1 & -1 & +1 & +1 & -1 & -1 & +1\\\\\n                     1 & +1 & -1 & +1 & -1 & +1 & -1 & -1\\\\\n                     1 & -1 & +1 & +1 & -1 & -1 & +1 & -1\\\\\n                     1 & +1 & +1 & +1 & +1 & +1 & +1 & +1\\\\         \n\\end{bmatrix}\\]\nO fatorial \\(2^k\\) permite o cálculo dos efeitos de forma intuitiva, além de garantir a possibilidade de estimativa de um modelo de regressão linear com interação e de testar significância dos coeficientes de regressão. É possível também utilizar a ANOVA para trabalhar a significância dos efeitos, considerando os contrastes das somas nos dois níveis. Para facilitar o entendimento, seja o exemplo Exemplo 5.1.\n\nExemplo 5.1 Um planejamento fatorial \\(2^k\\) foi utilizado para estudar a conformação a quente de um aço microligado com nióbio. Foram estudados três parâmetros do processo, a saber: \\(x_1\\): temperatura de desbaste; \\(x_2\\): temperatura de acabamento; e \\(x_3\\): temperatura de enrolamento em \\([^\\circ C]\\). A resposta estudada, \\(y\\), foi o tamanho de grão. A Tabela 5.2 expõe os níveis do planejamento. Três replicações foram realizadas,totalizando \\(N =3\\times2^{3} = 24\\) testes, sendo o planejamento e os 24 resultados dos experimentos expostos na Tabela 5.3.\n\n\n\n\n\nTabela 5.2: Níveis dos fatores\n\n\n\n\n\n\nFatores\n-1\n1\n\n\nX1\n1000\n1150\n\n\nX2\n800\n950\n\n\nX3\n550\n700\n\n\n\n\n\n\n\n\n\n\n\n\nTabela 5.3: Planejamento fatorial \\(2^3\\), conformação a quente\n\n\n\n\nPlanejamento fatorial 23, conformação a quente\n\n\n\n\n\n\n\n\n\n\n\nordem\nx1\nx2\nx3\nGrão \\([\\mu m]\\)\nGrão \\([\\mu m]\\)\nGrão \\([\\mu m]\\)\n\n\n\n\n1\n-1\n-1\n-1\n5.1\n5.0\n4.9\n\n\n2\n1\n-1\n-1\n5.6\n5.7\n5.2\n\n\n3\n-1\n1\n-1\n8.6\n8.5\n9.0\n\n\n4\n1\n1\n-1\n9.1\n9.2\n9.3\n\n\n5\n-1\n-1\n1\n7.7\n8.2\n8.1\n\n\n6\n1\n-1\n1\n8.4\n8.3\n8.5\n\n\n7\n-1\n1\n1\n13.5\n13.9\n14.3\n\n\n8\n1\n1\n1\n14.0\n14.1\n14.5\n\n\n\n\n\n\n\n\nInicialmente serão demonstrados os códigos para obtenção do planejamento e análise dos resultados utilizando comandos simples em R, de forma a explicar junto à teoria como realizar os cálculos. Posteriormente, serão utilizados pacotes mais estruturados para obtenção do planejamento e análise dos resultados de forma direta. Para gerar este planejamento no R, pode-se utilizar o código à seguir.\n\n# definindo os níveis\nlevels &lt;- c(-1, +1)\n\n# criando o planejamento\n# o comando expand.grid faz todas as combinações \n# dos níveis dos vetores colocados como argumentos\nplanej &lt;- expand.grid(levels,levels,levels)\n\n# replicando o planejamento três vezes\nplanej &lt;- rbind(planej,planej,planej)\n\n# adicionando coluna de ordem padrão e ordem aleatória\nplanej &lt;- cbind(c(1:24), sample(1:24,24,replace = F), planej)\n\n# definindo nomes para as colunas\ncolnames(planej) &lt;- c(\"ordem\", \"random\", \"x1\",\"x2\",\"x3\")\n\n# Definindo resposta\ngrao &lt;-  c(5.1, 5.6, 8.6, 9.1, 7.7, 8.4, 13.5, 14,\n             5, 5.7, 8.5, 9.2, 8.2, 8.3, 13.9, 14.1,\n             4.9, 5.2, 9, 9.3, 8.1, 8.5, 14.3, 14.5)\n\n# atribuindo resposta à coluna y do planejamento \nplanej$y &lt;- grao\n\nA coluna de ordem aleatória (random) foi gerada para propor uma ordem de condução dos ensaios. A aleatorização da ordem e da seleção dos materiais nos experimentos é importante para diluir o erro experimental devido a variáveis incontroláveis de forma aleatória em todas as condições experimentais. Estas variáveis incontroláveis, ditas de ruído, podem ter origem em condições ambientais ou de fontes de variação intrínsecas do próprio aparato experimental e materiais usados.\nPor exemplo, suponha que o analista não tem condições de fixar a temperatura ambiente durante a condução de \\(N\\) experimentos. Se estes ensaios são conduzidos na ordem padrão, caso a temperatura aumente de forma linear no horizonte de tempo de condução dos ensaios, pode ser que o efeito do último fator, \\(x_k\\), esteja confundido com o efeito da temperatura, visto que a ordem padrão do último fator no fatorial \\(2^k\\) implica na condução dos \\(N/2\\) primeiros ensaios no nível baixo, \\(x_k=-1\\), e a outra metade no nível alto, \\(x_k=+1\\). A aleatorização auxiliará na diluição do efeito do fator incontrolável, a temperatura ambiente, de forma aleatória em todas as parcelas experimentais.\nDe forma geral, o efeito consiste na diferença entre médias. No fatorial \\(2^k\\), para cada fator de interesse, o efeito é a diferença entre médias da resposta nos níveis alto e baixo. Seja \\(E_{x_i}\\) efeito do fator \\(x_i\\), \\(i = 1, ..., k\\), calculado conforme Equação 5.1.\n\\[\n  E_{x_{i}} = \\frac{\\sum_{x_{i}=+1}y - \\sum_{x_{i}=-1}y}{N/2}\n\\tag{5.1}\\]\nPara calcular os efeitos pode-se considerar a matrix \\(\\mathbf{X}\\), de forma que cada efeito seja a soma do produto da respectiva coluna da \\(\\mathbf{X^Ty}\\) pelo vetor linha da resposta, \\(y\\), dividido por \\(N/2\\), isto é, \\(\\mathbf{x}_i^Ty\\), onde \\(\\mathbf{x}_i\\), \\(i = 1, ..., r\\) é a i-ésima coluna da matriz \\(\\mathbf{X}\\). Neste caso geral \\(r = N\\). Porém, há casos onde o analista não deseja estimar todos os efeitos, de forma que \\(r&lt;N\\). O sinal do efeito indica se um acréscimo na variável independente (fator de controle) aumenta - efeito positivo - ou diminui - efeito negativo - a resposta de interesse.\n\n# construindo a matrix X do planejamento do exemplo\nX &lt;- with(planej, cbind(I = 1, x1, x2, x3, x1x2 = x1*x2, x1x3= x1*x3, x2x3 = x2*x3, x1x2x3 = x1*x2*x3))\n\n# Calculando os efeitos\nefeitos &lt;- crossprod(X, grao)/(3*2^3/2)\ncolnames(efeitos) &lt;- \"Efeitos\"\nefeitos\n\n       Efeitos\nI       18.225\nx1       0.425\nx2       4.775\nx3       4.025\nx1x2    -0.025\nx1x3    -0.075\nx2x3     1.075\nx1x2x3  -0.025\n\n\nGraficamente pode-se observar os efeitos lineares de forma simples, conforme ilustra a Figura 5.2. Todos os efeitos lineares foram positivos, de forma que o aumento nos níveis de \\(x_1\\), \\(x_2\\), e \\(x_3\\) acarreta um aumento no tamanho de grão. Observando o módulo dos efeitos calculados anteriormente e as inclinações das retas, os efeitos principais em ordem decrescente são \\(x_2\\), \\(x_3\\), e \\(x_1\\).\n\n\n\n\n\n\n\n\nFigura 5.2: Efeitos principais na resposta tamanho de grão\n\n\n\n\n\nÉ importante plotar as interações de segunda ordem graficamente. A Figura 7.8 apresenta os gráficos de interação de segunda ordem entre \\(x_1\\), \\(x_2\\) e \\(x_3\\). Pode-se confirmar que a maior interação foi \\(x_2x_3\\). Quando \\(x_3 = -1\\) o efeito de \\(x_2\\) é menor na resposta \\(y\\) em relação a \\(x_3 = +1\\). A interação consiste na mudança provocada no efeito de um fator dada a mudança simultânea no nível de outro fator. Todos os efeitos devem ser testados para averiguar a significância estatística. Os gráficos são um auxílio para interpretação prática dos mesmos. Pode-se observar que nmo gráfico da interação \\(x_2x_3\\) há maior diferença na inclinação entre as duas retas. O efeito de \\(x_2\\) na resposta tamanho de grão é maior quando \\(x_3 = +1\\). Pode-se constatar também que as médias relacionadas às quatro combinações desta interação estão mais próximas dos aglomerados formados pelas observações. Possivelmente ela terá maior efeito entre as interações.\n\n\n\n\n\n\n\n\nFigura 5.3: Interações na resposta tamanho de grão\n\n\n\n\n\nPor fim, um gráfico de interação de terceira ordem pode ser pensado considerando uma das variáveis em painéis. A Figura 5.4 expõe este gráfico.\n\n\n\n\n\n\n\n\nFigura 5.4: Interação de terceira ordem na resposta tamanho de grão\n\n\n\n\n\nUtilizando um planejamento fatorial \\(2^k\\) é possível estimar um modelo de regressão conforme o exposto na Equação 5.2. De forma genérica este modelo pode ser representado conforme Equação 5.3. Este modelo geral está truncado nas interações de segunda ordem, \\(\\beta_{ij}\\), porém poderiam constar nele interações de até k-ésima ordem. Um modelo de regressão fatorial deve ser hierárquico de forma que os todos os termos principais (efeitos lineares) contidos nas interações de segunda ordem que constam no modelo devem estar presentes no modelo.\n\\[\n  \\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_{12}x_1x_2 + \\beta_{13}x_1x_3 + \\beta_{23}x_2x_3\n\\tag{5.2}\\]\n\\[\n  \\hat{y} = \\beta_0 + \\displaystyle\\sum_{i=1}^{k}\\beta_ix_i+ \\displaystyle\\sum_{i\\ne}\\displaystyle\\sum_{j}\\beta_{ij}x_ix_j\n\\tag{5.3}\\]\nA partir dos efeitos, é possível obter coeficientes de regressão de forma simplória. A constante \\(\\beta_0\\) consiste na média de todos os \\(N\\) experimentos. A Figura 5.5 ilustra como o coeficiente linear deve ser interpretado para o fator \\(x_i\\), \\(i = 1, ..., k\\). O coeficiente linear, \\(\\beta_i\\), consiste na inclinação da reta, conforme expõe a Equação 5.4, e mede a mudança na resposta com o acréscimo de uma unidade codificada do fator de interesse. Estes coeficientes de regressão devem ser usados de forma codificada \\(x_i \\in [-1,+1]\\). Como cada interação pode ser representada em uma coluna como o produto dos fatores que interagem, o cálculo dos coeficientes das interações é feito de forma análoga. Tomando uma interação de segunda ordem entre os fatores \\(x_i\\) e \\(x_j\\), caso o coeficiente, \\(\\beta_{ij}\\), seja positivo, se os fatores que interagem são colocadas ambos no mesmo nível codificado, \\(x_ix_j = (-1)(-1)\\) ou \\(x_ix_j = (+1)(+1)\\), implica em um incremento na resposta igual ao valor do coeficiente. Ainda considerando o coeficiente positivo, se os fatores são colocadas em níveis codificados distintos, \\(x_ix_j = (-1)(+1)\\) ou \\(x_ix_j = (+1)(-1)\\), ocorre um decréscimo na resposta igual ao valor do coeficiente.\n\n\n\n\n\n\n\n\nFigura 5.5: Efeito linear no fatorial \\(2^k\\)\n\n\n\n\n\n\\[\n  \\beta_i = \\tan \\theta = \\frac{E_{x_{i}}}{2} \\text{,  } i = 1, ..., k\n\\tag{5.4}\\]\nConsiderando os efeitos obtidos anteriormente no R, pode-se obter os coeficientes de regressão com a sintaxe à seguir.\n\n# Cálculo dos coeficientes\nCoef &lt;- efeitos/2\ncolnames(Coef) &lt;- \"Coeficientes\"\nCoef\n\n       Coeficientes\nI            9.1125\nx1           0.2125\nx2           2.3875\nx3           2.0125\nx1x2        -0.0125\nx1x3        -0.0375\nx2x3         0.5375\nx1x2x3      -0.0125\n\n\nO modelo de regressão apresentado na Equação 5.4 é uma aproximação para a resposta de interesse, \\(\\hat{y}\\), servindo para prever a média da resposta considerando os limites (níveis) dos fatores testados experimentalmente. Mesmo se este modelo fosse completo, incluindo todas as interações possíveis até a interação de ordem \\(k\\), \\(\\beta_{ij...k}\\) no caso do fatorial replicado, com \\(N = n2^k\\) experimentos, há possibilidade de estimativa do erro experimental, considerando as \\(n\\) replicações experimentais de cada combinação. O erro experimental é decorrente de fatores incontroláveis presentes durante os ensaios e devido a imperfeições físicas do aparato experimental. Logo, se o modelo \\(\\hat{y}\\) apresenta erro, cada observação \\(y\\) pode ser descrita considerando o modelo de regressão adicionado do termo geral de erro ou resíduo, conforme Equação 5.5.\n\\[\n  \\hat{y} = \\beta_0 + \\displaystyle\\sum_{i=1}^{k}\\beta_ix_i+ \\displaystyle\\sum_{i\\ne}\\displaystyle\\sum_{j}\\beta_{ij}x_ix_j\n\\tag{5.5}\\]\nOs coeficientes de regressão também podem ser estimados utilizando o método dos mínimos quadrados. Seja o modelo de regressão fatorial somado do termo de erro apresentado em forma matricial conforme Equação 5.6.\n\\[\n  \\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\tag{5.6}\\]\nNo modelo da Equação 5.6 cada termo corresponde explicitamente a:\n\\[\\mathbf{y}_{[N \\times 1]} = \\begin{bmatrix}\n                     y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N                    \n\\end{bmatrix},\n\\boldsymbol{\\varepsilon}_{[N \\times 1]} = \\begin{bmatrix}\n\\varepsilon_1 \\\\ \\varepsilon_2 \\\\ \\vdots \\\\ \\varepsilon_N                 \n\\end{bmatrix},\n\\boldsymbol{\\beta}_{[r \\times 1]} = \\begin{bmatrix}\n     \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_k \\\\ \\beta_{12} \\\\ \\vdots \\\\ \\beta_{(k-1)k}                   \n\\end{bmatrix}\\]\n\\[\\mathbf{X}_{[N \\times r]} = \\begin{bmatrix}\n1 & x_{1(-)} & \\cdots & x_{k(-)} & x_{1(-)}x_{2(-)} & \\cdots & x_{k-1(-)}x_{k(-)}\\\\\n1 & x_{1(+)} & \\cdots & x_{k(-)} & x_{1(+)}x_{2(-)} & \\cdots & x_{k-1(-)}x_{k(-)}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots   & \\vdots        & \\ddots & \\vdots            \\\\\n1 & x_{1(+)} & \\cdots & x_{k(+)} & x_{1(+)}x_{2(+)} & \\cdots & x_{k-1(+)}x_{k(+)}\\\\\n\\end{bmatrix}\\]\nPode-se obter o vetor de valores previstos com o modelo \\(\\hat{\\mathbf{y}}= \\mathbf{X}\\boldsymbol{\\beta}\\). O objetivo do método de mínimos quadrados é escolher os coeficientes de regressão \\(\\boldsymbol{\\beta}\\) que minimizem a soma dos quadrados dos resíduos, \\(\\sum_{u=1}^{N}\\varepsilon_u^2 = \\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon}\\). Uma vez que os resíduos tem média nula, é necessário elevar ao quadrado para viabilizar a minimização destes. Tomando a Equação 5.6, o erro pode ser calculado como \\(\\boldsymbol{\\varepsilon}  = \\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}\\). Tomando o quadrado dos erros, tem-se:\n\\[\n\\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon} =\n(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\n\\] \\[\n\\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon} =\n\\mathbf{y}^T\\mathbf{y} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\] \\[\n\\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon} =\n\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\]\nMinimizando a soma dos quadrados dos resíduos em relação a \\(\\beta\\):\n\\[\n\\frac{\\partial\\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon}}{\\partial\\boldsymbol{\\beta}} =\n- 2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = 0\n\\]\nResolvendo para \\(\\hat{\\boldsymbol{\\beta}}\\), tem-se os estimadores de mínimos quadrados de \\(\\boldsymbol{\\beta}\\), conforme Equação 5.7.\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}(\\mathbf{X}^T\\mathbf{y})\n\\tag{5.7}\\]\nA ortogonalidade da matrix \\(\\mathbf{X}\\) implica na estimativa dos coeficientes de regressão de forma independente, isto é, todos os coeficientes são não correlacionados, com mínima variância. Os coeficientes de regressão podem ser obtidos no R com o código à seguir.\n\n# matrix X\nX &lt;- with(planej, cbind(I = 1, x1, x2, x3, \n                        x1x2 = x1*x2, x1x3= x1*x3, x2x3 = x2*x3,\n                        x1x2x3 = x1*x2*x3))\n\n# Coeficientes de mínimos quadrados\nbeta &lt;- (solve(t(X)%*%X))%*%(t(X)%*%grao)\n\nOs resíduos podem ser obtidos no R conforme segue.\n\n# resíduos\nresi &lt;- grao - X%*%beta\n\nÉ possível calcular a soma dos quadrados dos erros com a finalidade de posteriormente estimar a variância experimental. Uma vez que \\(\\boldsymbol{\\varepsilon}  = \\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{y} - \\hat{\\mathbf{y}}\\), tem-se a soma dos quadrados dos erros, conforme segue:\n\\[\nSS_E = \\displaystyle\\sum_{u=1}^{N}(y_u-\\hat{y}_u) =\n(\\mathbf{y} - \\hat{\\mathbf{y}})^T(\\mathbf{y} - \\hat{\\mathbf{y}})\n\\]\nTomando um planejamento com \\(N\\) experimentos para estimar um modelo com \\(r\\) termos, o número de graus de liberdade do erro experimental é \\(DF_E= N-r\\). Logo, a média dos quadrados dos erros, que estima a variância experimental, \\(\\hat{\\sigma}^2 = MS_E\\), pode ser obtida conforme Equação 5.8.\n\\[\nMS_E = \\frac{\\displaystyle\\sum_{u=1}^{N}(y_u-\\hat{y}_u)^2}{N-r}\n\\tag{5.8}\\]\nNo R pode-se obter a variância experimental conforme segue.\n\n# Número de ensaios\nN &lt;- dim(X)[1]\n# Número de termos\nr &lt;- dim(X)[2]\n\n# variância experimental - MSE\nmse &lt;- sum(resi^2)/(N-r)\nmse\n\n[1] 0.05875\n\n\nÉ possível testar a significância dos coeficientes de regressão utilizando a distribuição \\(t\\). Uma vez que o coeficiente de regressão linear consiste na mudança obtida na resposta com acréscimo de uma unidade, \\(\\beta_j\\) consiste no numerador da estatística do teste. Já o denominador da estatística do teste consiste no desvio-padrão da média, isto é \\(s/\\sqrt{N}=\\sqrt{MS_E/(n2^k)}\\), seguindo o teorema central do limite. Portanto, a estatística do teste \\(t\\) para os coeficientes de regressão é obtida pela Equação 5.9. A hipótese nula do teste é \\(H_0: \\beta_j = 0\\), enquanto a hipótese alternativa é \\(H_1: \\beta_j \\ne 0\\). Deste modo, se \\(|t_{\\beta_j}| &gt; |t_{(\\alpha/2,N-r)}|\\), rejeita-se \\(H_0\\).\n\\[\nt_{\\beta_j}= \\frac{\\beta_j}{\\sqrt{MS_E/(n2^k)}}\n\\tag{5.9}\\]\nPortanto, pode-se testar a significância dos coeficientes de regressão no R conforme segue. A condição \\(|t_{\\beta_j}| &gt; |t_{(\\alpha/2,N-r)}|\\) foi satisfeita para a constante \\(\\beta_0\\), para os coeficientes relacionados a \\(x_1\\), \\(x_2\\) e \\(x_3\\), ou seja, \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\) e para o coeficiente da interação entre \\(x_2x_3\\), \\(\\beta_{23}\\).\n\n# Desvio-padrão da média (erro padrão) dos coeficientes\nse_coef &lt;- sqrt(mse/N)\n\n# t calculado para os coeficientes\nt_beta &lt;- beta/(se_coef)\ncolnames(t_beta) &lt;- \"t0\"\nt_beta\n\n                t0\nI      184.1786251\nx1       4.2949748\nx2      48.2553051\nx3      40.6759378\nx1x2    -0.2526456\nx1x3    -0.7579367\nx2x3    10.8637598\nx1x2x3  -0.2526456\n\n# t tabelado\nt_tab &lt;- qt(p = 0.025, df = N-r)\nt_tab\n\n[1] -2.119905\n\n# p-valor \npvalue_t &lt;- 2*pt(q = abs(t_beta), df = N-r, lower.tail = F)\ncolnames(pvalue_t) &lt;- \"p-value\"\npvalue_t\n\n            p-value\nI      4.793840e-28\nx1     5.564585e-04\nx2     9.265472e-19\nx3     1.396616e-17\nx1x2   8.037592e-01\nx1x3   4.595076e-01\nx2x3   8.571502e-09\nx1x2x3 8.037592e-01\n\n\nAssociado ao teste \\(t\\) para os coeficientes de regressão pode-se construir um intervalo de confiança para os coeficientes de regressão conforme a Equação 5.10, onde \\(\\gamma = 1 - \\alpha\\) é o nível de confiança adotado.\n\\[\nIC_{\\beta_j,\\gamma}= \\beta_j \\pm t_{\\gamma}\\sqrt{MS_E/(n2^k)}\n\\tag{5.10}\\]\nAlém de testar a significância dos coeficientes de regressão utilizando o teste \\(t\\), no fatorial \\(2^k\\) é comum utilizar a análise de variância para testar a significância dos efeitos. A ANOVA testa a diferença entre médias considerando o particionamento da soma dos quadrados. No fatorial com dois níveis estas quantidades podem ser calculadas considerando o contraste entre as somas dos dois níveis considerados. Para o i-ésimo efeito principal a soma dos quadrados, \\(SS_{x_i}\\), pode ser calculada conforme a Equação 5.11. De forma análoga a soma dos quadrados para qualquer interação de segunda ordem \\(x_ix_j\\), \\(i \\ne j\\), pode ser calculada conforme a Equação 5.12, e de forma análoga para as interações de ordem maior. Para o i-ésimo efeito principal o número de graus de liberdade, no caso do fatorial de dois níveis, é sempre unitário, \\(DF_{x_i} = 2-1\\). O mesmo reside para os graus de liberdade das interações entre os fatores \\(x_ix_j\\), \\(i \\ne j\\), visto que a interação consiste no produto, ou seja, \\(DF_{x_ix_j} = DF_{x_i}DF_{x_j} = 1\\times1=1\\). Logo, a média dos quadrados para os efeitos em avaliação no fatorial \\(2^k\\) é igual à soma dos quadrados, , \\(MS_{x_i} = MS_{x_i}/1\\).\n\\[\nSS_{x_i} = \\frac{\\left(\\displaystyle\\sum_{x_{i}=+1}y - \\displaystyle\\sum_{x_{i}=-1}y\\right)^2}{n2^k}\n\\tag{5.11}\\] \\[\nSS_{x_ix_j} = \\frac{\\left(\\displaystyle\\sum_{x_{i}x_{j}=+1}y - \\displaystyle\\sum_{x_{i}x_{j}=-1}y\\right)^2}{n2^k}\n\\tag{5.12}\\]\nPara testar a significância dos efeitos no fatorial \\(2^k\\) via ANOVA deve-se calcular a estatística \\(F_{0(x_i)}\\), como a razão entre a média dos quadrados do efeito de interesse e a média dos quadrados dos erros, \\(F_{0(x_i)} = MS_{x_i}/MS_E\\). Se \\(F_0 &gt; F_{(\\alpha, 1, N-r)}\\), rejeita-se \\(H_0\\). O valor na distribuição \\(F\\) com um grau de liberdade unitário no numerador e \\(\\nu\\) graus de liberdade no numerador é igual ao quadrado do valor \\(t\\) com \\(\\nu\\) graus de liberdade, estando ambos associados à mesma probabilidade, isto é, \\(F_{(\\alpha,1,\\nu)}=t_{(\\alpha,\\nu)}^2\\). Deste modo, não há diferença na conclusão em relação à significância dos efeitos obtida com a ANOVA e com o teste \\(t\\) para os coeficientes de regressão. Entretanto, pelo sinal da estatística \\(t\\) já é possível afirmar se o efeito é positivo ou negativo, enquanto que a estatística \\(F\\) é sempre positiva, visto que \\(F \\in [0,+\\infty)\\). Em ambos os casos o p-valor será o mesmo e, logicamente, se \\(p-valor &lt; \\alpha\\), rejeita-se \\(H_0\\).\nPode-se utilizar o código seguir para obter os resultados da ANOVA.\n\n# Soma dos quadrados dos efeitos\nSSx &lt;- crossprod(X[,-1], grao)^2/(3*2^3)\n\n# Média dos quadrados dos efeitos\nMSx &lt;- SSx/1\ncolnames(MSx) &lt;- \"Média dos quadrados\" \nMSx\n\n       Média dos quadrados\nx1                 1.08375\nx2               136.80375\nx3                97.20375\nx1x2               0.00375\nx1x3               0.03375\nx2x3               6.93375\nx1x2x3             0.00375\n\n# Valor F calculado\nF0_x &lt;- MSx/mse\ncolnames(F0_x) &lt;- \"F0\" \nF0_x\n\n                 F0\nx1     1.844681e+01\nx2     2.328574e+03\nx3     1.654532e+03\nx1x2   6.382979e-02\nx1x3   5.744681e-01\nx2x3   1.180213e+02\nx1x2x3 6.382979e-02\n\n# F tabelado\nFtab &lt;- qf(p = 0.05, df1 = 1, df2 = N-r, lower.tail = F)\nFtab\n\n[1] 4.493998\n\n# P-valor\npvalue_F &lt;- pf(q = F0_x, df1 = 1, df2 = N-r, lower.tail = F)\ncolnames(pvalue_F) &lt;- \"p-valor\" \npvalue_F\n\n            p-valor\nx1     5.564585e-04\nx2     9.265472e-19\nx3     1.396616e-17\nx1x2   8.037592e-01\nx1x3   4.595076e-01\nx2x3   8.571502e-09\nx1x2x3 8.037592e-01\n\n\nPara avaliar a performance do modelo obtido, pode-se calcular as estatísticas de ajuste. Os coeficientes de determinação no fatorial \\(2^k\\) podem ser obtidos de forma análoga ao realizado na ANOVA para um fator. No R, o cálculo pode ser realizado conforme segue. Apesar do alto ajuste, foi observado que há alguns efeitos que não foram estatisticamente significativos. Deste modo, pode-se optar por reduzir o modelos caso seja desejável melhorar o ajuste. Para isto, basta remover a coluna do efeito a ser removido da matriz \\(\\mathbf{X}\\). Geralmente, ao se remover do modelo termos não significativos diminui-se o erro experimental, \\(\\hat{\\sigma}^2 = MS_E\\), uma vez que aumenta o número de graus de liberdade para estimativa deste. Consequentemente, aumenta-se \\(R_{aj}^2\\) e diminui-se \\(R^2\\), o que é positivo, visto que o primeiro é uma medida mais fiel para estimar a proporção da variabilidade dos dados explicada pelo modelo, por levar em conta o erro experimental. E quanto mais próximo o valor das duas medidas, mais confiáveis são.\n\n# coef de determinação simples\nR2 &lt;- sum(SSx)/sum(((grao)-mean(grao))^2)\nR2\n\n[1] 0.9961318\n\n# coef de determinação ajustado\nR2aj &lt;- 1 - mse/var(grao)\nR2aj\n\n[1] 0.9944394\n\n\nOs cálculos demonstrados para regressão, teste \\(t\\) para os coeficientes e ANOVA foram realizados com a finalidade de entender a modelagem e os testes passo a passo. Entretanto, o R possui pacotes e comandos estruturados que viabilizam um resultado organizado com menos trabalho.\nUtilizando o pacote FrF2 pode-se criar e analisar planejamentos fatorias \\(2^k\\). Junto com este pacote podem ser utilizadas funções base do R como lm e aov para obter, respectivamente, o modelo de regressão, teste \\(t\\) e a ANOVA. O primeiro passo é carregar o pacote FrF2.\n\n# carregando o pacote FrF2\nlibrary(FrF2)\n\nPode-se criar o planejamento com o comando FrF2. Observe que o planejamento pode ser criado considerando os níveis decodificados dos fatores de interesse. É possível aleatorizar os ensaios com randomize = T. Entretanto, só é recomendado a aleatorização ao gerar o planejamento antes de ir para o laboratório. Para apresentar os resultados em um trabalho acadêmico, a ordem padrão facilita a visualização dos efeitos e compreensão dos resultados. Posteriormente à criação do planejamento pode-se adicionar a resposta com o comando add.response.\n\n# Criando o planejamento\nplan &lt;- FrF2(nruns = 8, \n             nfactors = 3, \n             factor.names=list(x1=c(1000,1150),\n                               x2=c(800,950),\n                               x3=c(550,700)),\n             replications = 3,\n             randomize = F)\n\n# \nplan &lt;- add.response(plan, grao)\nsummary(plan)\n\nCall:\nFrF2(nruns = 8, nfactors = 3, factor.names = list(x1 = c(1000, \n    1150), x2 = c(800, 950), x3 = c(550, 700)), replications = 3, \n    randomize = F)\n\nExperimental design of type  full factorial \n8  runs\neach run independently conducted  3  times\n\nFactor settings:\n    x1  x2  x3\n1 1000 800 550\n2 1150 950 700\n\nResponses:\n[1] grao\n\nThe design itself:\n   run.no run.no.std.rp   x1  x2  x3 Blocks grao\n1       1           1.1 1000 800 550     .1  5.1\n2       2           2.1 1150 800 550     .1  5.6\n3       3           3.1 1000 950 550     .1  8.6\n4       4           4.1 1150 950 550     .1  9.1\n5       5           5.1 1000 800 700     .1  7.7\n6       6           6.1 1150 800 700     .1  8.4\n7       7           7.1 1000 950 700     .1 13.5\n8       8           8.1 1150 950 700     .1 14.0\n9       9           1.2 1000 800 550     .2  5.0\n10     10           2.2 1150 800 550     .2  5.7\n11     11           3.2 1000 950 550     .2  8.5\n12     12           4.2 1150 950 550     .2  9.2\n13     13           5.2 1000 800 700     .2  8.2\n14     14           6.2 1150 800 700     .2  8.3\n15     15           7.2 1000 950 700     .2 13.9\n16     16           8.2 1150 950 700     .2 14.1\n17     17           1.3 1000 800 550     .3  4.9\n18     18           2.3 1150 800 550     .3  5.2\n19     19           3.3 1000 950 550     .3  9.0\n20     20           4.3 1150 950 550     .3  9.3\n21     21           5.3 1000 800 700     .3  8.1\n22     22           6.3 1150 800 700     .3  8.5\n23     23           7.3 1000 950 700     .3 14.3\n24     24           8.3 1150 950 700     .3 14.5\nclass=design, type= full factorial \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\n\nUma forma mais simples de obter a matriz do planejamento é utilizando o comando model.matrix, conforme segue.\n\n# matriz do planejamento\nX &lt;- model.matrix(~x1*x2*x3, data=plan)\nX\n\n   (Intercept) x11 x21 x31 x11:x21 x11:x31 x21:x31 x11:x21:x31\n1            1  -1  -1  -1       1       1       1          -1\n2            1   1  -1  -1      -1      -1       1           1\n3            1  -1   1  -1      -1       1      -1           1\n4            1   1   1  -1       1      -1      -1          -1\n5            1  -1  -1   1       1      -1      -1           1\n6            1   1  -1   1      -1       1      -1          -1\n7            1  -1   1   1      -1      -1       1          -1\n8            1   1   1   1       1       1       1           1\n9            1  -1  -1  -1       1       1       1          -1\n10           1   1  -1  -1      -1      -1       1           1\n11           1  -1   1  -1      -1       1      -1           1\n12           1   1   1  -1       1      -1      -1          -1\n13           1  -1  -1   1       1      -1      -1           1\n14           1   1  -1   1      -1       1      -1          -1\n15           1  -1   1   1      -1      -1       1          -1\n16           1   1   1   1       1       1       1           1\n17           1  -1  -1  -1       1       1       1          -1\n18           1   1  -1  -1      -1      -1       1           1\n19           1  -1   1  -1      -1       1      -1           1\n20           1   1   1  -1       1      -1      -1          -1\n21           1  -1  -1   1       1      -1      -1           1\n22           1   1  -1   1      -1       1      -1          -1\n23           1  -1   1   1      -1      -1       1          -1\n24           1   1   1   1       1       1       1           1\nattr(,\"assign\")\n[1] 0 1 2 3 4 5 6 7\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x1\n     [,1]\n1000   -1\n1150    1\n\nattr(,\"contrasts\")$x2\n    [,1]\n800   -1\n950    1\n\nattr(,\"contrasts\")$x3\n    [,1]\n550   -1\n700    1\n\n\nPara realizar a análise basta utilizar o comando lm com o nome dado ao planejamento criado anteriormente como argumento. É importante utilizar o comando summary para exibir o resultado neste caso para ter não somente o modelo, mas também o teste da significância dos coeficientes. Pode-se observar que o pacote FrF2 apresenta o modelo com interações de até segunda ordem. A proposta da autora está de acordo com a adoção do fatorial \\(2^k\\) em estratégias sequenciais para obtenção de modelos quadráticos para otimização. Ao comparar os resultados obtidos abaixo com os obtidos anteriormente, é importante justificar que a diferença aqui é que o efeito de terceira ordem não foi considerado, de forma que o erro experimental ganha um grau de liberdade.\n\n# Regressão e teste t para coeficientes\n# O comando lm aqui é do pacote FrF2/DoE.base\nlm_grao &lt;- lm(plan) \nsummary(lm_grao)\n\nNumber of observations used: 24 \nFormula:\ngrao ~ (x1 + x2 + x3)^2\n\nCall:\nlm.default(formula = fo, data = model.frame(fo, data = formula))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.3875 -0.1125  0.0125  0.1125  0.4125 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.11250    0.04809 189.469  &lt; 2e-16 ***\nx11          0.21250    0.04809   4.418 0.000376 ***\nx21          2.38750    0.04809  49.642  &lt; 2e-16 ***\nx31          2.01250    0.04809  41.844  &lt; 2e-16 ***\nx11:x21     -0.01250    0.04809  -0.260 0.798060    \nx11:x31     -0.03750    0.04809  -0.780 0.446282    \nx21:x31      0.53750    0.04809  11.176 2.96e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2356 on 17 degrees of freedom\nMultiple R-squared:  0.9961,    Adjusted R-squared:  0.9947 \nF-statistic: 726.7 on 6 and 17 DF,  p-value: &lt; 2.2e-16\n\n\nPara testar os efeitos via ANOVA basta utilizar o código à seguir. Pode-se averiguar que os p-valores são iguais aos obtidos no teste \\(t\\).\n\n# ANOVA\nanova_grao &lt;- aov(lm_grao)\nsummary(anova_grao)\n\n            Df Sum Sq Mean Sq  F value   Pr(&gt;F)    \nx1           1   1.08    1.08   19.522 0.000376 ***\nx2           1 136.80  136.80 2464.279  &lt; 2e-16 ***\nx3           1  97.20   97.20 1750.955  &lt; 2e-16 ***\nx1:x2        1   0.00    0.00    0.068 0.798060    \nx1:x3        1   0.03    0.03    0.608 0.446282    \nx2:x3        1   6.93    6.93  124.899 2.96e-09 ***\nResiduals   17   0.94    0.06                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPosteriormente, pode-se prosseguir à análise das pressuposições. Pelo teste de Shapiro-Wilk confirma-se a não rejeição da hipótese de normalidade dos resíduos. Graficamente, pela Figura 5.6 pode-se confirmar a independência dos resíduos em relação aos valores previstos (residuals vs fitted), um bom ajuste dos resíduos em relação aos quantis da distribuição normal (normal Q-Q), a inexistência de outliers dos resíduos (scale-location) e homogeneidade dos resíduos nos níveis dos fatores (constant leverage).\n\n# Extraindo resíduos\nresi &lt;- lm_grao$residuals\n\n# Analisando normalidade\nshapiro.test(resi)\n\n\n    Shapiro-Wilk normality test\n\ndata:  resi\nW = 0.97971, p-value = 0.8904\n\n\n\n# Gráficos de resíduos\npar(mfrow=c(2,2))\nplot(lm_grao)\n\n\n\n\n\n\n\nFigura 5.6: Gráfico de resíduos para o tamanho de grão, modelo com termos de até segunda ordem\n\n\n\n\n\nA premissa de homocedasticidade da resposta de interesse considerando as replicações realizadas, deve ser confirmada. Em caso de heterocedasticidade o modelo de regressão não apresentará eficiência na previsão. O teste de homocedasticidade de Bartlett pode ser utilizado no R com a sintaxe à seguir. Deve-se utilizar a função interaction() para considerar a variância dentro das combinações dos níveis dos fatores. A hipótese nula do teste garante a homogeneidade de variância dos dados. Para o Exemplo 5.1 como \\(p-valor = 0,5306 &gt; 0,05 = \\alpha\\), não rejeita-se a hipótese de homocedasticidade do tamanho de grão.\n\n# teste de homocedasticidade\nbartlett.test(grao ~ interaction(x1,x2,x3), data=planej)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  grao by interaction(x1, x2, x3)\nBartlett's K-squared = 6.079, df = 7, p-value = 0.5306\n\n\nPode-se utilizar o pacote FrF2 para criar o planejamento e, ao invés de utilizar o comando lm deste pacote para análise, pode-se utilizar o comando homônimo base do R para análise. Isto permite obter modelos completos de terceira ordem ou maior ou modelos reduzidos de forma mais simples. O modelo completo, conforme o obtido passo a passo ao se explicar os cálculos relacionados à regressão e ANOVA, pode ser obtido conforme segue.\n\n# Modelo completo\nlm_grao3 &lt;- lm(formula = grao ~ (x1*x2*x3), data = plan)\nsummary(lm_grao3)\n\n\nCall:\nlm.default(formula = grao ~ (x1 * x2 * x3), data = plan)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -0.4   -0.1    0.0    0.1    0.4 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.11250    0.04948 184.179  &lt; 2e-16 ***\nx11          0.21250    0.04948   4.295 0.000556 ***\nx21          2.38750    0.04948  48.255  &lt; 2e-16 ***\nx31          2.01250    0.04948  40.676  &lt; 2e-16 ***\nx11:x21     -0.01250    0.04948  -0.253 0.803759    \nx11:x31     -0.03750    0.04948  -0.758 0.459508    \nx21:x31      0.53750    0.04948  10.864 8.57e-09 ***\nx11:x21:x31 -0.01250    0.04948  -0.253 0.803759    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2424 on 16 degrees of freedom\nMultiple R-squared:  0.9961,    Adjusted R-squared:  0.9944 \nF-statistic: 588.6 on 7 and 16 DF,  p-value: &lt; 2.2e-16\n\n\nCaso o analista queira obter o modelo com interações apenas de segunda ordem utilizando o comando lm base, pode-se utilizar o código à seguir.\n\n# Modelo de segunda ordem com comando lm base R\nlm_grao2 &lt;- lm(formula = grao ~ (x1+x2+x3)^2, data = plan)\nsummary(lm_grao2)\n\n\nCall:\nlm.default(formula = grao ~ (x1 + x2 + x3)^2, data = plan)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.3875 -0.1125  0.0125  0.1125  0.4125 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.11250    0.04809 189.469  &lt; 2e-16 ***\nx11          0.21250    0.04809   4.418 0.000376 ***\nx21          2.38750    0.04809  49.642  &lt; 2e-16 ***\nx31          2.01250    0.04809  41.844  &lt; 2e-16 ***\nx11:x21     -0.01250    0.04809  -0.260 0.798060    \nx11:x31     -0.03750    0.04809  -0.780 0.446282    \nx21:x31      0.53750    0.04809  11.176 2.96e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2356 on 17 degrees of freedom\nMultiple R-squared:  0.9961,    Adjusted R-squared:  0.9947 \nF-statistic: 726.7 on 6 and 17 DF,  p-value: &lt; 2.2e-16\n\n\nFinalmente, é possível reduzir o modelo automaticamente utilizando o comando step. Com este comando o algoritmo de eliminação passo a passo com o argumento direction com a opção backward inicia-se com o modelo completo e a cada passo retira-se o termo menos significativo de forma hierárquica, sendo realizada uma eliminação para trás. A cada termo removido o algoritmo considera o critério de informaçã de Akaike (Akaike information criteria - AIC), uma métrica que leva em consideração, não somente o erro do modelo, mas o número de termos, penalizando modelos mais complexos (maiores). Para o Exemplo 5.1 ao reduzir o modelo obteve-se o maior ajuste aquele com apenas os termos lineares e uma interação de segunda ordem, com \\(R_{aj}^2 = 0,9951\\). A interação \\(x_2x_3\\) permaneceu após a redução do modelo, confirmando a Figura 7.8.\n\n# Modelo reduzido\nlm_grao_red &lt;- step(lm_grao3, direction = \"backward\", trace=T)\n\nStart:  AIC=-61.76\ngrao ~ (x1 * x2 * x3)\n\n           Df Sum of Sq     RSS     AIC\n- x1:x2:x3  1   0.00375 0.94375 -63.663\n&lt;none&gt;                  0.94000 -61.758\n\nStep:  AIC=-63.66\ngrao ~ x1 + x2 + x3 + x1:x2 + x1:x3 + x2:x3\n\n        Df Sum of Sq    RSS     AIC\n- x1:x2  1    0.0037 0.9475 -65.568\n- x1:x3  1    0.0337 0.9775 -64.819\n&lt;none&gt;               0.9438 -63.663\n- x2:x3  1    6.9338 7.8775 -14.737\n\nStep:  AIC=-65.57\ngrao ~ x1 + x2 + x3 + x1:x3 + x2:x3\n\n        Df Sum of Sq    RSS     AIC\n- x1:x3  1    0.0337 0.9813 -66.728\n&lt;none&gt;               0.9475 -65.568\n- x2:x3  1    6.9338 7.8813 -16.726\n\nStep:  AIC=-66.73\ngrao ~ x1 + x2 + x3 + x2:x3\n\n        Df Sum of Sq    RSS     AIC\n&lt;none&gt;               0.9813 -66.728\n- x1     1    1.0837 2.0650 -50.870\n- x2:x3  1    6.9338 7.9150 -18.623\n\nsummary(lm_grao_red)\n\n\nCall:\nlm.default(formula = grao ~ x1 + x2 + x3 + x2:x3, data = plan)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.3375 -0.1437  0.0125  0.1375  0.4625 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.11250    0.04639 196.440  &lt; 2e-16 ***\nx11          0.21250    0.04639   4.581 0.000204 ***\nx21          2.38750    0.04639  51.468  &lt; 2e-16 ***\nx31          2.01250    0.04639  43.384  &lt; 2e-16 ***\nx21:x31      0.53750    0.04639  11.587 4.67e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2273 on 19 degrees of freedom\nMultiple R-squared:  0.996, Adjusted R-squared:  0.9951 \nF-statistic:  1172 on 4 and 19 DF,  p-value: &lt; 2.2e-16\n\n\nÉ importante confirmar as pressuposições acerca dos resíduos para o modelo escolhido ao final das análises. Pelo teste de normalidade de Shapiro- Wilk não há indícios para rejeição da hipótese de normalidade dos resíduos. A Figura 5.7 apresenta os gráficos de resíduos.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resi_red\nW = 0.97152, p-value = 0.7046\n\n\n\n\n\n\n\n\n\n\nFigura 5.7: Gráfico de resíduos para o tamanho de grão, modelo reduzido\n\n\n\n\n\nO gráfico de Pareto tem sido comumente utilizado para plotar o teste t para os coeficientes no fatorial \\(2^k\\), conforme Figura 5.8. Este gráfico pode ser obtido no R utilizando o pacote pid conforme segue. No caso estudado todos os efeitos foram positivos.\n\n\n\n\n\n\n\n\nFigura 5.8: Gráfico de Pareto dos efeitos\n\n\n\n\n\n\nlibrary(pid)\n\n\nPareto1 &lt;- paretoPlot(lm_grao_red, \n                      xlab=\"Efeito\", \n                      ylab=\"Magnitude\",\n                      legendtitle=\"Sinal efeito\",\n                      negative=c(\"Negativo\", \"blue\"),\n                      positive=c(\"Positivo\", \"red\"))\n\nPara obter os valores previstos pelo modelo \\(\\hat{y}\\), considerando o planejamento, pode-se proceder conforme segue, sendo as primeiras observações preditas pbservadas junto às observações do tamanho de grão na Tabela 5.4.\n\n# Valores previstos\ny_pred &lt;- lm_grao_red$fitted\n\n\n\n\n\nTabela 5.4: Primeiras observações e respectivas previsões\n\n\n\n\n\n\ngrao\nypred\n\n\n\n\n5.1\n5.0375\n\n\n5.6\n5.4625\n\n\n8.6\n8.7375\n\n\n9.1\n9.1625\n\n\n7.7\n7.9875\n\n\n8.4\n8.4125\n\n\n\n\n\n\n\n\nO experimentador pode também desejar utilizar o modelo obtido para prever observações em condições diferentes das testadas no planejamento. Entretanto, recomenda-se não extrapolar a região do planejamento, uma vez que o erro de previsão fora da região experimental é alto. Seja um ponto de interesse na região experimental para previsão \\(\\mathbf{x}_0^T = [x_1,...,x_k,x_{12},...,x_{(k-1)k}]^T\\), de ordem \\(r\\times1\\). Pode-se obter valor previsto neste ponto conforme Equação 5.13.\n\\[\n\\hat{y} = \\mathbf{x}_0^T\\boldsymbol{\\hat{\\beta}}\n\\tag{5.13}\\]\nPara prever novas observações pode-se utilizar o comando predict. Supondo que o experimentador deseja prever o tamanho de grão para \\(X_1 = 1100\\) ºC, \\(X_2 = 850\\) ºC e \\(X_3 = 600\\) ºC, é importante codificar estes valores antes de avaliá-los no modelo. A Equação 5.14 deve ser utilizada, onde \\(X_{j(0)} = (X_{j(+)}+X_{j(-)})/2\\). Para os níveis originais desejados os níveis codificados são \\(x_1 = 1/3\\), \\(x_2 = -1/3\\) e \\(x_3 = -1/3\\).\n\\[\nx_j = \\frac{X_j-X_{j(0)}}{(X_{j(+)}-X_{j(-)})/2}\n\\tag{5.14}\\]\nPara utilizar o comando predict recomenda-se que o planejamento não tenha sido criado via pacote FrF2. Deste modo, pode-se retomar o planejamento criado com o comando expand.grid e traçar um modelo reduzido a partir deste planejamento utilizando o comando lm obtido com este planejamento. É importante recordar que o fatorial \\(2^k\\) pode ser considerado para fatores categóricos, de forma que apenas previsões nás condições testadas no planejamento sejam possíveis.\n\n# Modelo completo utilizando planejamento planej\nlm4 &lt;- lm(formula = grao ~ (x1*x2*x3), data = planej)\n\n# Reduzindo lm4 via backward\nlm_red &lt;- step(lm4, direction = \"backward\", trace = F)\n\n# Valores de x para previsão\nx &lt;- data.frame(x1 = 1/3, \n                x2 = -1/3, \n                x3 = - 1/3)\n\n# Previsão\ny_pred &lt;- predict(object = lm_red, \n                  newdata = x)\ny_pred\n\n       1 \n7.776389 \n\n\nO experimentador pode desejar obter um modelo decodificado, isto é nas unidades originais. Para tal, sugere-se utilizar os comandos base R, conforme segue. Deve-se atentar para nunca realizar o teste \\(t\\) para o modelo nas unidades originais, evitando efeito de escala e unidades de medida no teste, sugerindo-se utilizá-lo para melhor interpretação e previsão.\n\n# Níveis decodificados\nX1 &lt;- c(1000, 1150) \nX2 &lt;- c(800, 950) \nX3 &lt;- c(550, 700)\n\n# Planejamento\nplan_decod &lt;- expand.grid(X1,X2,X3)\nplan_decod &lt;- rbind(plan_decod, plan_decod, plan_decod)\n\n# Resposta\ngrao &lt;-  c(5.1, 5.6, 8.6, 9.1, 7.7, 8.4, 13.5, 14,\n           5, 5.7, 8.5, 9.2, 8.2, 8.3, 13.9, 14.1,\n           4.9, 5.2, 9, 9.3, 8.1, 8.5, 14.3, 14.5)\nplan_decod$grao &lt;- grao\n\n# Nomes colunas\ncolnames(plan_decod) &lt;- c(\"X1\", \"X2\", \"X3\", \"y\")\n\n# Modelo completo\nlm_decod &lt;- lm(formula = grao ~ X1*X2*X3, data = plan_decod)\n\n# Modelo reduzido \nlm_decod &lt;- step(lm_decod, direction = \"backward\", trace = F)\n\n# apenas exibir, com modelo decodificado\n# nunca fazer teste t e ANOVA \nlm_decod\n\n\nCall:\nlm.default(formula = grao ~ X1 + X2 + X3 + X2:X3, data = plan_decod)\n\nCoefficients:\n(Intercept)           X1           X2           X3        X2:X3  \n  1.370e+01    2.833e-03   -2.789e-02   -5.678e-02    9.556e-05  \n\n# Valores de x para previsão\nX &lt;- data.frame(X1 = 1100, \n                X2 = 850, \n                X3 = 600)\n\n# Previsão\ny_pred_decod &lt;- predict(object = lm_decod, \n                  newdata = X)\ny_pred_decod\n\n       1 \n7.776389 \n\n\nPode-se utilizar o modelo nas unidades originais para obter gráficos de efeitos. A Figura 5.9 ilustra os gráficos de efeitos principais, com código esplicitado à seguir. É importante fixar a amplitude do eixo y para os três gráficos para fins de comparação dos efeitos, além de considerar os valores preditos para realizar o gráfico. Em um modelo completo usar a média das replicações daria no mesmo resultado que os valores previstos. Entretanto, ao se reduzir o modelo, as previsões são distintas das médias das réplicas.\n\nplan_decod$fit &lt;- lm_decod$fitted.values\n\nplan_dec_x1 &lt;- plan_decod |&gt;\n  group_by(X1, group=1) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nplan_dec_x2 &lt;- plan_decod |&gt;\n  group_by(X2, group=1) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nplan_dec_x3 &lt;- plan_decod |&gt;\n  group_by(X3, group=1) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nrange_y &lt;- (c(min(plan_dec_x1$y,plan_dec_x2$y,plan_dec_x3$y),\n              max(plan_dec_x1$y,plan_dec_x2$y,plan_dec_x3$y)))\n\npx1 &lt;- ggplot(plan_dec_x1, \n       aes(x=X1, y=y)) +\n  geom_line(col=\"blue\", lwd = 1) +\n  geom_point(col=\"blue\", size = 2) +\n  ylim(range_y) + \n  ylab(expression(\"y [\" * mu * \"m]\")) +\n  xlab(\"X1 [ºC]\")\n\npx2 &lt;- ggplot(plan_dec_x2, \n       aes(x=X2, y=y)) +\n  geom_line(col=\"green4\", lwd = 1) +\n  geom_point(col=\"green4\", size = 2) +\n  ylim(range_y) + ylab(expression(\"y [\" * mu * \"m]\")) +\n  xlab(\"X2 [ºC]\")\n\npx3 &lt;- ggplot(plan_dec_x3, \n       aes(x=X3, y=y)) +\n  geom_line(col=\"red\", lwd = 1) +\n  geom_point(col=\"red\", size = 2) +\n  ylim(range_y) + ylab(expression(\"y [\" * mu * \"m]\")) +\n  xlab(\"X3 [ºC]\")\n\nggarrange(px1, px2, px3, ncol = 3)\n\n\n\n\n\n\n\nFigura 5.9: Gráficos de efeitos principais para o modelo final\n\n\n\n\n\nA Figura 5.10 ilustra o gráfico de interação entre X2 e X3 para o modelo final, com código para obtê-lo exibido à seguir. As outras interações não serão consideradas, uma vez que não estão no modelo.\n\nplan_dec_means &lt;- plan_decod |&gt;\n  group_by(X2,X3) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nggplot(plan_dec_means, \n       aes(x=X2, group=X3, col=X3, y=y)) +\n  geom_line(aes(lty=X3), lwd = 1) +\n  geom_point(aes(shape=X3), size = 2) +\n  xlab(\"X2 [ºC]\") +\n  labs(col = \"X3 [ºC]\", lty = \"X3 [ºC]\", shape = \"X3 [ºC]\")\n\n\n\n\n\n\n\nFigura 5.10: Gráficos de interação entre X2 e X3 para o modelo final\n\n\n\n\n\nNos casos onde os fatores em estudo são quantitativos, é comum utilizar gráficos de contorno para visualizar o efeito de dois fatores de controle na resposta de interesse. Para tal fim pode-se utilizar o pacote gráfico ggplot2. O código à seguir permite a obtenção dos gráficos de contorno exibidos na Figura 5.11, considerando \\(x_2\\) no eixo horizontal, \\(x_3\\) no vertical e \\(x_1\\) fixo nos painéis. É possível adaptar o código considerando o fator \\(x_3\\) em um dos eixos. Neste caso optou-se por considerar a resposta em função das variáveis \\(x_2\\) e \\(x_3\\) por serem as mais significativas individualmente além de comporem a única interação significativa.\n\n# Malha\nX_levels &lt;- expand.grid(X1 = c(1000, 1150),\n                    X2 = seq(800, 950, by = 1),\n                    X3 = seq(550, 700, by = 1))\n\n# prevendo valores em toda malha\ny &lt;- as.data.frame(predict(lm_decod,\n                           newdata = X_levels))\ncolnames(y) &lt;- c(\"y\")\n\n# dados para gráfico\ndados &lt;- cbind(X_levels, y)\n\n# Gráfico de contorno\nggplot(data = dados,\n       mapping = aes(x = X2, y = X3, z = y, fill = y)) +\n  facet_wrap(facets = ~X1, labeller = label_both) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"RdYlGn\",\n                       direction = -1) +\n  geom_contour(color = \"navy\") +\n  coord_equal() + theme_bw()\n\n\n\n\n\n\n\nFigura 5.11: Gráfico de contorno do tamanho de grão em função de X2 e X3, com X1 = 1000 e X1 = 1150 ºC",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fatorial de dois níveis</span>"
    ]
  },
  {
    "objectID": "05-fat2k.html#propriedades-do-fatorial-2k",
    "href": "05-fat2k.html#propriedades-do-fatorial-2k",
    "title": "5  Fatorial de dois níveis",
    "section": "5.3 Propriedades do fatorial \\(2^k\\)",
    "text": "5.3 Propriedades do fatorial \\(2^k\\)\nÉ essencial entender as propriedades do planejamento fatorial \\(2^k\\) e suas implicações no erro experimental e na qualidade do modelo de regressão obtido. Seja o vetor de coeficientes de regressão obtido por mínimos quadrados, \\(\\mathbf{\\beta}\\) conforme Equação 5.7. No fatorial \\(2^k\\), pode-se constatar que\n\\[\n\\mathbf{X}^T\\mathbf{X} = \\mathbf{I}N\n\\]\nonde \\(\\mathbf{I}\\) é uma matriz identidade. Deste modo, \\((\\mathbf{X}^T\\mathbf{X})^{-1} = \\mathbf{I}/N\\), pois uma matriz diagonal pode ser invertida tomando os inversos dos elementos não nulos contidos na diagonal. Logo, os estimadores de mínimos quadrados, estritamente no caso do fatorial \\(2^k\\), podem ser ser reescritos conforme a Equação 5.15. Em outros planejamentos para modelos quadráticos ou em estudos de regressão sem experimentos planejados, \\(\\mathbf{X}^T\\mathbf{X}\\) e sua inversa não serão diagonais, não valendo a Equação 5.15.\n\\[\n\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}/N\n\\tag{5.15}\\]\nTomando a matrix \\(\\mathbf{X}\\) os momentos de primeira ordem desta matriz, os quais consistem na média de cada coluna, isto é, \\(\\sum_{u=1}^Nx_{iu}/N=0\\) sendo nulos garantem que o planejamento é balanceado, com cada fator sendo avaliado o mesmo número de vezes em cada nível.\nTomando a matrix \\(\\mathbf{X}\\) do planejamento os momentos de segunda ordem mistos da matriz, que consistem na média do produto de duas colunas distintas, também são nulos, isto é, \\(\\sum_{u=1}^Nx_{iu}x_{ju}/N=0\\), \\(i \\ne j\\) garantindo a independência na estimativa dos coeficientes. Já os momentos de segunda ordem puros são unitários, \\(\\sum_{u=1}^Nx_{iu}^2/N=1\\). Estes dois resultados garantem que \\(\\mathbf{X}^T\\mathbf{X}\\) é diagonal, garantindo a independência na estimativa dos coeficientes de regressão.\nPode-se demonstrar que a matriz \\(\\mathbf{X}^T\\mathbf{X}\\) é diagonal, conforme segue.\n\\[\\mathbf{X}^T\\mathbf{X} = \\begin{bmatrix}\n\\sum_{u=1}^N 1^2 & \\sum_{u=1}^N x_1x_2 & ... & \\sum_{u=1}^N x_1x_r \\\\\n\\sum_{u=1}^N x_2x_1 & \\sum_{u=1}^N x_1^2 & ... & \\sum_{u=1}^N x_2x_r \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sum_{u=1}^N x_rx_1 & \\sum_{u=1}^N x_rx_2 & ... & \\sum_{u=1}^N x_r^2 \\\\\n\\end{bmatrix} = \\begin{bmatrix}\nN & 0 & 0 & 0\\\\\n0 & N & 0 & 0\\\\\n0 & 0 & N & 0\\\\\n0 & 0 & 0 & N\\\\\n\\end{bmatrix} = \\mathbf{I}N\\]\nPode-se demonstrar que a variância dos coeficientes de regressão depende não somente do erro experimental, mas também do planejamento. Aplicando o operador de variância na Equação 5.7, tem-se:\n\\[\nVar(\\hat{\\boldsymbol{\\beta}}) = Var((\\mathbf{X}^T\\mathbf{X})^{-1}(\\mathbf{X}^T\\mathbf{y}))\n\\] \\[\nVar(\\hat{\\boldsymbol{\\beta}}) = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T)^TVar(\\mathbf{y})(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\n\\] \\[\nVar(\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}Var(\\mathbf{y})(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\] \\[\nVar(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{I}Var(\\mathbf{y})(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\] \\[\nVar(\\hat{\\boldsymbol{\\beta}}) = \\hat\\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\tag{5.16}\\]\nÉ importante recordar que constantes saem do operador de variância elevadas ao quadrado, o que em operação matricial equivale a multiplicar pela transposta. A transposta de uma matriz diagonal também é a própria matriz diagonal e uma matriz ao ser multiplicada por sua inversa resulta em uma matriz identidade. Logo, a variância dos coeficientes depende da variância experimental \\(\\hat\\sigma^2 = MS_E\\) e da variância do planejamento \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\), que consiste em uma matriz diagonal de ordem \\(r \\times r\\).\nComo no caso dos fatoriais \\(2^k\\) a variância da matriz \\(\\mathbf{X}\\) é a razão entre uma matriz identidade e o número de experimentos, isto é, \\((\\mathbf{X}^T\\mathbf{X})^{-1} = \\mathbf{I}/N = \\mathbf{I}/(n2^k)\\), a variância de cada coeficiente pode ser escrita conforme a Equação 5.17. Logo, quanto maior o número de replicações, menor a variância dos coeficientes. Este resultado é uma implicação do teorema central do limite.\n\\[\nVar(\\hat{\\beta}_i) = \\hat{\\sigma}^2/N\n\\tag{5.17}\\]\nA variância de previsão em um ponto de interesse \\(\\mathbf{x}_0\\) na região experimental pode ser escrita conforme segue, aplicando o operador de variância na Equação 5.13.\n\\[\nVar(\\hat{y}) = Var(\\mathbf{x}_0^T\\boldsymbol{\\hat{\\beta}})\n\\] \\[\nVar(\\hat{y}) = \\mathbf{x}_0^TVar(\\boldsymbol{\\hat{\\beta}})\\mathbf{x}_0\n\\] \\[\nVar(\\hat{y}) = \\mathbf{x}_0^TVar(\\boldsymbol{\\hat{\\beta}})\\mathbf{x}_0\n\\] \\[\nVar(\\hat{y}) = \\mathbf{x}_0^T\\hat{\\sigma}^2(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{x}_0\n\\] \\[\nVar(\\hat{y}) = \\hat{\\sigma}^2\\mathbf{x}_0^T(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{x}_0\n\\tag{5.18}\\]\nLogo, a variância de previsão depende do ponto de interesse \\(\\mathbf{x}_0\\) na região experimental, da variância do planejamento \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\) e da variância experimental \\(\\hat{\\sigma}^2\\).\nUma vez que a variância de previsão depende do erro experimental, pode-se utilizar uma medida escalonada de variância,dividindo o resultado da Equação 5.18 pela variância experimental \\(\\hat{\\sigma^2}\\) e multiplicando por \\(N\\), obtendo-se a variância escalonada de previsão scaled prediction variance (SPV), conforme a Equação 5.19. Ao multiplicar a medida por \\(N\\) previne-se o aumento do número de replicações para diminuir a variância do planejamento, uma vez que aumentar o número de ensaios implica em aumento nos custos de experimentação, contrariando o princípio de economia na experimentação. Já ao dividir por \\(\\hat{\\sigma}^2\\) obtém-se uma medida livre do erro experimental, de forma que a \\(SPV\\) pode ser usada para comparar planejamentos.\n\\[\nSPV = Var(\\hat{y})N/\\hat{\\sigma}^2 = N\\mathbf{x}_0^T(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{x}_0\n\\tag{5.19}\\]\nPode-se obter a matriz de variância do planejamento, com a seguinte sintaxe no R.\n\n\n  (Intercept) x1 x2 x3 x1:x2 x1:x3 x2:x3 x1:x2:x3\n1           1 -1 -1 -1     1     1     1       -1\n2           1  1 -1 -1    -1    -1     1        1\n3           1 -1  1 -1    -1     1    -1        1\n4           1  1  1 -1     1    -1    -1       -1\n5           1 -1 -1  1     1    -1    -1        1\n6           1  1 -1  1    -1     1    -1       -1\n7           1 -1  1  1    -1    -1     1       -1\n8           1  1  1  1     1     1     1        1\nattr(,\"assign\")\n[1] 0 1 2 3 4 5 6 7\n\n\n            (Intercept)    x1    x2    x3 x1:x2 x1:x3 x2:x3 x1:x2:x3\n(Intercept)       0.125 0.000 0.000 0.000 0.000 0.000 0.000    0.000\nx1                0.000 0.125 0.000 0.000 0.000 0.000 0.000    0.000\nx2                0.000 0.000 0.125 0.000 0.000 0.000 0.000    0.000\nx3                0.000 0.000 0.000 0.125 0.000 0.000 0.000    0.000\nx1:x2             0.000 0.000 0.000 0.000 0.125 0.000 0.000    0.000\nx1:x3             0.000 0.000 0.000 0.000 0.000 0.125 0.000    0.000\nx2:x3             0.000 0.000 0.000 0.000 0.000 0.000 0.125    0.000\nx1:x2:x3          0.000 0.000 0.000 0.000 0.000 0.000 0.000    0.125\n\n\nO pacote vdg é uma opção para obter a SPV em função do raio do planejamento. A Figura 5.12 plota a variância escalonada de previsão em função do raio do planejamento para o fatorial \\(2^3\\). Este tipo de gráfico é chamado de gráfico de dispersão de variância. Pode-se observar que à medida que o ponto de interesse se afasta do centro do planejamento, a variância escalonada de previsão aumenta. É natural, portanto, que fora da região experimental, isto é, fora dos limites do planejamento, a capacidade de previsão do modelo obtido seja baixa, visto que as variâncias do planejamento e de previsão aumentam com o aumento da distância do centro do planejamento.\n\n# Carregando pacote vdg\nlibrary(vdg)\n\n\n# gerando valores de spv p/ planejamento pl\nout &lt;- spv(n = 10000, design = pl, type = \"cuboidal\", formula = ~(x1*x2*x3))\n\n# plotando (função plot do pacote vdg)\nplot(out, which = \"fds\")$fds + theme_bw() + ggtitle(\"\")\n\n\n\n\n\n\n\nFigura 5.12: Gráfico de dispersão de variância para o fatorial \\(2^k\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fatorial de dois níveis</span>"
    ]
  },
  {
    "objectID": "05-fat2k.html#bibliografia",
    "href": "05-fat2k.html#bibliografia",
    "title": "5  Fatorial de dois níveis",
    "section": "Bibliografia",
    "text": "Bibliografia\nBANCROFT, Theodore Alfonso. On biases in estimation due to the use of preliminary tests of significance. The Annals of Mathematical Statistics, v. 15, n. 2, p. 190-204, 1944.\nBARNARD, M. M. An Enumeration of the Confounded Arrangements in the 2× 2× 2… Factorial Designs. Supplement to the Journal of the Royal Statistical Society, v. 3, n. 2, p. 195-202, 1936.\nBOX, G. E. P. Multi-factor designs of first order. Biometrika, v. 39, n. 1-2, p. 49-57, 1952.\nCOX, D. R. Some systematic experimental designs. Biometrika, v. 38, n. 3/4, p. 312-323, 1951.\nFANG, Kai-Tai et al. Uniform design: theory and application. Technometrics, v. 42, n. 3, p. 237-248, 2000.\nFISHER, Ronald A. The design of experiments. 1949.\nIS’ HAQ, A. Mohammed et al. Full factorial design approach to carbon nanotubes synthesis by CVD method in argon environment. South african journal of chemical engineering, v. 24, p. 17-42, 2017.\nKELLY, Matthew R. et al. Experimental investigation of linear friction welding of AISI 1020 steel with pre-heating. Journal of Manufacturing Processes, v. 39, p. 26-39, 2019.\nMEE, Robert. A comprehensive guide to factorial two-level experimentation. Springer Science & Business Media, 2009.\nSNEDECOR, G. W. Statistical Methods: Applied to Experiments in Agriculture.. 1956.\nYATES, Frank. The design and analysis of factorial experiments. Harpenden, UK: Imperial Bureau of Soil Science, 1978.\nZHANG, Chunyong et al. Anodic treatment of acrylic fiber manufacturing wastewater with boron-doped diamond electrode: a statistical approach. Chemical Engineering Journal, v. 161, n. 1-2, p. 93-98, 2010.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fatorial de dois níveis</span>"
    ]
  },
  {
    "objectID": "06-fatunrep_frac.html",
    "href": "06-fatunrep_frac.html",
    "title": "6  Fatorial de dois níveis não replicado e fracionado",
    "section": "",
    "text": "6.1 Introdução\nO fatorial \\(2^k\\) é um planejamento essencial ao DOE por permitir diversas estratégias na experimentação, desde a economia experimental, a partir de planejamentos não replicados ou fracionados, blocagem de variáveis controláveis porém indesejáveis, além da busca de região de curvatura e complementação do planejamento para obtenção de modelos passíveis de otimização.\nNeste capítulo, será apresentado o planejamento fatorial \\(2^k\\) não replicado. Em seguida serão explicados os conceitos de blocagem. confundimento no fatorial \\(2^k\\). O planejamento fatorial fracionado \\(2^{k-p}\\) é exposto a partir dos conceitos de confundimento anteriormente apresentados.\nNeste capítulo são utilizados os pacotes FrF2 e unrepx, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fatorial de dois níveis não replicado e fracionado</span>"
    ]
  },
  {
    "objectID": "06-fatunrep_frac.html#fatorial-2k-sem-replicar",
    "href": "06-fatunrep_frac.html#fatorial-2k-sem-replicar",
    "title": "6  Fatorial de dois níveis não replicado e fracionado",
    "section": "6.2 Fatorial \\(2^k\\) sem replicar",
    "text": "6.2 Fatorial \\(2^k\\) sem replicar\nO fatorial \\(2^k\\) não replicado consiste em um caso particular do fatorial \\(2^k\\) com \\(n = 1\\). Especialmente quando há muitos fatores \\(k\\) de interesse a serem analisados, o fatorial \\(2^k\\) não replicado tem sido utilizado, visto que o custo da replicação é alto. É possível obter o modelo de regressão completo, porém não é possível testar os efeitos via teste \\(t\\) ou ANOVA, uma vez que não há graus de liberdade remanescentes para estimar o erro experimental, uma vez que o número total de experimentos é igual ao número de termos no modelo completo, \\(N = 2^k = r\\).\nExistem métodos alternativos para estimar o erro experimental considerando os efeitos mais esparços, isto é, os efeitos de menor magnitude. Estes métodos se baseiam no princípio da esparcidade dos efeitos que garantem que poucos efeitos apresentam magnitude não desprezível, enquanto a maior parte dos efeitos investigados é esparça. Outra possibilidade de estimativa do erro experimental pode ser realizada a partir da redução hierárquica do modelo e, deste modo, testar a significância dos efeitos de menor ordem. Geralmente, os efeitos de menor ordem explicam melhor a variabilidade dos dados. Modelos saturados e com termos de ordem maior além de difícil interpretação, geralmente apresentam maior variabilidade.\n\nExemplo 6.1 Um fatorial \\(2^4\\) não replicado foi usado para estudar o tratamento eletroquímico de águas residuais de fabricação de fibra acrílica com eletrodo de diamante dopado com boro. Os fatores considerados foram o tempo de tratamento (1-2 horas), a vazão (400-600 mL/min), intensidade de corrente (0,50-1,00 A) e carga inicial de demanda química de oxigênio (362- 723 mg/L) na eficiência do tratamento.\n\n\n\n\n\nTabela 6.1: Planejamento fatorial 2^4 não replicado, tratamento efluentes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nordem\nTempo [h]\nVazão [mL/min]\nCorrente [A]\nDQO [mg/L]\nRemoção de DQO [%]\n\n\n\n\n1\n1\n400\n0.5\n362\n43.4\n\n\n2\n2\n400\n0.5\n362\n54.1\n\n\n3\n1\n600\n0.5\n362\n48.6\n\n\n4\n2\n600\n0.5\n362\n65.5\n\n\n5\n1\n400\n1.0\n362\n59.7\n\n\n6\n2\n400\n1.0\n362\n61.9\n\n\n7\n1\n600\n1.0\n362\n56.9\n\n\n8\n2\n600\n1.0\n362\n71.3\n\n\n9\n1\n400\n0.5\n723\n47.4\n\n\n10\n2\n400\n0.5\n723\n69.2\n\n\n11\n1\n600\n0.5\n723\n38.5\n\n\n12\n2\n600\n0.5\n723\n70.5\n\n\n13\n1\n400\n1.0\n723\n55.9\n\n\n14\n2\n400\n1.0\n723\n79.9\n\n\n15\n1\n600\n1.0\n723\n65.7\n\n\n16\n2\n600\n1.0\n723\n79.3\n\n\n\n\n\n\n\n\nPode-se criar o planejamento utilizando o pacote FrF2 do R.\n\n# carregando o pacote FrF2\nlibrary(FrF2)\n\n\n# Criando o planejamento\nplan_eflu &lt;- FrF2(nruns = 16, \n             nfactors = 4, \n             factor.names=list(Tem=c(1,2),\n                               Vaz=c(400,600),\n                               Cor=c(0.5,1),\n                               DQO=c(362,723)),\n             replications = 1,\n             randomize = F)\n\n\n# Energia em [kJ]\ny &lt;- c(43.4, 54.1, 48.6, 65.5, 59.7, 61.9, 56.9, 71.3, 47.4, 69.2, 38.5, 70.5, 55.9, 79.9, 65.7, 79.3)\n\nplan_eflu &lt;- add.response(plan_eflu, y)\nsummary(plan_eflu)\n\nCall:\nFrF2(nruns = 16, nfactors = 4, factor.names = list(Tem = c(1, \n    2), Vaz = c(400, 600), Cor = c(0.5, 1), DQO = c(362, 723)), \n    replications = 1, randomize = F)\n\nExperimental design of type  full factorial \n16  runs\n\nFactor settings:\n  Tem Vaz Cor DQO\n1   1 400 0.5 362\n2   2 600   1 723\n\nResponses:\n[1] y\n\nThe design itself:\n   Tem Vaz Cor DQO    y\n1    1 400 0.5 362 43.4\n2    2 400 0.5 362 54.1\n3    1 600 0.5 362 48.6\n4    2 600 0.5 362 65.5\n5    1 400   1 362 59.7\n6    2 400   1 362 61.9\n7    1 600   1 362 56.9\n8    2 600   1 362 71.3\n9    1 400 0.5 723 47.4\n10   2 400 0.5 723 69.2\n11   1 600 0.5 723 38.5\n12   2 600 0.5 723 70.5\n13   1 400   1 723 55.9\n14   2 400   1 723 79.9\n15   1 600   1 723 65.7\n16   2 600   1 723 79.3\nclass=design, type= full factorial \n\n\nÉ possível calcular os efeitos no R conforme segue.\n\n# construindo a matrix X\nlevels &lt;- c(-1, +1)\nplan2&lt;- expand.grid(levels,levels,levels,levels)\ncolnames(plan2) &lt;- c(\"x1\",\"x2\",\"x3\",\"x4\")\n\nX &lt;- with(plan2, cbind(I = 1, x1, x2, x3, x4, x1x2 = x1*x2, x1x3 = x1*x3,\n                       x1x4 = x1*x4,  x2x3 = x2*x3, x2x4 = x2*x4, \n                       x3x4 = x3*x4, x1x2x3 = x1*x2*x3, x1x2x4 = x1*x2*x4,\n                       x1x3x4 = x1*x3*x4, x2x3x4 = x2*x3*x4, \n                       x1x2x3x4 = x1*x2*x3*x4))\n\n# Calculando os efeitos\nefeitos &lt;- crossprod(X, y)/(1*2^4/2)\ncolnames(efeitos) &lt;- \"Efeitos\"\nefeitos\n\n         Efeitos\nI        120.975\nx1        16.950\nx2         3.100\nx3        11.675\nx4         5.625\nx1x2       2.275\nx1x3      -3.400\nx1x4       5.900\nx2x3       0.850\nx2x4      -2.700\nx3x4       2.125\nx1x2x3    -1.825\nx1x2x4    -2.325\nx1x3x4    -0.650\nx2x3x4     3.350\nx1x2x3x4  -3.325\n\n\nPosteriormente pode-se obter os coeficientes de regressão conforme segue.\n\n# Cálculo dos coeficientes\nCoef &lt;- efeitos/2\ncolnames(Coef) &lt;- \"Coeficientes\"\nCoef\n\n         Coeficientes\nI             60.4875\nx1             8.4750\nx2             1.5500\nx3             5.8375\nx4             2.8125\nx1x2           1.1375\nx1x3          -1.7000\nx1x4           2.9500\nx2x3           0.4250\nx2x4          -1.3500\nx3x4           1.0625\nx1x2x3        -0.9125\nx1x2x4        -1.1625\nx1x3x4        -0.3250\nx2x3x4         1.6750\nx1x2x3x4      -1.6625\n\n\nUma vez que \\(N = 2^4 = 16\\) e \\(r = 16\\), não há graus de liberdade para estimar o erro experimental, pois \\(DF_E= N - r = 0\\). Deste modo, os métodos tradicionais para testar a significância dos efeitos, isto é, o teste \\(t\\) e a ANOVA não podem ser realizados.\nPode-se testar a significância dos efeitos utilizando o pseudo erro padrão de Lenth. Sejam \\(E_1\\), \\(E_2\\)…, \\(E_{N-1}\\) os efeitos estimados em um fatorial \\(2^k\\) não replicado. Seja \\(s_0\\), onde \\(\\widetilde{|E_j|}\\) é a mediana dos efeitos padonizados.\n\\[\ns_0 = 1,5\\widetilde{|E_j|}\n\\]\nEntão, o pseudo erro padrão de Lenth (pseudo standard error- PSE) é calculado de forma análoga, porém considerando apenas os efeitos esparsos. Estes efeitos desprezíveis são levados em consideração no cálculo, conforme Equação 6.1, visto que podem representar o erro aleatório do processo em estudo.\n\\[\nPSE = 1,5\\underbrace{\\widetilde{|E_j|}}_{|E_j|&lt;2,5s_0}\n\\tag{6.1}\\]\nDefine-se um intervalo de 0,95 de confiança para o erro, com o limite denominado de erro marginal, \\(ME\\), conforme Equação 6.2. Pode-se também construir um intervalo de confiança para o i-ésimo efeito como \\(E_j \\pm ME\\).\n\\[\nME= t_{(0,975;m/3)}PSE\n\\tag{6.2}\\]\nQuando o número de efeitos \\(N-1\\) testados é alto, pode acontecer de efeitos inativos serem significativos. Deste modo, pode-se usar como alternativa a margem de erro simultânea, \\(SME\\), conforme Equação 6.3, onde \\(\\gamma = (1+0,95^{1/m})/2\\).\n\\[\nSME= t_{(\\gamma;m/3)}PSE\n\\tag{6.3}\\]\nO pacote unrepx do R, de autoria do próprio Lenth, pode ser utilizado para análise da significância dos efeitos considerando o pseudo erro padrão.\n\n# carregando o pacote unrepx\nlibrary(unrepx)\n\nPrimeiramente, deve-se tomar os efeitos, \\(E_1\\), …, \\(E_{N-1}\\). O comando yates do pacote unrepx permite a estimativa dos efeitos sem a necessidade da matriz \\(\\textbf{X}\\), conforme segue.\n\n# Efeitos\nefeitos &lt;- yates(y)\nefeitos\n\n     A      B     AB      C     AC     BC    ABC      D     AD     BD    ABD \n16.950  3.100  2.275 11.675 -3.400  0.850 -1.825  5.625  5.900 -2.700 -2.325 \n    CD    ACD    BCD   ABCD \n 2.125 -0.650  3.350 -3.325 \nattr(,\"mean\")\n        \n60.4875 \n\n\nO chamado half normal plot ou gráfico de Daniel, permite observar os efeitos mais importantes. Neste gráfico, os efeitos são plotados de forma padronizada e ordenada em relação aos quantis da distribuição normal. Quanto maior o desvio da reta onde devem se encontrar os efeitos esparços, mais importante o efeito. Entretanto, ele funciona melhor quando há poucos efeitos influentes entre os \\(N-1\\) estimados. Os efeitos positivos são plotados em vermelho e os negativos em azul. Para o Exemplo 6.2 o half normal plot é apresentado na Figura 6.1. Pode-se concluir que os efeitos A e C são significativos considerando o erro marginal de Lenth.\n\nhnplot(efeitos, half = T, method = \"Lenth\", ID = ME(efeitos))\n\n\n\n\n\n\n\nFigura 6.1: Half normal plot para os efeitos no experimento de tratamento de efluentes\n\n\n\n\n\nO gráfico de Pareto tem sido comumente utilizado para plotar os efeitos em relação ao erro marginal, \\(ME\\), e ao erro marginal simultâneo, \\(SME\\). Para o Exemplo 6.2 o gráfico de Pareto é plotado na Figura 6.2. Pelo primeiro critério temos a mesma conclusão obtida pelo método gráfico de Daniel, enquanto pelo segundo critério apenas o efeito do fator A é significativo.\n\n# Pareto PSE plot\nparplot(efeitos, method = \"Lenth\")\n\n\n\n\n\n\n\nFigura 6.2: Gráfico de Pareto dos efeitos padronizados para o exemplo\n\n\n\n\n\nFinalmente, é possível resumir a análise da significância dos efeitos, conforme segue. O valor da estatística calculada \\(t\\) é obtido tomando a razão entre o efeito e o pseudo erro padrão de Lenth, isto é, \\(t_j = E_j/PSE\\). As conclusões são as mesmas das obtidas graficamente considerando o p-valor para \\(ME\\) e para o \\(SME\\).\n\n# Análise da significância dos efeitos\neff.test(efeitos, method = \"Lenth\")\n\n     effect Lenth_PSE t.ratio p.value simult.pval\nA    16.950      4.05   4.185  0.0058      0.0499\nC    11.675      4.05   2.883  0.0217      0.1860\nAD    5.900      4.05   1.457  0.1469      0.8376\nD     5.625      4.05   1.389  0.1635      0.8778\nAC   -3.400      4.05  -0.840  0.3728      0.9996\nBCD   3.350      4.05   0.827  0.3793      0.9996\nABCD -3.325      4.05  -0.821  0.3829      0.9996\nB     3.100      4.05   0.765  0.4164      1.0000\nBD   -2.700      4.05  -0.667  0.5399      1.0000\nABD  -2.325      4.05  -0.574  0.6012      1.0000\nAB    2.275      4.05   0.562  0.6089      1.0000\nCD    2.125      4.05   0.525  0.6322      1.0000\nABC  -1.825      4.05  -0.451  0.6819      1.0000\nBC    0.850      4.05   0.210  0.8482      1.0000\nACD  -0.650      4.05  -0.160  0.8833      1.0000\n\n\nOutra possibilidade em relação ao fatorial \\(2^k\\) não replicado é a estimativa do erro experimental utilizando graus de liberdade dos efeitos esparços desconsiderados. Para proceder desta forma podemos retomar o uso do pacote FrF2. Fazando a análise com o comando lm deste pacote apenas os efeitos de até segunda ordem são estimados. Consequentemente, a soma dos quadrados e os graus de liberdade dos erros são obtidos considerando os efeitos de terceira ordem ou maior. O resultado abaixo expõe o modelo de regressão e o teste t para os coeficientes. Os efeitos significativos foram os do Tempo e da Corrente, os mesmos significativos via \\(ME\\) de Lenth. Caso o experimentador queira continuar a investigação para procurar região de curvatura e um modelo quadrático, pode-se o modelo com interações de até segunda ordem é uma boa opção, além de ser de fácil interpretação.\n\n# Análise via FrF2\nlm_eflu &lt;- lm(plan_eflu)\nsummary(lm_eflu)\n\nNumber of observations used: 16 \nFormula:\ny ~ (Tem + Vaz + Cor + DQO)^2\n\nCall:\nlm.default(formula = fo, data = model.frame(fo, data = formula))\n\nResiduals:\n      1       2       3       4       5       6       7       8       9      10 \n-0.9375 -2.4125  1.5875  1.7625  3.2625  0.0875 -3.9125  0.5625  2.7625  0.5875 \n     11      12      13      14      15      16 \n-3.4125  0.0625 -5.0875  1.7375  5.7375 -2.3875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   60.487      1.254  48.246 7.23e-08 ***\nTem1           8.475      1.254   6.760  0.00108 ** \nVaz1           1.550      1.254   1.236  0.27125    \nCor1           5.838      1.254   4.656  0.00555 ** \nDQO1           2.812      1.254   2.243  0.07490 .  \nTem1:Vaz1      1.137      1.254   0.907  0.40586    \nTem1:Cor1     -1.700      1.254  -1.356  0.23314    \nTem1:DQO1      2.950      1.254   2.353  0.06532 .  \nVaz1:Cor1      0.425      1.254   0.339  0.74839    \nVaz1:DQO1     -1.350      1.254  -1.077  0.33076    \nCor1:DQO1      1.062      1.254   0.847  0.43541    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.015 on 5 degrees of freedom\nMultiple R-squared:  0.9439,    Adjusted R-squared:  0.8317 \nF-statistic: 8.413 on 10 and 5 DF,  p-value: 0.01486\n\n\nOutra possibilidade é utilizar o comando lm para obter um modelo completo e reduzir o modelo. Pode-se também selecionar o modelo considerando a simplicidade na interpretação. Pelas análises realizadas o modelo reduzido com o comando step via opção backward presentou o maior ajuste, com menor AIC e maior coeficiente de determinação múltipla ajustado, \\(R_{aj}^2 = 0,8464\\). É importante recortdar que antes de aplicar o comando step, devse-se remover um coeficiente manualmente, sempre o de maior ordem.\n\n# Modelo completo\nlm_eflu2 &lt;- lm(formula = y ~ (Tem + Vaz + Cor + DQO)^4, data = plan_eflu)\nsummary(lm_eflu2)\n\n\nCall:\nlm.default(formula = y ~ (Tem + Vaz + Cor + DQO)^4, data = plan_eflu)\n\nResiduals:\nALL 16 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)          60.4875        NaN     NaN      NaN\nTem1                  8.4750        NaN     NaN      NaN\nVaz1                  1.5500        NaN     NaN      NaN\nCor1                  5.8375        NaN     NaN      NaN\nDQO1                  2.8125        NaN     NaN      NaN\nTem1:Vaz1             1.1375        NaN     NaN      NaN\nTem1:Cor1            -1.7000        NaN     NaN      NaN\nTem1:DQO1             2.9500        NaN     NaN      NaN\nVaz1:Cor1             0.4250        NaN     NaN      NaN\nVaz1:DQO1            -1.3500        NaN     NaN      NaN\nCor1:DQO1             1.0625        NaN     NaN      NaN\nTem1:Vaz1:Cor1       -0.9125        NaN     NaN      NaN\nTem1:Vaz1:DQO1       -1.1625        NaN     NaN      NaN\nTem1:Cor1:DQO1       -0.3250        NaN     NaN      NaN\nVaz1:Cor1:DQO1        1.6750        NaN     NaN      NaN\nTem1:Vaz1:Cor1:DQO1  -1.6625        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 15 and 0 DF,  p-value: NA\n\n# Modelo de terceira ordem\nlm_eflu3 &lt;- lm(formula = y ~ (Tem + Vaz + Cor + DQO)^3, data = plan_eflu)\nsummary(lm_eflu3)\n\n\nCall:\nlm.default(formula = y ~ (Tem + Vaz + Cor + DQO)^3, data = plan_eflu)\n\nResiduals:\n     1      2      3      4      5      6      7      8      9     10     11 \n-1.663  1.663  1.663 -1.663  1.663 -1.663 -1.663  1.663  1.663 -1.663 -1.663 \n    12     13     14     15     16 \n 1.663 -1.663  1.663  1.663 -1.663 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)     60.4875     1.6625  36.383   0.0175 *\nTem1             8.4750     1.6625   5.098   0.1233  \nVaz1             1.5500     1.6625   0.932   0.5223  \nCor1             5.8375     1.6625   3.511   0.1766  \nDQO1             2.8125     1.6625   1.692   0.3399  \nTem1:Vaz1        1.1375     1.6625   0.684   0.6180  \nTem1:Cor1       -1.7000     1.6625  -1.023   0.4929  \nTem1:DQO1        2.9500     1.6625   1.774   0.3267  \nVaz1:Cor1        0.4250     1.6625   0.256   0.8407  \nVaz1:DQO1       -1.3500     1.6625  -0.812   0.5658  \nCor1:DQO1        1.0625     1.6625   0.639   0.6380  \nTem1:Vaz1:Cor1  -0.9125     1.6625  -0.549   0.6804  \nTem1:Vaz1:DQO1  -1.1625     1.6625  -0.699   0.6115  \nTem1:Cor1:DQO1  -0.3250     1.6625  -0.195   0.8771  \nVaz1:Cor1:DQO1   1.6750     1.6625   1.008   0.4976  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.65 on 1 degrees of freedom\nMultiple R-squared:  0.9803,    Adjusted R-squared:  0.7041 \nF-statistic: 3.549 on 14 and 1 DF,  p-value: 0.3961\n\n# Modelo reduzido via backward\nlm_eflu3_red &lt;- step(lm_eflu3, direction = \"backward\", trace=FALSE)\nsummary(lm_eflu3_red)\n\n\nCall:\nlm.default(formula = y ~ Tem + Vaz + Cor + DQO + Tem:Vaz + Tem:Cor + \n    Tem:DQO + Vaz:Cor + Vaz:DQO + Cor:DQO + Tem:Vaz:Cor + Tem:Vaz:DQO + \n    Vaz:Cor:DQO, data = plan_eflu)\n\nResiduals:\n     1      2      3      4      5      6      7      8      9     10     11 \n-1.338  1.338  1.988 -1.988  1.338 -1.338 -1.988  1.988  1.338 -1.338 -1.988 \n    12     13     14     15     16 \n 1.988 -1.338  1.338  1.988 -1.988 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     60.4875     1.1978  50.498 0.000392 ***\nTem1             8.4750     1.1978   7.075 0.019396 *  \nVaz1             1.5500     1.1978   1.294 0.324939    \nCor1             5.8375     1.1978   4.873 0.039619 *  \nDQO1             2.8125     1.1978   2.348 0.143378    \nTem1:Vaz1        1.1375     1.1978   0.950 0.442525    \nTem1:Cor1       -1.7000     1.1978  -1.419 0.291638    \nTem1:DQO1        2.9500     1.1978   2.463 0.132804    \nVaz1:Cor1        0.4250     1.1978   0.355 0.756652    \nVaz1:DQO1       -1.3500     1.1978  -1.127 0.376763    \nCor1:DQO1        1.0625     1.1978   0.887 0.468646    \nTem1:Vaz1:Cor1  -0.9125     1.1978  -0.762 0.525754    \nTem1:Vaz1:DQO1  -1.1625     1.1978  -0.971 0.434167    \nVaz1:Cor1:DQO1   1.6750     1.1978   1.398 0.296886    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.791 on 2 degrees of freedom\nMultiple R-squared:  0.9795,    Adjusted R-squared:  0.8464 \nF-statistic: 7.357 on 13 and 2 DF,  p-value: 0.1259\n\n\nA análise dos resíduos pode ser realizada conforme código à seguir. Escolhemos o modelo de segunda ordem como modelo final. Pelo p-valor do teste de Shapiro-Wilk, não há indícios para rejeição da hipótese nula de normalidade dos resíduos. A Figura 6.3 apresenta os gráficos de resíduos para o modelo de segunda ordem.\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  resi_eflu\nW = 0.97825, p-value = 0.9482\n\n\n\n\n\n\n\n\n\n\nFigura 6.3: Gráfico de resíduos para experimento do tratamento de efluentes, modelo com termos de até segunda ordem\n\n\n\n\n\nPode-se também plotar os efeitos principais significativos graficamente utilizando, por exemplo, o pacote ggplot2, conforme feito no capítulo anterior. A Figura 6.4 apresenta os efeitos principais dos fatores significativos Tempo e Corrente. Pode-se observar que ambos apresentaram efeito positivo, de forma que o aumento destes garante o aumento da eficiência do tratamento.\n\n\n\n\n\n\n\n\nFigura 6.4: Gráfico de efeitos principais para Tempo e Corrente para o experimento do tratamento de efluentes\n\n\n\n\n\nA Figura 6.5 ilustra o gráfico de contorno para o modelo reduzido. Considerou-se apenas os efeitos mais importantes neste caso. Observa-se maior rendimento com corrente e tempo mais alto.\n\n\n\n\n\n\n\n\nFigura 6.5: Gráfico de contorno do tamanho de grão em função de X2 e X3, com X1 = 1000 e X1 = 1150 ºC",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fatorial de dois níveis não replicado e fracionado</span>"
    ]
  },
  {
    "objectID": "06-fatunrep_frac.html#bloco-e-confundimento-no-fatorial-2k",
    "href": "06-fatunrep_frac.html#bloco-e-confundimento-no-fatorial-2k",
    "title": "6  Fatorial de dois níveis não replicado e fracionado",
    "section": "6.3 Bloco e confundimento no fatorial \\(2^k\\)",
    "text": "6.3 Bloco e confundimento no fatorial \\(2^k\\)\nEm diversas situações não é possível realizar todas os \\(N\\) experimentos em condições homogêneas, mesmo com múltiplos fatores em estudo. Nestes casos deve-se planejar o experimento de forma a evitar que o efeito de fontes de variação adicionais seja confundido com os efeitos dos fatores em avaliação ou inflem o erro experimental. A blocagem pode ser útil também no contexto do fatorial \\(2^k\\).\nA blocagem é um conceito muito útil no fatorial \\(2^k\\) e em outros planejamentos envolvendo multiplos fatores, como alguns de superfície de resposta. Um planejamento pode ser dividido de forma sistemática em dois ou mais blocos, de acordo com o número de níveis da condição heterogênea em avaliação a ser blocada.\n\nExemplo 6.2 Suponha que um fatorial \\(2^2\\) com \\(n=2\\) réplicas será realizado para estudar o efeito do tempo e da temperatura no tratamento térmico de uma liga. Suponha que o experimentador tem quatro corpos de prova de um lote e quatro corpos de prova de outro lote, ambos da mesma liga e fornecidos pelo mesmo fornecedor. Apesar da garantia do fornecedor de homogeneidade entre os lotes, o analista decide blocar os lotes, de forma a evitar que o efeito de uma possível diferença entre estes lotes afete os resultados do experimento. Uma vez que o número de corpos de prova de cada lote corresponde a uma replicação completa, cada bloco, isto é, cada lote da liga pode corresponder a uma replicação. Os dados do exemplo são resumidos na Tabela 6.2.\n\n\n\n\n\nTabela 6.2: Planejamento fatorial 2^2, bloco na replicação\n\n\n\n\n\n\nOrdem\nBlocos\nx1\nx2\nDureza [HRC]\n\n\n\n\n1\n1\n-1\n-1\n48\n\n\n2\n1\n1\n-1\n53\n\n\n3\n1\n-1\n1\n51\n\n\n4\n1\n1\n1\n54\n\n\n5\n2\n-1\n-1\n50\n\n\n6\n2\n1\n-1\n54\n\n\n7\n2\n-1\n1\n53\n\n\n8\n2\n1\n1\n57\n\n\n\n\n\n\n\n\nA blocagem na replicação pode ser considerada na ANOVA com soma dos quadrados definida conforme Equação 6.4, com número de graus de liberdade \\(DF_{blocos} = n_{blocos}-1\\).\n\\[\nSS_{blocos}= \\sum_{i=1}^{n_{blocos}}\\frac{B_i^2}{2^k}-\\frac{y_{...}^2}{n2^k}\n\\tag{6.4}\\]\nPara gerar este planejamento utilizando o pacote FrF2 do R pode-se utilizar o código à seguir.\n\n# Planejamento\nplan_block &lt;- FrF2(nruns = 4,\n                   nfactors = 2,\n                   randomize = F,\n                   replications = 2)\n\n# Resposta\ndureza &lt;- c(48, 53, 51, 54, 50, 54, 53, 57)\nplan_block &lt;- add.response(plan_block,dureza)\n\nplan_block\n\n  run.no run.no.std.rp  A  B Blocks dureza\n1      1           1.1 -1 -1     .1     48\n2      2           2.1  1 -1     .1     53\n3      3           3.1 -1  1     .1     51\n4      4           4.1  1  1     .1     54\n5      5           1.2 -1 -1     .2     50\n6      6           2.2  1 -1     .2     54\n7      7           3.2 -1  1     .2     53\n8      8           4.2  1  1     .2     57\nclass=design, type= full factorial \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\n\nPode-se observar que a coluna blocos já é adicionada no planejamento sem necessidade de algum argumento adicional. A análise deve considerar o termo Blocks no modelo, conforme segue. Observando o resultado do modelo linear, o termo Blocks.2 refere-se ao segundo nível do bloco, sendo adicionado no modelo a diferença entre médias deste nível e do primeiro na previsão, no caso de se prever os resultados dos ensaios no segundo bloco. Logo, o bloco é tratado segundo uma variável categórica na análise. Para o exemplo esta diferença média entre blocos é igual a 2 HRC. Pode-se concluir que neste caso houve significância do fator blocos.\n\n# Análise fatorial 2^k com bloco na replicação\n# Modelo linear\nlm_block &lt;- lm(formula = dureza ~ Blocks + A*B, \n               data = plan_block)\nsummary(lm_block)\n\n\nCall:\nlm.default(formula = dureza ~ Blocks + A * B, data = plan_block)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-1.099e-14  5.000e-01  4.026e-15 -5.000e-01  1.092e-14 -5.000e-01 -3.926e-15 \n         8 \n 5.000e-01 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  51.5000     0.2887 178.401 3.88e-07 ***\nBlocks.2      2.0000     0.4082   4.899  0.01628 *  \nA1            2.0000     0.2041   9.798  0.00226 ** \nB1            1.2500     0.2041   6.124  0.00875 ** \nA1:B1        -0.2500     0.2041  -1.225  0.30807    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5774 on 3 degrees of freedom\nMultiple R-squared:  0.9815,    Adjusted R-squared:  0.9568 \nF-statistic: 39.75 on 4 and 3 DF,  p-value: 0.00623\n\n# ANOVA\nanova_block &lt;- aov(lm_block)\nsummary(anova_block)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nBlocks       1    8.0    8.00    24.0 0.01628 * \nA            1   32.0   32.00    96.0 0.00226 **\nB            1   12.5   12.50    37.5 0.00875 **\nA:B          1    0.5    0.50     1.5 0.30807   \nResiduals    3    1.0    0.33                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA Figura 6.6 apresenta os gráficos de efeitos principais para os fatores A, B e bloco na resposta. O código para obter os gráficos é exposto à seguir. Apesar de não se desejar estudar o efeito do bloco, é importante observar que o bloco 2 apresenta dureza média mais alta em relação ao 1.\n\nplan_block$fit &lt;- lm_block$fitted.values\n\nplan_dec_x1 &lt;- plan_block |&gt;\n  group_by(A, group=1) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nplan_dec_x2 &lt;- plan_block |&gt;\n  group_by(B, group=1) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nplan_dec_bl &lt;- plan_block |&gt;\n  group_by(Blocks, group=1) |&gt;\n  summarise(y = mean(fit)) |&gt;\n  mutate(across(!y, as.factor))\n\nrange_y &lt;- (c(min(plan_dec_x1$y,plan_dec_x2$y, plan_dec_bl$y),\n              max(plan_dec_x1$y,plan_dec_x2$y, plan_dec_bl$y)))\n\npx1 &lt;- ggplot(plan_dec_x1 , \n       aes(x=A, y=y, group=1)) +\n  geom_line(col=\"#00AFBB\",lwd=1) +\n  geom_point(col=\"#00AFBB\",size=2) +\n  ylim(range_y) + \n  ylab(\"y\") +\n  xlab(\"A\")\n\npx2 &lt;- ggplot(plan_dec_x2,\n       aes(x=B, y=y, group=1)) +\n  geom_line(col=\"#E7B800\",lwd=1) +\n  geom_point(col=\"#E7B800\",size=2) +\n  ylim(range_y) + ylab(\"y\") +\n  xlab(\"B\")\n\npbl&lt;- ggplot(plan_dec_bl,\n       aes(x=Blocks, y=y, group=1)) +\n  geom_line(col=\"#FC4E07\",lwd=1) +\n  geom_point(col=\"#FC4E07\",size=2) +\n  ylim(range_y) + ylab(\"y\") +\n  xlab(\"Bloco\")\n\n# Arranjando os gráficos em um único painel\nggarrange(px1,px2,pbl, ncol=3)\n\n\n\n\n\n\n\nFigura 6.6: Efeitos principais para o experimento de tratamento térmico\n\n\n\n\n\nCaso o experimentador deseje constatar a diferença no modelo quando o bloco não é considerado, basta fazer a análise sem o termo Blocks, conforme resultado abaixo. Pode-se observar que a diferença entre os blocos inflará o erro experimental, mesmo o erro sendo estimado com mais graus de liberdade, dada a significância da variável blocada. Neste sentido, ao desconsiderar a variável blocada no modelo, perde-se qualidade do modelo, conforme pode-se constatar pelas medidas de ajuste.\n\n\n\nCall:\nlm.default(formula = dureza ~ A * B, data = plan_block)\n\nResiduals:\n   1    2    3    4    5    6    7    8 \n-1.0 -0.5 -1.0 -1.5  1.0  0.5  1.0  1.5 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     0.5303  98.995 6.24e-08 ***\nA1            2.0000     0.5303   3.771   0.0196 *  \nB1            1.2500     0.5303   2.357   0.0779 .  \nA1:B1        -0.2500     0.5303  -0.471   0.6619    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.5 on 4 degrees of freedom\nMultiple R-squared:  0.8333,    Adjusted R-squared:  0.7083 \nF-statistic: 6.667 on 3 and 4 DF,  p-value: 0.04909\n\n\nNo caso onde deseja-se blocar uma determinada variável em um fatorial com número de níveis da variável a ser blocada maior que o número de réplicas, deve-se utilizar do confundimento. O confundimento é uma técnica para dividir os experimentos do fatorial \\(2^k\\) em blocos de forma menos prejudicial, quando não é possível blocar nas replicações. Neste caso aloca-se uma fração do planejamento em cada bloco. A escolha desta fração acarreta um confundimento com um dos efeitos a ser estimado no fatorial \\(2^k\\). Respeitando a hierarquia dos efeitos, deve-se sempre alocar os níveis da variável blocada na interação de maior ordem.\nA Figura 6.7 ilustra um fatorial \\(2^3\\) com bloco com confundimento em dois níveis. O princípio de hierarquia dos efeitos garante que os efeitos de ordem mais baixa são os mais importantes. Já pelo princípio da esparcidade dos efeitos na maioria dos estudos poucos efeitos explicam a maior proporção da variabilidade dos dados na resposta de interesse. Portanto, espera-se que poucos efeitos e de menor ordem sejam mais importantes. Neste sentido, para o fatorial \\(2^3\\) não replicado com bloco em dois níveis, o confundimento deve ser alocado na interação de maior ordem, \\(x_1x_2x_3\\), conforme a Tabela 6.3. O bloco destacado em azul na Figura 6.7 corresponde a \\(x_1x_2x_3=-1\\), enquanto o amarelo correponde a \\(x_1x_2x_3=+1\\) na Tabela 6.3.\n\n\n\n\n\n\n\n\nFigura 6.7: Fatorial \\(2^3\\) com confundimento em dois níveis\n\n\n\n\n\n\n\n\n\nTabela 6.3: Planejamento fatorial 2^3 com confundimento\n\n\n\n\n\n\nOrdem\nx1\nx2\nx3\nBloco = x1x2x3\n\n\n\n\n1\n-1\n-1\n-1\n-1\n\n\n2\n1\n-1\n-1\n1\n\n\n3\n-1\n1\n-1\n1\n\n\n4\n1\n1\n-1\n-1\n\n\n5\n-1\n-1\n1\n1\n\n\n6\n1\n-1\n1\n-1\n\n\n7\n-1\n1\n1\n-1\n\n\n8\n1\n1\n1\n1\n\n\n\n\n\n\n\n\nÉ importante entender além de como alocar blocos com confundimento, como realizar a análise. Seja o Exemplo 6.3, à seguir.\n\nExemplo 6.3 Um planejamento fatorial \\(2^4\\) foi utilizado no estudo da síntese por deposição química a vapor de acetileno. Foram estudados os efeitos do tempo de crescimento (45, 60 min), da temperatura de crescimento (700, 750 °C), da vazão de acetileno (150, 190 ml/min) e da vazão de argônio (230, 290 ml/min). O catalisador bimetálico FeCo foi utilizado na síntese. Supondo que o experimentador tinha disponível quantidade suficiente de um primeiro lote do catalisador para oito experimentos e quantidade suficientes de um segundo lote para oito experimentos, ele decidiu blocar esta variável. Deve-se definir o confundimento menos prejudicial de forma a alocar os níveis dos blocos.\n\n\n\n\n\nTabela 6.4: Planejamento fatorial 2^4, confundimento\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrdem\nFluxo de Acetileno [ml/min]\nFluxo de Argônio [ml/min]\nTemperatura [ºC]\nTempo [min]\nRendimento [%]\n\n\n\n\n1\n150\n190\n700\n45\n48\n\n\n2\n190\n190\n700\n45\n53\n\n\n3\n150\n230\n700\n45\n51\n\n\n4\n190\n230\n700\n45\n54\n\n\n5\n150\n190\n750\n45\n50\n\n\n6\n190\n190\n750\n45\n54\n\n\n7\n150\n230\n750\n45\n53\n\n\n8\n190\n230\n750\n45\n57\n\n\n9\n150\n190\n700\n60\n48\n\n\n10\n190\n190\n700\n60\n53\n\n\n11\n150\n230\n700\n60\n51\n\n\n12\n190\n230\n700\n60\n54\n\n\n13\n150\n190\n750\n60\n50\n\n\n14\n190\n190\n750\n60\n54\n\n\n15\n150\n230\n750\n60\n53\n\n\n16\n190\n230\n750\n60\n57\n\n\n\n\n\n\n\n\nPara entender a melhor forma de obter o confundimento neste planejamento, é importante considerar a matriz \\(X\\). Para obtê-la no R, pode-se utilizar o comando model.matrix, conforme código à seguir. A forma menos prejudicial neste caso é confundir o bloco com a interação de quarta ordem \\(x_1x_2x_3x_4\\).\n\n# construindo a matrix X\nlevels &lt;- c(-1, +1)\nplan2&lt;- expand.grid(levels,levels,levels,levels)\ncolnames(plan2) &lt;- c(\"x1\",\"x2\",\"x3\",\"x4\")\n\n# matriz do planejamento\nX &lt;- model.matrix(~x1*x2*x3*x4,data=plan2)\nX\n\n   (Intercept) x1 x2 x3 x4 x1:x2 x1:x3 x2:x3 x1:x4 x2:x4 x3:x4 x1:x2:x3\n1            1 -1 -1 -1 -1     1     1     1     1     1     1       -1\n2            1  1 -1 -1 -1    -1    -1     1    -1     1     1        1\n3            1 -1  1 -1 -1    -1     1    -1     1    -1     1        1\n4            1  1  1 -1 -1     1    -1    -1    -1    -1     1       -1\n5            1 -1 -1  1 -1     1    -1    -1     1     1    -1        1\n6            1  1 -1  1 -1    -1     1    -1    -1     1    -1       -1\n7            1 -1  1  1 -1    -1    -1     1     1    -1    -1       -1\n8            1  1  1  1 -1     1     1     1    -1    -1    -1        1\n9            1 -1 -1 -1  1     1     1     1    -1    -1    -1       -1\n10           1  1 -1 -1  1    -1    -1     1     1    -1    -1        1\n11           1 -1  1 -1  1    -1     1    -1    -1     1    -1        1\n12           1  1  1 -1  1     1    -1    -1     1     1    -1       -1\n13           1 -1 -1  1  1     1    -1    -1    -1    -1     1        1\n14           1  1 -1  1  1    -1     1    -1     1    -1     1       -1\n15           1 -1  1  1  1    -1    -1     1    -1     1     1       -1\n16           1  1  1  1  1     1     1     1     1     1     1        1\n   x1:x2:x4 x1:x3:x4 x2:x3:x4 x1:x2:x3:x4\n1        -1       -1       -1           1\n2         1        1       -1          -1\n3         1       -1        1          -1\n4        -1        1        1           1\n5        -1        1        1          -1\n6         1       -1        1           1\n7         1        1       -1           1\n8        -1       -1       -1          -1\n9         1        1        1          -1\n10       -1       -1        1           1\n11       -1        1       -1           1\n12        1       -1       -1          -1\n13        1       -1       -1           1\n14       -1        1       -1          -1\n15       -1       -1        1          -1\n16        1        1        1           1\nattr(,\"assign\")\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n\n\nPara gerar um planejamento fatorial \\(2^k\\) com blocagem e confundimento pode-se utilizar o pacote FrF2. Para o Exemplo 6.3 pode-se utilizar o código à seguir.\n\n# Planejamento 2^4 com confundimento\nplan_conf &lt;- FrF2(nruns = 16,\n                  nfactors = 4,\n                  randomize = F,\n                  blocks = 2)\n\n# Recomenda-se avaliar o planejamento gerado primeiro, \n# pois o pacote ordena por bloco\n# Resposta\nrend &lt;- c(112, 62, 120, 56, 156, 50, 134, 36, # bloco1: x1x2x3x4 = -1\n          102, 42, 126, 24, 170, 72, 142, 38) # bloco2: x1x2x3x4 = +1\nplan_conf &lt;- add.response(plan_conf,rend)\n\nplan_conf\n\n  run.no run.no.std.rp Blocks  A  B  C  D rend\n1      1         2.1.1      1 -1 -1 -1  1  112\n2      2         3.1.2      1 -1 -1  1 -1   62\n3      3         5.1.3      1 -1  1 -1 -1  120\n4      4         8.1.4      1 -1  1  1  1   56\n5      5         9.1.5      1  1 -1 -1 -1  156\n6      6        12.1.6      1  1 -1  1  1   50\n7      7        14.1.7      1  1  1 -1  1  134\n8      8        15.1.8      1  1  1  1 -1   36\n   run.no run.no.std.rp Blocks  A  B  C  D rend\n9       9         1.2.1      2 -1 -1 -1 -1  102\n10     10         4.2.2      2 -1 -1  1  1   42\n11     11         6.2.3      2 -1  1 -1  1  126\n12     12         7.2.4      2 -1  1  1 -1   24\n13     13        10.2.5      2  1 -1 -1  1  170\n14     14        11.2.6      2  1 -1  1 -1   72\n15     15        13.2.7      2  1  1 -1 -1  142\n16     16        16.2.8      2  1  1  1  1   38\nclass=design, type= FrF2.blocked \nNOTE: columns run.no and run.no.std.rp  are annotation, \n not part of the data frame\n\n\nA soma dos quadrados para a blocagem com confundimento em dois níveis pode ser obtida conforme a Equação 6.5.\n\\[\nSS_{blocos}= \\frac{(\\sum_{bloco=+1}y)^2 - (\\sum_{bloco=-1}y)^2}{n2^k/2} - \\frac{y_{...}^2}{n2^k}\n\\tag{6.5}\\]\nA análise no R é feita de forma similar à blocagem na replicação, incluindo o fator Blocks no modelo. Portanto, a diferença é na criação do planejamento. No caso da blocagem na replicação não é necessário modificação alguma no planejamento, já na blocagem com confundimento é necessário colocar o argumento blocks com o número de níveis desejado. Logicamente, o número de ensaios \\(N\\) deve ser múltiplo do número de níveis, de forma que as frações alocadas para cada bloco sejam iguais.\nPara o Exemplo 6.3, a análise é realizada com a sintaxe à seguir. O modelo rend ~ Blocks + (A+B+C+D)^3 não contém o termo de quarta ordem, \\(x_1x_2x_3x_4\\), pois este está confundido com o termo Blocks. De qualquer forma os 16 graus de liberdade foram usados para estimar os efeitos, sem a possibilidade de estimar o erro experimental da forma tradicional.\n\n# Análise fatorial 2^k com blocagem e confundimento\n# Modelo linear\nlm_conf &lt;- lm(formula = rend ~ Blocks + (A+B+C+D)^3, \n               data = plan_conf)\nsummary(lm_conf)\n\n\nCall:\nlm.default(formula = rend ~ Blocks + (A + B + C + D)^3, data = plan_conf)\n\nResiduals:\nALL 16 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   90.125        NaN     NaN      NaN\nBlocks1       -0.625        NaN     NaN      NaN\nA1             9.625        NaN     NaN      NaN\nB1            -5.625        NaN     NaN      NaN\nC1           -42.625        NaN     NaN      NaN\nD1             0.875        NaN     NaN      NaN\nA1:B1         -6.625        NaN     NaN      NaN\nA1:C1         -8.125        NaN     NaN      NaN\nA1:D1         -2.625        NaN     NaN      NaN\nB1:C1         -3.375        NaN     NaN      NaN\nB1:D1          3.125        NaN     NaN      NaN\nC1:D1         -1.875        NaN     NaN      NaN\nA1:B1:C1       3.625        NaN     NaN      NaN\nA1:B1:D1      -2.875        NaN     NaN      NaN\nA1:C1:D1      -1.375        NaN     NaN      NaN\nB1:C1:D1       6.375        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 15 and 0 DF,  p-value: NA\n\n# ANOVA\n# anova_conf &lt;- aov(lm_conf)\n# summary(anova_conf)\n\nApós uma primeira avaliação, pode-se remover alguma interação de ordem maior com efeito menor. Porém, neste estudo, como o bloco não foi significativo, pode-se removê-lo do modelo, conforme segue. Pode-se concluir que os fatores \\(x_1\\) e \\(x_3\\) além da interação entre estes foram significativos. Este modelo também apresentou um excelente ajuste, com \\(R_{aj}^2 = 0,9973\\).\n\n# Análise fatorial 2^k com blocagem e confundimento\n# Modelo linear sem bloco\nlm_conf3 &lt;- lm(formula = rend ~ (A+B+C+D)^3, \n               data = plan_conf)\nsummary(lm_conf3)\n\n\nCall:\nlm.default(formula = rend ~ (A + B + C + D)^3, data = plan_conf)\n\nResiduals:\n     1      2      3      4      5      6      7      8      9     10     11 \n 0.625  0.625  0.625  0.625  0.625  0.625  0.625  0.625 -0.625 -0.625 -0.625 \n    12     13     14     15     16 \n-0.625 -0.625 -0.625 -0.625 -0.625 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   90.125      0.625   144.2  0.00441 **\nA1             9.625      0.625    15.4  0.04128 * \nB1            -5.625      0.625    -9.0  0.07045 . \nC1           -42.625      0.625   -68.2  0.00933 **\nD1             0.875      0.625     1.4  0.39486   \nA1:B1         -6.625      0.625   -10.6  0.05988 . \nA1:C1         -8.125      0.625   -13.0  0.04887 * \nA1:D1         -2.625      0.625    -4.2  0.14881   \nB1:C1         -3.375      0.625    -5.4  0.11657   \nB1:D1          3.125      0.625     5.0  0.12567   \nC1:D1         -1.875      0.625    -3.0  0.20483   \nA1:B1:C1       3.625      0.625     5.8  0.10869   \nA1:B1:D1      -2.875      0.625    -4.6  0.13628   \nA1:C1:D1      -1.375      0.625    -2.2  0.27160   \nB1:C1:D1       6.375      0.625    10.2  0.06221 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.5 on 1 degrees of freedom\nMultiple R-squared:  0.9998,    Adjusted R-squared:  0.9973 \nF-statistic: 392.7 on 14 and 1 DF,  p-value: 0.03954\n\n# ANOVA\n# anova_conf3 &lt;- aov(lm_conf3)\n# summary(anova_conf3)\n\nPode-se também utilizar o pacote unrepx para analisar o planejamento fatorial \\(2^k\\) com blocagem e confundimento. Entretano, o analista deve entender em qual interação está alocado o bloco, visto que os resultados deste pacote não especificam. Para o Exemplo 6.3, a análise pode ser realizada conforme segue.\n\n# Resposta na ordem padrão do fatorial\nrend &lt;- c(102, 156, 120, 142, 62, 72, 24, 36, 112, 170, 126, 134, 42, 50, 56, 38)\n\n# Efeitos\nefeitos &lt;- yates(rend)\nefeitos\n\n     A      B     AB      C     AC     BC    ABC      D     AD     BD    ABD \n 19.25 -11.25 -13.25 -85.25 -16.25  -6.75   7.25   1.75  -5.25   6.25  -5.75 \n    CD    ACD    BCD   ABCD \n -3.75  -2.75  12.75  -1.25 \nattr(,\"mean\")\n       \n90.125 \n\n# Análise da significância dos efeitos\neff.test(efeitos, method = \"Lenth\")\n\n     effect Lenth_PSE t.ratio p.value simult.pval\nC    -85.25      9.75  -8.744  0.0004      0.0034\nA     19.25      9.75   1.974  0.0654      0.4934\nAC   -16.25      9.75  -1.667  0.1048      0.7008\nAB   -13.25      9.75  -1.359  0.1711      0.8890\nBCD   12.75      9.75   1.308  0.1845      0.9149\nB    -11.25      9.75  -1.154  0.2341      0.9723\nABC    7.25      9.75   0.744  0.4305      1.0000\nBC    -6.75      9.75  -0.692  0.4650      1.0000\nBD     6.25      9.75   0.641  0.5569      1.0000\nABD   -5.75      9.75  -0.590  0.5908      1.0000\nAD    -5.25      9.75  -0.538  0.6235      1.0000\nCD    -3.75      9.75  -0.385  0.7257      1.0000\nACD   -2.75      9.75  -0.282  0.7978      1.0000\nD      1.75      9.75   0.179  0.8695      1.0000\nABCD  -1.25      9.75  -0.128  0.9066      1.0000\n\n\n\n\n\n\n\n\n\n\nFigura 6.8: Gráfico de Pareto para os efeitos no fatorial \\(2^4\\) com confundimento",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fatorial de dois níveis não replicado e fracionado</span>"
    ]
  },
  {
    "objectID": "06-fatunrep_frac.html#fatorial-fracionado-2k-p",
    "href": "06-fatunrep_frac.html#fatorial-fracionado-2k-p",
    "title": "6  Fatorial de dois níveis não replicado e fracionado",
    "section": "6.4 Fatorial fracionado \\(2^{k-p}\\)",
    "text": "6.4 Fatorial fracionado \\(2^{k-p}\\)\nEm diversas situações onde o número de fatores de controle é elevado, o custo experimental para executar um planejamento fatorial \\(2^k\\) completo fica elevado, visto que o número de experimentos cresce exponencialmente com o aumento do número de fatores de interesse, \\(N=2^k\\). Nestes casos pode-se utilizar o planejamento fatorial fracionado \\(2^{k-p}\\) para estudar o processo de interesse. No planejamento fatorial fracionado \\(2^{k-p}\\) apenas uma fração do fatorial \\(2^k\\) é realizada, viabilizando economia na experimentação. Para \\(p=1\\), tem-se um planejamento com meia fração, já para \\(p=2\\), tem-se uma fração de um quarto. Apesar da perda de informação decorrente na redução do número de ensaios, há alguns princípios que sustentam o uso do fatorial fracionado \\(2^{k-p}\\).\nAo realizar apenas uma fração do planejamento, não é possível estimar todos os efeitos do processo em estudo. Entretanto, pelo princípio da hierarquia dos efeitos, os efeitos de menor ordem são mais importantes e devem ser priorizados. Já pelo princípio da esparcidade dos efeitos, geralmente poucos efeitos serão significativos em uma resposta de interesse, enquanto a maior parte dos efeitos será esparça. Logo, considerando estes dois princípios, na maioria dos estudos poucos efeitos e de menor ordem serão significativos na resposta de interesse. A Figura 6.9 ilustra estes princípios.\n\n\n\n\n\n\n\n\nFigura 6.9: Princípios da esparcidade e hierarquia dos efeitos\n\n\n\n\n\nUm conceito fundamental na experimentação que sustenta o uso do planejamento fatorial fracionado é a experimentação sequencial. Geralmente em estudos com muitas variáveis de interesse, torna-se necessário a realização de experimentos inciciais, ditos de varredura (screening experiments). Nestes experimentos deseja-se conhecer os fatores influentes entre muitos existentes. Deste modo, ao realizar o fatorial fracionado \\(2^{k-p}\\) não deseja-se obter resultados conclusivos, mas indícios que demonstrem o caminho a ser seguido nas etapas subsequentes da experimentação. O analista busca com este planejamento reduzir o número de fatores em investigação para depois aplicar outros métodos conclusivos.\nRelacionado à questão da experimentação sequencial está a propriedade de projeção. Esta propriedade implica na remoção dos efeitos com menor magnitude do fatorial fracionado \\(2^{k-p}\\), projetando-o em um fatorial completo \\(2^k\\). Seja um fatorial fracionado \\(2^{3-1}\\). Este planejamento contém \\(k = 3\\) fatores, \\(x_1\\), \\(x_2\\) e \\(x_3\\) e consiste em meia fração do fatorial \\(2^k\\) completo, \\(p = 1\\). Logo, o número de experimentos realizado é \\(N=2^{3-1}=4\\). Supondo que após uma primeira análise dos efeitos principais dos três fatores, observa-se que o efeito de um deles, por exemplo de \\(x_3\\), não é significativo. Sugere-se remover este fator do estudo, projetando o planejamento em um fatorial completo \\(2^2\\). A Figura 6.10 ilustra a propriedade de projeção.\n\n\n\n\n\n\n\n\nFigura 6.10: Projeção no fatorial fracionado \\(2^{k-p}\\)\n\n\n\n\n\nAinda considerando o caso do fatorial fracionado \\(2^{3-1}\\), com \\(N = 4\\) experimentos, deve-se escolher qual \\(1/2\\) fração menos prejudicial deve ser realizada. Neste caso os níveis do fator \\(x_3\\) devem ser definidos considerando o produto \\(x_1x_2\\). Isto, logicamente implicará em um confundimento desta interação com o efeito de \\(x_3\\). A Tabela 6.5 apresenta este planejamento. Entretanto, há outra possibilidade para o mesmo planejamento fatorial fracionado \\(2^{3-1}\\), a fração alternativa, definindo o terceiro fator como \\(x_3=-x_1x_2\\).\n\n\n\n\nTabela 6.5: Planejamento fatorial fracionado 2^3-1\n\n\n\n\n\n\nordem\nx1\nx2\nx3=x1x2\n\n\n\n\n1\n-1\n-1\n1\n\n\n2\n1\n-1\n-1\n\n\n3\n-1\n1\n-1\n\n\n4\n1\n1\n1\n\n\n\n\n\n\n\n\nA Figura 6.11 ilustra a fração principal, Figura 6.11(a) do planejamento fatorial \\(2^{3-1}\\), com os experimentos enumerados 5, 2, 3 e 8 correspondentes, respectivamente, aos experimentos 1, 2, 3 e 4 da Tabela Tabela 6.5. A Figura 6.11(b) apresenta a fração alternativa deste planejamento, enquanto a Figura 6.11(c) apresenta o fatorial completo resultante da composição das duas frações.\n\n\n\n\n\n\n\n\nFigura 6.11: Fatorial fracionado \\(2^{3-1}\\) (a) fração principal; (b) fração alternativa; (fatorial completo \\(2^3\\))\n\n\n\n\n\nConsiderando ainda o princípio da experimentação sequencial, após realizar \\(1/2\\) fração de um fatorial completo, caso o experimentador constate que todos os efeitos são importantes em magnitude, ele pode completar o planejamento com a outra fração, de forma a obter mais informação acerca dos efeitos em estudo. O experimentador pode neste caso blocar as frações testadas em momentos distintos, para avaliar a significância de uma possível variabilidade entre as estas etapas.\nAo realizar um fatorial fracionado, o analista deve ter em mente que perderá informação em relação aos efeitos possíveis de serem estimados considerando os fatores em análise e suas interações. Tomando o exemplo dos três fatores, no fatorial completo \\(2^3\\) há possibilidade de estimar uma constante, 3 efeitos principais, 3 interações de segunda ordem e uma interação de terceira ordem. Ao realizar um fatorial fracionado \\(2^{3-1}\\), o analista só poderá estimar \\(r = 4\\) efeitos, uma vez que tem apenas \\(N=4\\) experimentos. Deste modo, o conceito de confundimento está implícito nos fatoriais fracionados, de forma que não é possível estimar um efeito sem este estar confundido com outro de interesse. Deve-se, portanto, avaliar a estrutura de confundimento do planejamento e entender quais as implicações desta estrutura na estimativa dos efeitos.\nSeja a estrutura de confundimento do fatorial fracionado \\(2^{3-1}\\). Sejam os efeitos de \\(x_1\\), \\(x_2\\) e \\(x_3\\), A, B e C, respectivamente. Para definir esta estrutura, deve-se considerar a seguinte regra AA = BB = CC = I, onde I é uma constante (não confundir com álgebra matricial). Tomando o gerador C = AB, visto que os níveis de \\(x_3\\) foram gerados considerando a interação \\(x_1x_2\\), multiplicando ambos os lados por C, tem-se, CC = ABC, resultando em I = ABC. Portanto, I = ABC consiste na relação de definição. A partir desta relação sabe-se que o efeito da constante está confundido com a interação de terceira ordem. Ao multiplicar cada efeito em ambos os lados nesta relação, obtém-se a estrutura de confundimento completa do planejamento fatorial fracionado \\(2^{3-1}\\), conforme ilustrado na Figura 6.12. Pode-se constatar que neste planejamento os efeitos principais estão confundidos com as interações de segunda ordem e a constante confundida com a interação de terceira ordem.\n\n\n\n\n\n\n\n\nFigura 6.12: Estrutura de confundimento do fatorial fracionado \\(2^{3-1}\\)\n\n\n\n\n\nOutro conceito importante para avaliar o fatorial fracionado \\(2^{k-p}\\) é a resolução. Considerando a estrutura de confundimento do fatorial fracionado \\(2^{3-1}\\) este planejamento é dito de resolução III. Um fatorial fracionado de resolução III não é considerado de boa resolução, uma vez que os efeitos principais estão confundidos com as interações de segunda ordem, sendo a interpretação dos efeitos de baixa ordem imprecindível considerando os objetivos do planejamento fatorial.\nUm modelo de regressão do fatorial fracionado \\(2^{3-1}\\) pode ser escrito conforme Equação 7.3. Pode-se observar que não há certeza em relação aos coeficientes, dado o confundimento na estimativa destes. Entretanto, deve-se priorizar os efeitos de menor ordem na interpretação, dado o princípio da hierarquia dos efeitos.\n\\[\n\\hat{y}=(\\beta_0+\\beta_{123}) + (\\beta_1+\\beta_{23})x_1 + (\\beta_2+\\beta_{13})x_2 + (\\beta_3+\\beta_{12})x_3\n\\tag{6.6}\\]\n\nExemplo 6.4 Um planejamento fatorial fracionado \\(2^{4-1}\\) foi utilizado para estudar o processo de metalurgia do pó para fabricação de uma liga biodegradável de Mg−Zn. Foram estudados os efeitos de quatro fatores: o tempo de moagem (2 - 10h), a velocidade de moagem (100 - 300rev/min), a razão mássica bola/pó (5:1 - 15:1) e o teor de Zn (3 - 10%). A resposta estudada foi o módulo de elasticidade em GPa. A Tabela 6.6 apresenta o planejamento com a resposta.\n\n\n\n\n\nTabela 6.6: Planejamento fatorial fracionado 24-1, metalurgia do pó da liga de Mg-Zn\n\n\n\n\n\n\nordem\nx1\nx2\nx3\nx4=x1x2x3\ny\n\n\n\n\n1\n-1\n-1\n-1\n-1\n41.83\n\n\n2\n1\n-1\n-1\n1\n45.24\n\n\n3\n-1\n1\n-1\n-1\n47.88\n\n\n4\n1\n1\n-1\n1\n44.16\n\n\n5\n-1\n-1\n1\n-1\n46.47\n\n\n6\n1\n-1\n1\n1\n40.18\n\n\n7\n-1\n1\n1\n-1\n43.79\n\n\n8\n1\n1\n1\n1\n45.38\n\n\n\n\n\n\n\n\nPara gerar este planejamento no R, pode-se utilizar o pacote FrF2 com o código à seguir. Ao exibir o planejamento com o comando summary(plan_mgzn), o analista obtém o planejamento, suas características e a estrutura de confundimento (alias structure). Entretanto, como o padrão deste pacote é a análise do modelo linear com interações de até segunda ordem, a estrutura de confundimento exibida só apresenta os confundimentos dos termos de até segunda ordem.\n\n# Planejamento\nplan_mgzn &lt;- FrF2(nruns = 8,\n                  nfactors = 4,\n                  factor.names = list(x1=c(2,10),\n                                      x2=c(100,300),\n                                      x3=c(5,15),\n                                      x4=c(3,10)),\n                  randomize = F)\n    \n\n# Módulo de elasticidade\ny &lt;- c(41.83, 45.24, 47.88, 44.16, 46.47, 40.18, 43.79, 45.38)\n\n# Adicionando resposta ao planejamento\nplan_mgzn &lt;- add.response(plan_mgzn,y)\n\n# Exibindo o planejamento\nsummary(plan_mgzn)\n\nCall:\nFrF2(nruns = 8, nfactors = 4, factor.names = list(x1 = c(2, 10), \n    x2 = c(100, 300), x3 = c(5, 15), x4 = c(3, 10)), randomize = F)\n\nExperimental design of type  FrF2 \n8  runs\n\nFactor settings (scale ends):\n  x1  x2 x3 x4\n1  2 100  5  3\n2 10 300 15 10\n\nResponses:\n[1] y\n\nDesign generating information:\n$legend\n[1] A=x1 B=x2 C=x3 D=x4\n\n$generators\n[1] D=ABC\n\n\nAlias structure:\n$fi2\n[1] AB=CD AC=BD AD=BC\n\n\nThe design itself:\n  x1  x2 x3 x4     y\n1  2 100  5  3 41.83\n2 10 100  5 10 45.24\n3  2 300  5 10 47.88\n4 10 300  5  3 44.16\n5  2 100 15 10 46.47\n6 10 100 15  3 40.18\n7  2 300 15  3 43.79\n8 10 300 15 10 45.38\nclass=design, type= FrF2 \n\n\nPara obter a estrutura de confundimento completa utilizando o pacote FrF2 deve-se utilizar o comando aliases, com o modelo de interesse, conforme segue. Pelos resultados, pode-se constatar que os termos principais estão confundidos com as interações de terceira ordem, enquanto as interações de segunda ordem estão confundidas entre si. Este planejamento tem resolução IV. O maior problema neste planejamento reside na dificuldade de interpretar as interações de segunda ordem.\n\n# Estrutura de confundimento com termos de até quarta ordem\naliases(lm(y ~ (.)^4, data = plan_mgzn))\n\n              \n x1 = x2:x3:x4\n x2 = x1:x3:x4\n x3 = x1:x2:x4\n x4 = x1:x2:x3\n x1:x2 = x3:x4\n x1:x3 = x2:x4\n x1:x4 = x2:x3\n\n\nApós criar o planejamento pode-se proceder com a análise. Pode-se observar que, ao se obter o modelo de segunda ordem, algumas das interações não são exibidas. Isto ocorre pois, além de não haver graus de liberdade suficiente para estimá-las, deve-se lembrar que estas interações estão confundidas. Deste modo, quando o analista interpreta o efeito da interação \\(x_1x_2\\), ele deve ter em mente que neste efeito consta também a interação \\(x_3x_4\\), ou seja, a magnitude do efeito é na verdade o confundimento destes dois efeitos \\(x_1x_2+x_3x_4\\). O mesmo ocorre para as demais interações de segunda ordem. As interações de terceira ordem, apesar de serem menos importantes estão confundidas com os efeitos de primeira ordem. Entretanto, neste caso, a interpretação deve priorizar os efeitos principais, dado o princípio da hierarquia dos efeitos.\n\n# Modelo \"completo\"\nlm1 &lt;- lm(plan_mgzn)\nsummary(lm1)\n\nNumber of observations used: 8 \nFormula:\ny ~ (x1 + x2 + x3 + x4)^2\n\nCall:\nlm.default(formula = fo, data = model.frame(fo, data = formula))\n\nResiduals:\nALL 8 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (3 not defined because of singularities)\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 44.36625        NaN     NaN      NaN\nx11         -0.62625        NaN     NaN      NaN\nx21          0.93625        NaN     NaN      NaN\nx31         -0.41125        NaN     NaN      NaN\nx41          1.87625        NaN     NaN      NaN\nx11:x21      0.09375        NaN     NaN      NaN\nx11:x31     -0.54875        NaN     NaN      NaN\nx11:x41     -0.30625        NaN     NaN      NaN\nx21:x31           NA         NA      NA       NA\nx21:x41           NA         NA      NA       NA\nx31:x41           NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 7 and 0 DF,  p-value: NA\n\n\nAo observar os efeitos, pode-se optar por reduzir o modelo, retirando uma interação com menor magnitude para estimar o erro experimental. Isto pode ser feito utilizando o comando lm base do R, conforme segue. Procedendo desta forma é possível estimar o erro experimental e testar a significância dos efeitos. Neste caso apenas o efeito de \\(x_4\\) foi estatísticamente significativo com \\(\\alpha = 0,05\\) de significância. O modelo explica uma proporção de 0,9895 da variabilidade dos dados.\n\n# Modelo com apenas duas interações\nlm2 &lt;- lm(formula = y ~x1 +x2 + x3 + x4 + x1:x3 + x2:x3,\n            plan_mgzn)\nsummary(lm2)\n\n\nCall:\nlm.default(formula = y ~ x1 + x2 + x3 + x4 + x1:x3 + x2:x3, data = plan_mgzn)\n\nResiduals:\n       1        2        3        4        5        6        7        8 \n 0.09375 -0.09375 -0.09375  0.09375  0.09375 -0.09375 -0.09375  0.09375 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 44.36625    0.09375 473.240  0.00135 **\nx11         -0.62625    0.09375  -6.680  0.09460 . \nx21          0.93625    0.09375   9.987  0.06354 . \nx31         -0.41125    0.09375  -4.387  0.14269   \nx41          1.87625    0.09375  20.013  0.03178 * \nx11:x31     -0.54875    0.09375  -5.853  0.10772   \nx21:x31     -0.30625    0.09375  -3.267  0.18912   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2652 on 1 degrees of freedom\nMultiple R-squared:  0.9984,    Adjusted R-squared:  0.9885 \nF-statistic: 101.5 on 6 and 1 DF,  p-value: 0.07583\n\n\nA Figura 6.13 resume algumas possibilidades para o planejamento fatorial fracionado \\(2^{k-p}\\). Pode-se observar a resolução do planejamento e os geradores para cada caso. Recomenda-se sempre que possível utilizar planejamentos de resolução V ou superior. Um planejamento de resolução V tem os efeitos principais confundidos com as interações de quarta ordem e as interações de segunda ordem confundidas com as interações de terceira ordem, sendo este tipo de confundimento menos prejudicial.\n\n\n\n\n\n\n\n\nFigura 6.13\n\n\n\n\n\nUtilizando o pacote FrF2 é possível gerar um planejamento fatorial fracionado \\(2^{k-p}\\), definindo o gerador do planejamento. Observando a Figura 6.13 seja o planejamento \\(2^{5-1}\\) considerando que o analista deseja analisar 5 fatores, mas só tem recursos para 16 ensaios. Este planejamento tem resolução V. Caso o analista queira utilizar a fração alternativa, ele deve considerar o gerador E = -ABCD, colocando o argumento gen = \"-ABCD\", conforme segue.\n\n# Planejamento 2^(5-1) com fração alternativa\nplanv &lt;- FrF2(nruns = 16,\n              nfactors = 5, \n              gen = \"-ABCD\")\nsummary(planv)\n\nCall:\nFrF2(nruns = 16, nfactors = 5, gen = \"-ABCD\")\n\nExperimental design of type  FrF2.generators \n16  runs\n\nFactor settings (scale ends):\n   A  B  C  D  E\n1 -1 -1 -1 -1 -1\n2  1  1  1  1  1\n\nDesign generating information:\n$legend\n[1] A=A B=B C=C D=D E=E\n\n$generators\n[1] E=-ABCD\n\n\nAlias structure:\n[[1]]\n[1] no aliasing among main effects and 2fis\n\n\nThe design itself:\n    A  B  C  D  E\n1  -1 -1 -1  1  1\n2  -1  1  1 -1 -1\n3  -1 -1  1 -1  1\n4   1  1  1  1 -1\n5   1 -1  1 -1 -1\n6   1  1  1 -1  1\n7   1  1 -1 -1 -1\n8  -1  1  1  1  1\n9  -1  1 -1 -1  1\n10  1 -1 -1  1 -1\n11  1 -1 -1 -1  1\n12 -1  1 -1  1 -1\n13  1  1 -1  1  1\n14  1 -1  1  1  1\n15 -1 -1 -1 -1 -1\n16 -1 -1  1  1 -1\nclass=design, type= FrF2.generators \n\n\nPelos resultados pode-se observar que não há confundimento entre os efeitos principais e as interações de segunda ordem. Caso o analista deseje entender toda a estrutura de confundimento, deve-se utilizar o comando aliases conforme sintaxe abaixo.\n\n# gerando coluna resposta aleatória \n# apenas para ver confundimento\nset.seed(7)\ny &lt;- rnorm(16)\nplanv$y &lt;- y\n\n# Estrutura de confundimento completa\naliases(lm(y ~ (.)^5, data = planv))\n\n             \n A = -B:C:D:E\n B = -A:C:D:E\n C = -A:B:D:E\n D = -A:B:C:E\n E = -A:B:C:D\n A:B = -C:D:E\n A:C = -B:D:E\n A:D = -B:C:E\n A:E = -B:C:D\n B:C = -A:D:E\n B:D = -A:C:E\n B:E = -A:C:D\n C:D = -A:B:E\n C:E = -A:B:D\n D:E = -A:B:C",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fatorial de dois níveis não replicado e fracionado</span>"
    ]
  },
  {
    "objectID": "06-fatunrep_frac.html#planejamento-fatorial-2k-com-pontos-centrais",
    "href": "06-fatunrep_frac.html#planejamento-fatorial-2k-com-pontos-centrais",
    "title": "6  Economia na experimentação e busca de região de curvatura via Fatorial 2^k",
    "section": "6.5 Planejamento fatorial \\(2^k\\) com pontos centrais",
    "text": "6.5 Planejamento fatorial \\(2^k\\) com pontos centrais\nEm diversas situações um modelo linear pode não se ajustar bem à região experimental. Nestes casos o fatorial \\(2^k\\) não oferecerá um modelo de regressão útil em toda região experimental, especialmente para a região central do planejamento. Há casos também que o experimentador deseja testar a presença de curvatura, isto é, testar se um modelo quadrático se ajustaria melhor aos dados, para propósito de experimentação sequencial e busca dos níveis ótimos operacionais dos fatores de controle avaliados.\nA adição de pontos centrais no fatorial \\(2^k\\) permite testar a presença de curvatura na região experimental. Os pontos centrais são condições intermediárias entre os dois níveis fatoriais, sendo codificados em \\(x_{j(0)}=0\\). O planejamento fatorial com pontos centrais permite testar a hipótese \\(H_0: \\sum\\beta_{jj}=0\\), onde \\(\\beta_{jj}\\), \\(j = 1, ..., k\\) são os coeficientes quadráticos, sendo portanto multiplicados por \\(x_j^2\\), \\(j = 1, ..., k\\), em um modelo de regressão de segunda ordem completo almejado. O fatorial \\(2^k\\) com pontos centrais não permite, entretanto, estimar um modelo quadrático, visto que não tem níveis suficientes para tal finalidade. Entretanto, ele é um passo preliminar para a obtenção de um modelo com termos de segunda ordem puros (quadráticos), possibilitando a posterior realização de experimentos em níveis adicionais para viabilizar a obtenção de um modelo quadrático. Tal estratégia sequencial para metodologia de superfície de resposta pode ser efetivada via planejamento composto central.\nO fatorial \\(2^k\\) com pontos centrais também permite a economia experimental pela replicação apenas na condição intermediária, especialmente nos casos com elevado número de fatores \\(k\\). Deste modo, ao se obter um modelo completo via fatorial \\(2^k\\) com pontos centrais, os graus de liberdade para o erro são calculados com base nos pontos centrais, sendo o erro experimental estimado tomando a variância dos pontos centrais, conforme Equação 5.8, onde \\(y_{c(i)}\\) é o i-ésimo ponto central e \\(n_c\\) é o número de pontos centrais.\n\\[\n\\hat{\\sigma}^2 = MS_E = \\frac{\\displaystyle \\sum_{i=1}^{n_c}(y_{c(i)}-\\bar{y}_c)^2}{n_c-1}\n\\tag{6.7}\\]\n\nExemplo 6.5 A influência da temperatura, da concentração de catalisador e da razão molar álcool/óleo no rendimento da produção de uma fração de baixo peso molecular foi estudada e otimizada por meio de um planejamento fatorial. A fração é composta de ésteres de caprilato, caprato, laurato e miristato butílico, os quais podem ser usados como valorosos produtos químicos (devido a suas inúmeras aplicações nas indústrias cosmética, farmacêutica e de alimentos). O planejamento fatorial \\(2^3\\) com adição de pontos centrais foi inicialmente utilizado para testar curvatura e avaliar a possibilidade futura de obtenção de um modelo quadrático. O planejamento é exposto na Tabela 6.7.\n\n\n\n\n\nTabela 6.7: Planejamento fatorial 23 com pontos centrais\n\n\n\n\n\n\nordem\nT [ºC]\nC [%]\nMR\ny [%]\n\n\n\n\n1\n55\n3\n3\n38\n\n\n2\n75\n3\n3\n49\n\n\n3\n55\n7\n3\n59\n\n\n4\n75\n7\n3\n49\n\n\n5\n55\n3\n7\n39\n\n\n6\n75\n3\n7\n59\n\n\n7\n55\n7\n7\n65\n\n\n8\n75\n7\n7\n75\n\n\n9\n65\n5\n5\n63\n\n\n10\n65\n5\n5\n62\n\n\n11\n65\n5\n5\n58\n\n\n12\n65\n5\n5\n60\n\n\n\n\n\n\n\n\nO efeito dos pontos centrais \\(E_{0}\\) é calculado como a diferença entre médias entre os pontos centrais e os pontos axiais, conforme Equação 6.8, onde \\(\\bar{y}_{fat}\\) é a média dos pontos fatoriais, enquanto \\(\\bar{y}_{ctpt}\\) é a média dos pontos centrais.\n\\[\nE_{0} = \\bar{y}_{fat}-\\bar{y}_{ctpt}\n\\tag{6.8}\\]\nPara gerar o planejamento do Exemplo 6.5 pode-se utilizar o código à seguir.\n\n# Planejamento\nplanctpt &lt;- FrF2(nruns = 8,\n                 nfactors = 3, \n                 factor.names = c(\"T\", \"C\", \"MR\"),\n                 ncenter = 4,\n                 randomize = F)\n\n# Adicionando a coluna com a resposta\nplanctpt$y &lt;- c(38, 49, 59, 49, 39, 59, 65, 75, 63, 62, 58, 60)\n\nsummary(planctpt)\n\nCall:\nFrF2(nruns = 8, nfactors = 3, factor.names = c(\"T\", \"C\", \"MR\"), \n    ncenter = 4, randomize = F)\n\nExperimental design of type  full factorial.center \n12  runs\n\nFactor settings (scale ends):\n   T  C MR\n1 -1 -1 -1\n2  1  1  1\n\nThe design itself:\n    T  C MR  y\n1  -1 -1 -1 38\n2   1 -1 -1 49\n3  -1  1 -1 59\n4   1  1 -1 49\n5  -1 -1  1 39\n6   1 -1  1 59\n7  -1  1  1 65\n8   1  1  1 75\n9   0  0  0 63\n10  0  0  0 62\n11  0  0  0 58\n12  0  0  0 60\nclass=design, type= full factorial.center \n\n\nPara testar a curvatura, deve-se considerar a soma dos quadrados para curvatura, conforme Equação 6.9.\n\\[\nSS_0 = \\frac{n_{fat}n_{ctpt}(\\bar{y}_{fat}-\\bar{y}_{center})^2}{n_{fat}+n_{ctpt}}\n\\tag{6.9}\\]\nPara obter a ANOVA com teste de curvatura, deve-se proceder conforme segue. Optou-se por adicionar uma coluna center no planejamento para testar curvatura. Posteriormente, adicionou-se o termo center no modelo. Outra opção, caso o analista não queira criar esta coluna seria adicionando o termo !iscube(planctpt) no modelo. Em caso de significância na curvatura, o modelo de regressão é útil desde que ao realizar previsão nos pontos centrais, seja somado o efeito dos pontos centrais. Já ao realizar previsão nos pontos fatoriais o efeito da curvatura deve ser desconsiderado.\nPara o Exemplo 6.5 o teste de curvatura apresentou significância estatística, \\(p-valor = 0,01646 &lt; 0,05 = \\alpha\\). Consequentemente, é viável a realização de experimentos adicionais para estimar um modelo quadrático completo. Entretanto, este exemplo será retomado posteriormente para entendimento da estratégia sequencial para metodologia de superfície de resposta.\n\n# Adicionando coluna para teste de curvatura\nplanctpt$center &lt;- c(rep(0, times =8), rep(1, times = 4))\n\n# Regressão teste de curvatura\nlm1 &lt;- lm(formula = y ~ T*C*MR + center, data = planctpt)\nsummary(lm1)\n\n\nCall:\nlm.default(formula = y ~ T * C * MR + center, data = planctpt)\n\nResiduals:\n         1          2          3          4          5          6          7 \n 3.053e-16  1.031e-16 -1.048e-16 -8.049e-17 -1.489e-16 -1.462e-17  2.309e-16 \n         8          9         10         11         12 \n 1.087e-16  2.250e+00  1.250e+00 -2.750e+00 -7.500e-01 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   54.125      0.784  69.041  6.7e-06 ***\nT              3.875      0.784   4.943  0.01588 *  \nC              7.875      0.784  10.045  0.00210 ** \nMR             5.375      0.784   6.856  0.00635 ** \ncenter         6.625      1.358   4.879  0.01646 *  \nT:C           -3.875      0.784  -4.943  0.01588 *  \nT:MR           3.625      0.784   4.624  0.01904 *  \nC:MR           2.625      0.784   3.348  0.04411 *  \nT:C:MR         1.375      0.784   1.754  0.17772    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.217 on 3 degrees of freedom\nMultiple R-squared:  0.9884,    Adjusted R-squared:  0.9576 \nF-statistic: 32.03 on 8 and 3 DF,  p-value: 0.008\n\n# ANOVA\n# anova1 &lt;- aov(lm1)\n# summary(anova1)\n\nA Figura 6.14 ilustra os gráficos de efeitos principais. Pode-se observar que a média da resposta nos pontos centrais confirma o indício de presença de curvatura na região experimental.\n\nplanctpt$fit &lt;- lm1$fitted.values \n\nmeanc1 &lt;- planctpt |&gt;\n  group_by(T) |&gt;\n  summarise(y=mean(fit))\n\nmeanc2 &lt;- planctpt |&gt;\n  group_by(C) |&gt;\n  summarise(y=mean(fit))\n\nmeanc3 &lt;- planctpt |&gt;\n  group_by(MR) |&gt;\n  summarise(y=mean(fit))\n\nmeanc1$ct &lt;- ifelse(meanc1$T == 0, \"0\", \"1\")\nmeanc2$ct &lt;- ifelse(meanc2$C == 0, \"0\", \"1\")\nmeanc3$ct &lt;- ifelse(meanc3$MR == 0, \"0\", \"1\")\n\nrangec &lt;- c(min(meanc1$y,meanc2$y,meanc3$y),\n            max(meanc1$y,meanc2$y,meanc3$y))\n\npc1 &lt;- ggplot(meanc1, aes(T,y,col = ct)) + \n  geom_line(lwd=1) +\n  geom_point(size=2) +\n  ylim(rangec) + theme(legend.position=\"none\")\n\npc2 &lt;- ggplot(meanc2, aes(C,y,col = ct)) + \n  geom_line(lwd=1) +\n  geom_point(size=2) +\n  ylim(rangec) + theme(legend.position=\"none\")\n\npc3 &lt;- ggplot(meanc3, aes(MR,y,col = ct)) + \n  geom_line(lwd=1) +\n  geom_point(size=2) +\n  ylim(rangec) + theme(legend.position=\"none\")\n\nggarrange(pc1,pc2,pc3, nrow=1)\n\n\n\n\n\n\n\nFigura 6.14: Efeitos principais, fatorial \\(2^k\\) com pontos centrais\n\n\n\n\n\nA Figura 6.15 ilustra os gráficos de interação de segunda ordem. Os pontos centrais são plotados à parte.\n\nmeanc12 &lt;- planctpt |&gt;\n  group_by(T,C) |&gt;\n  summarise(y=mean(fit))\n\nmeanc13 &lt;- planctpt |&gt;\n  group_by(T,MR) |&gt;\n  summarise(y=mean(fit))\n\nmeanc23 &lt;- planctpt |&gt;\n  group_by(C,MR) |&gt;\n  summarise(y=mean(fit))\n\nrangecc &lt;- c(min(meanc12$y,meanc13$y,meanc23$y),\n             max(meanc12$y,meanc13$y,meanc23$y))\n\npc12 &lt;- ggplot() + \n  geom_line(data = meanc12 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(C),\n                   shape = as.factor(C)), lwd=1) +\n  geom_point(data = meanc12 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(C),\n                   shape = as.factor(C)), size=2) +\n  geom_point(data = meanc12 |&gt; filter(T == 0),\n             mapping = aes(x=T, y), shape=8, size=2) +\n  ylim(rangecc) + \n  labs(col = \"C\", shape = \"C\") + \n  theme(legend.position = \"bottom\")\n\npc13 &lt;- ggplot() + \n  geom_line(data = meanc13 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(MR),\n                   shape = as.factor(MR)), lwd=1) +\n  geom_point(data = meanc13 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(MR),\n                   shape = as.factor(MR)), size=2) +\n  geom_point(data = meanc13 |&gt; filter(T == 0),\n             mapping = aes(x=T, y), shape=8, size=2) +\n  ylim(rangecc) + \n  labs(col = \"MR\", shape = \"MR\") + \n  theme(legend.position = \"bottom\")\n\npc23 &lt;- ggplot() + \n  geom_line(data = meanc23 |&gt; filter(C != 0),\n               mapping = aes(x=C, y, col = as.factor(MR),\n                   shape = as.factor(MR)), lwd=1) +\n  geom_point(data = meanc23 |&gt; filter(C != 0),\n               mapping = aes(x=C, y, col = as.factor(MR),\n                   shape = as.factor(MR)), size=2) +\n  geom_point(data = meanc23 |&gt; filter(C == 0),\n             mapping = aes(x=C, y), shape=8, size=2) +\n  ylim(rangecc) + \n  labs(col = \"MR\", shape = \"MR\") + \n  theme(legend.position = \"bottom\")\n\nggarrange(pc12,pc13,pc23, nrow=1)\n\n\n\n\n\n\n\nFigura 6.15: Interações no fatorial com pontos centrais",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Economia na experimentação e busca de região de curvatura via Fatorial 2^k</span>"
    ]
  },
  {
    "objectID": "06-fatunrep_frac.html#bibliografia",
    "href": "06-fatunrep_frac.html#bibliografia",
    "title": "6  Fatorial de dois níveis não replicado e fracionado",
    "section": "Bibliografia",
    "text": "Bibliografia\nBOX, G. E. P.; HUNTER, J. Stuart. The 2 k—p Fractional Factorial Designs Part I. Technometrics, v. 42, n. 1, p. 28-47, 2000.\nBOX, George EP; HUNTER, J. S. The 2 k—p Fractional Factorial Designs Part II. Technometrics, v. 3, n. 4, p. 449-458, 1961.\nCHENG, Shao Wei; WU, CF J. Choice of optimal blocking schemes in two-level and three-level designs. Technometrics, v. 44, n. 3, p. 269-277, 2002.\nDANIEL, Cuthbert. Use of half-normal plots in interpreting factorial two-level experiments. Technometrics, v. 1, n. 4, p. 311-341, 1959.\nFISHER, Ronald A. The theory of confounding in factorial experiments in relation to the theory of groups. Annals of Eugenics, v. 11, n. 1, p. 341-353, 1941.\nLENTH, Russell V. Quick and easy analysis of unreplicated factorials. Technometrics, v. 31, n. 4, p. 469-473, 1989.\nSALLEH, Emee Marina; ZUHAILAWATI, Hussain; RAMAKRISHNAN, Sivakumar. Synthesis of biodegradable Mg-Zn alloy by mechanical alloying: Statistical prediction of elastic modulus and mass loss using fractional factorial design. Transactions of Nonferrous Metals Society of China, v. 28, n. 4, p. 687-699, 2018.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fatorial de dois níveis não replicado e fracionado</span>"
    ]
  },
  {
    "objectID": "07-rsm.html",
    "href": "07-rsm.html",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "",
    "text": "7.1 Introdução\nA metodologia de superfície de resposta (response surface methodology - RSM) foi apresentada por Box e Wilson (1951) como uma proposta para modelagem e otimização via experimentos planejados, sendo inicialmente aplicada em experimentos químicos. Atualmente a RSM é aplicada em diversas áreas onde deseja-se modelar e otimizar uma determinada resposta \\(y\\) em função de \\(k\\) variáveis de controle \\(x_1, x_2, \\dots, x_k\\). Dentro do contexto do DOE a RSM é um dos métodos mais usados para otimização em engenharia. As variáveis ditas de controle são independentes e podem ser referenciadas na literatura como variáveis preditoras, de controle ou de processo.\nPretende-se neste capítulo expor a busca de região de curvatura e teste via fatorial \\(2^k\\) com pontos centrais. Pretende-se também elucidar a metodologia de superfície de resposta, inclindo principais planejamentos, modelagem, análise de condições de otimalidade e otimização restrita.\nNeste capítulo são utilizados os pacotes FrF2, rsm, ggplot2 e ggpubr, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#intuição",
    "href": "07-rsm.html#intuição",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.2 Intuição",
    "text": "7.2 Intuição\nConsiderando uma resposta \\(y\\) dependente dos níveis de \\(k\\) variáveis independentes e quantitativas, passíveis de controle e mensuração, dada a observação de \\(N\\) combinações dos níveis das \\(k\\) variáveis de controle, pode-se estimar um modelo de resposta de \\(y\\) em função de \\(x_1, ..., x_k\\), conforme segue\n\\[\ny=f(\\mathbf{x})+\\varepsilon=f\\left(x_1, x_2, \\ldots, x_k\\right)+\\varepsilon\\text{,}\n\\]\ncom o erro experimental normalmente distribuído, \\(\\varepsilon \\sim N(0,\\sigma^2_\\varepsilon)\\).\nO erro experimental, dada a existência de variáveis de ruído, faz com que o modelo de superfície de resposta seja uma aproximação para a resposta na região experimental \\(k\\) dimensional. A motivação para a aproximação de uma função desconhecida em uma determinada região é baseada na expansão da série de Taylor em torno do ponto \\(\\mathbf{x_0} =x_{10}, x_{20}, ..., x_{k0}\\), \\(u = 1, ..., N\\). Por exemplo, considerando que uma aproximação de segunda ordem seja razoável para a região de interesse, um modelo de aproximação seria conforme Equação 7.1.\n\\[\n\\begin{equation}\n\\begin{aligned}\nf \\cong & f\\left(x_{10}, x_{20}, \\ldots, x_{k0}\\right) + \\sum_{i=1}^k \\left.\\frac{\\partial f}{\\partial x_i}\\right|_{\\mathbf{x}=\\mathbf{x}_0} \\left(x_i - x_{i0}\\right) \\\\\n& + \\frac{1}{2} \\sum_{i=1}^k \\left.\\frac{\\partial^2 f}{\\partial x_i^2}\\right|_{\\mathbf{x}=\\mathbf{x}_0} \\left(x_i - x_{i0}\\right)^2 \\\\\n& + \\sum_{i &lt; j} \\left.\\frac{\\partial^2 f}{\\partial x_i \\partial x_j}\\right|_{\\mathbf{x}=\\mathbf{x}_0} \\left(x_i - x_{i0}\\right)\\left(x_j - x_{j0}\\right)\n\\end{aligned}\n\\end{equation}\n\\tag{7.1}\\]\nOnde:\n\n\\(\\beta_0 = f\\left(x_{10}, x_{20}, \\ldots, x_{k0}\\right)\\);\n\\(\\beta_i = \\left.\\frac{\\partial f}{\\partial x_i}\\right|_{\\mathbf{x}=\\mathbf{x}_0}\\) (termos lineares);\n\\(\\beta_{ii} = \\frac{1}{2} \\left.\\frac{\\partial^2 f}{\\partial x_i^2}\\right|_{\\mathbf{x}=\\mathbf{x}_0}\\) (termos quadráticos puros);\n\\(\\beta_{ij} = \\left.\\frac{\\partial^2 f}{\\partial x_i \\partial x_j}\\right|_{\\mathbf{x}=\\mathbf{x}_0}\\) (termos de interação).\n\nO modelo final, após reparametrização, fica conforme Equação 7.2. Os termos quadráticos, \\(\\beta_{ii} x_i^2\\), são a novidade em relação ao modelo obtido via fatorial \\(2^k\\). Este modelo é dito de segunda ordem completo, contendouma constante, \\(k\\) termos lineares, \\(k\\) termos quadráticos ou de segunda ordem puros e \\(k(k-1)/2\\) termos de interação de sgeunda ordem ou termos de segunda ordem mistos.\n\\[\ny = \\beta_0 + \\sum_{i=1}^k \\beta_i x_i + \\sum_{i=1}^k \\beta_{ii} x_i^2 + \\sum_{i &lt; j} \\beta_{ij} x_i x_j + \\varepsilon\n\\tag{7.2}\\]\nO procedimento para encontrar a superfície de resposta pode seguir estratégia sequencial, envolvendo experimentos iniciais de varredura, busca da região de curvatura, estimativa de um modelo de superfície de resposta, até a obtenção das condições ótimas operacionais. Por exemplo, supondo um caso bidimensional com domínio experimental amplo, conforme observado na Figura 7.1, observa-se em cinza uma suposta função desconhecida de interesse. Para fins de modelagem e otimização, supõe-se inicialmente que o analista selecione a região delimitada pelo quadrado vermelho para um primeiro planejamento fatorial \\(2^k\\) com pontos centrais. A definição de uma região inicial pequena é razoável, visto que uma aproximação quadrática não seria suficiente para uma região ampla e complexa. Obtém-se para esta região um modelo linear. Define-se a direção de máximo crescimento da resposta a partir do gradiente da função linear estimada. Realiza-se outro planejamento fatorial \\(2^k\\) com pontos centrais. Obtém-se outro modelo linear e, analogamente, define-se a direção de máximo crescimento da resposta via gradiente. Finalmente, na terceira região a ser explorada, como o teste de curvatura realizado via fatorial \\(2^k\\) com pontos centrais indicou curvatura significativa, completa-se o planejamento com mais pontos e novos experimentos, definindo um planejamento com região circular observada em azul, viabilizando a obtenção de um modelo quadrático passível de otimização.\n\n\n\n\n\n\n\n\nFigura 7.1: Busca de região de curvatura via experimentação sequencial e subida mais íngreme",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#planejamento-composto-central",
    "href": "07-rsm.html#planejamento-composto-central",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.4 Planejamento composto central",
    "text": "7.4 Planejamento composto central\nO planejamento composto central (central composite design - CCD) apresenta boas propriedades de variância e tem sido extensivamente usado para obter modelos de superfície de resposta. O CCD possibilita a experimentação sequencial, garantindo economia na experimentação e busca de região de curvatura. Métodos como fatorial fracionado, blocagem do fatorial com pontos centrais e subida mais íngreme, conforme ilustrado na Figura 7.1 são comumente utilizados. Entretanto, em alguns problemas, devido a restrições de região experimental, realizar o CCD de forma direta é suficiente para obtenção de um modelo quadrático definitivo.\nA Figura 7.4 ilustra o planejamento CCD para \\(k = 2\\) e \\(k = 3\\) variáveis de controle. Pode-se observar que o planejamento é composto de \\(2^k\\) pontos fatoriais (ou \\(2^{k-p}\\) pontos de um fatorial fracionado com resolução V ou maior de preferência), \\(2k\\) pontos axiais e \\(nc\\) pontos centrais. Este planejamento pode ser usado para obter um modelo na forma da Equação 7.2. A Tabela 7.2 apresenta um arranjo CCD genérico. A distância dos pontos axiais \\(\\rho\\) e o número de pontos centrais é definida visando propriedades ótimas do planejamento e de previsão.\n\n\n\n\n\n\n\n\nFigura 7.4: Representação do CCD (a) \\(k=3\\); (b) \\(k=2\\)\n\n\n\n\n\n\n\n\n\nTabela 7.2: Planejamento CCD genérico\n\n\n\n\n\n\nordem\nx₁\nx₂\n⋯\nxₖ\n\n\n\n\n1\n-1\n-1\n⋯\n-1\n\n\n⋮\n1\n-1\n⋯\n-1\n\n\n⋮\n-1\n1\n⋯\n-1\n\n\n⋮\n1\n1\n⋯\n-1\n\n\n⋮\n⋮\n⋮\n⋯\n⋮\n\n\nnf = 2k\n1\n1\n⋯\n1\n\n\n1\n-ρ\n0\n⋯\n0\n\n\n⋮\nρ\n0\n⋯\n0\n\n\n⋮\n0\n-ρ\n⋯\n0\n\n\n⋮\n0\nρ\n⋯\n0\n\n\n⋮\n⋮\n⋮\n⋯\n⋮\n\n\n⋮\n0\n0\n⋯\n-ρ\n\n\nna = 2k\n0\n0\n⋯\nρ\n\n\n1\n0\n0\n⋯\n0\n\n\n⋮\n⋮\n⋮\n⋯\n⋮\n\n\nnc\n0\n0\n⋯\n0\n\n\n\n\n\n\n\n\n\n\nPelas ilustrações da Figura 7.4, pode-se inferir que o CCD se limita a uma região experimental esférica. O valor do raio do planejamento, \\(\\rho\\), pode ser considerado igual a \\(\\sqrt{k}\\) para que esta região seja um círculo, esfera ou hiperesfera perfeita. No entanto, Box definiu que o ideal para obter um CCD dito rotacionável é que \\(\\rho = 2^{k/4}\\). Um CCD rotacionável seria aquele no qual a variância do modelo se mantenha constante em pontos equidistanciados do centro do planejamento ou, de forma análoga, que a variância e covariância dos efeitos não seja alterada pela rotação do planejamento ou modelo. A rotação às vezes é importante, por exemplo ao diagonalizar o modelo para verificar as condições de otimalidade de primeira ordem, ou caracterizar a superfície de resposta. A título de exemplo a seguir expõe-se o código para obtenção de um CCD para \\(k = 3\\). Observa-se que \\(\\rho = 2^{k/4} = 1,6818\\). É possível obter um CCD esférico fazendo alpha = \"spherical\". Nos casos quando o número de fatores \\(k\\) é par o CCD rotacionável é perfeitamente esférico. Em casos onde a região experimental é restrita e deseja-se que a distância dos pontos axiais não seja maior que a dos fatoriais, faz-se alpha = \"faces\", obtendo um CCD de face centrada (face-centered central composite design - FCD). O CCD permite a blocagem da sequência experimental, caso inicalmente seja realizado o fatorial compontos centrais, conforme observado na última coluna. Porém, é necessário que sejam alocados pontos centrais na parte fatorial com o argumento n0.\n\nlibrary(rsm)\n\nccd(3, \n    n0 = c(0,3), \n    alpha = \"rotatable\",\n    randomize = F\n    )\n\n   run.order std.order  x1.as.is  x2.as.is  x3.as.is Block\n1          1         1 -1.000000 -1.000000 -1.000000     1\n2          2         2  1.000000 -1.000000 -1.000000     1\n3          3         3 -1.000000  1.000000 -1.000000     1\n4          4         4  1.000000  1.000000 -1.000000     1\n5          5         5 -1.000000 -1.000000  1.000000     1\n6          6         6  1.000000 -1.000000  1.000000     1\n7          7         7 -1.000000  1.000000  1.000000     1\n8          8         8  1.000000  1.000000  1.000000     1\n9          1         1 -1.681793  0.000000  0.000000     2\n10         2         2  1.681793  0.000000  0.000000     2\n11         3         3  0.000000 -1.681793  0.000000     2\n12         4         4  0.000000  1.681793  0.000000     2\n13         5         5  0.000000  0.000000 -1.681793     2\n14         6         6  0.000000  0.000000  1.681793     2\n15         7         7  0.000000  0.000000  0.000000     2\n16         8         8  0.000000  0.000000  0.000000     2\n17         9         9  0.000000  0.000000  0.000000     2\n\nData are stored in coded form using these coding formulas ...\nx1 ~ x1.as.is\nx2 ~ x2.as.is\nx3 ~ x3.as.is\n\n\nNo CCD os pontos fatoriais ou fracionados são usados para estimar os efeitos lineares e interações de segunda ordem. Os pontos centrais ajudam a estimar o erro experimental e contribuem para estimar os termos quadráticos. Os pontos axiais tem grande contribuição na estimativa dos termos quadráticos, de forma que sem eles somente o somatório dos termos quadráticos, \\(\\sum \\beta_{ii}\\), seria obtido, o que é usado para testar curvatura.\nNos planejamentos fatoriais a ortogonalidade do planejamento é uma propriedade que garante independência das variáveis de controle, baixa variância dos coeficientes, independência dos coeficientes e boa capacidade de previsão do modelo de resposta. Entretanto, em planejamentos de segunda ordem a ortogonalidade não é uma propriedade presente de forma a garantir a total independência dos coeficientes de regressão.\n\nExemplo 7.2 Seja um experimento para determinar o conteúdo de cobre em diferentes amostras de água via espectrometria de emissão óptica. Os fatores de controle são x1: \\(pH\\) e x2: vazao - \\(vz\\) (\\(mL/min\\)). Os níveis fatoriais são 7 e 9 para pH e 7 e 9 \\(mL/min\\) para \\(vz\\). A resposta consiste no sinal analítico resultante das medições de altura de pico instrumental. Uma vez medidos tais valores para os experimentos realizados, o maior foi considerado como 100 e os demais como porcentagem deste máximo (sinal analítico relativo). Foi utilizado um CCD rotacionável e RSM para inferência, modelagem e otimização. https://doi.org/10.1016/j.jhazmat.2010.07.014\n\nA Tabela 7.3 apresenta o planejamento considerado já com os resultados da resposta. O código apresentado em sequência pode ser usado para obtenção deste CCD e armazenamento da resposta. Pode-se observar que os fatores podem ser definidos de forma decodificada, ou seja, nas unidades originais. Por exemplo \\(x_1\\) consiste na vazão codificada, isto é, \\(x_1 = (vz-8)/1\\), onde 8 seria o nível central da vazão (a média dos fatoriais) e o denominador, neste caso unitário, consiste na distância entre os pontos fatoriais e o central.\n\n# Planejamento CCD\nccd1 &lt;- ccd(basis = ~x1+x2,\n            n0 = c(0,3),\n            alpha = \"rotatable\",\n            randomize = FALSE, \n            oneblock=TRUE,\n            coding = list(x1 ~ (vz - 8)/1,  # mL/min\n                          x2 ~ (pH - 8)/1)) # -\n\n# resposta - sinal analitico relativo\ny &lt;- c(68.64, 69.82, 81.66, 85.80, \n       79.29, 87.57, 74.56, 94.08, \n       100, 99.41, 100)\n\n# adicionando resposta ao planejamento\nccd1$y &lt;- y\n\n\n\n\n\nTabela 7.3: Planejamento CCD para determinação de conteúdo de cobre em água\n\n\n\n\n\n\nrun.order\nstd.order\nvz\npH\ny\n\n\n\n\n1\n1\n7.000000\n7.000000\n68.64\n\n\n2\n2\n9.000000\n7.000000\n69.82\n\n\n3\n3\n7.000000\n9.000000\n81.66\n\n\n4\n4\n9.000000\n9.000000\n85.80\n\n\n1\n1\n6.585786\n8.000000\n79.29\n\n\n2\n2\n9.414214\n8.000000\n87.57\n\n\n3\n3\n8.000000\n6.585786\n74.56\n\n\n4\n4\n8.000000\n9.414214\n94.08\n\n\n5\n5\n8.000000\n8.000000\n100.00\n\n\n6\n6\n8.000000\n8.000000\n99.41\n\n\n7\n7\n8.000000\n8.000000\n100.00",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#estimativa-dos-coeficientes-de-regressão",
    "href": "07-rsm.html#estimativa-dos-coeficientes-de-regressão",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.5 Estimativa dos coeficientes de regressão",
    "text": "7.5 Estimativa dos coeficientes de regressão\nSeja o modelo da Equação 7.2 escrito de forma expandida conforme Equação 7.6.\n\\[\ny=\\beta_0+\\beta_1 x_1+\\ldots+\\beta_k x_k+\\beta_{11} x_1^2+\\ldots+\\beta_{k k} x_k^2+\\beta_{12} x_1 x_2+\\ldots+\\beta_{(k-1)(k)} x_{(k-1)} x_{(k)}+\\varepsilon\n\\tag{7.6}\\]\nEm notação matricial, para facilitar a obtenção das estimativas de mínimos quadrados para os coeficientes, o modelo na forma da Equação 7.2 e da Equação 7.6, de forma análoga ao modelo obtido va fatorial \\(2^k\\), também pode ser representado como \\(\\mathbf{y}=X \\boldsymbol{\\beta}+\\boldsymbol{\\varepsilon}\\), com os devidos ajustes nas matrizes e vetores:\n\\[\n\\begin{aligned}\n& \\mathbf{y}=\\left[\\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_N\n\\end{array}\\right] ; \\quad \\mathbf{X}=\\left[\\begin{array}{cccccccccc}\n1 & x_{1(-)} & \\cdots & x_{k(-)} & x_1^2 & \\cdots & x_k^2 & x_{1(-)} x_{2(-)} & \\cdots & x_{k-1(-)} x_{k(-)} \\\\\n1 & x_{1(+)} & \\cdots & x_{k(-)} & x_1^2 & \\cdots & x_k^2 & x_{1(+)} x_{2(-)} & \\cdots & x_{k-1(-)} x_{k(-)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{1(+)} & \\cdots & x_{k(+)} & x_1^2 & \\cdots & x_k^2 & x_{1(+)} x_{2(+)} & \\cdots & x_{k-1(-)} x_{k(-)}\n\\end{array}\\right] ; \\\\\n& \\boldsymbol{\\beta}=\\left[\\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_k \\\\\n\\beta_{11} \\\\\n\\vdots \\\\\n\\beta_{k k} \\\\\n\\beta_{12} \\\\\n\\vdots \\\\\n\\beta_{(k-1)(k)}\n\\end{array}\\right]; \\text{ }\n\\boldsymbol{\\varepsilon}=\\left[\\begin{array}{c}\n\\varepsilon_1 \\\\\n\\varepsilon_2 \\\\\n\\vdots \\\\\n\\varepsilon_N\n\\end{array}\\right]\n\\end{aligned}.\n\\]\nOnde o vetor de respostas \\(\\mathbf y\\) é da ordem \\(N \\times 1\\), a matriz do planejamento \\(\\mathbf{X}\\) é da ordem \\(N \\times r\\), o vetor de coeficientes \\(\\boldsymbol{\\beta}\\) é da ordem \\(r \\times 1\\) e o vetor do erro aleatório é da ordem \\(N \\times 1\\), sendo \\(N = 2^k + 2k + n_c\\) e \\(r = 1 + 2^k + 2k + k(k − 1)/2\\) para um modelo de resposta completo correspondente à Equação 7.6. Os coeficientes podem ser estimados pelo método dos mínimos quadrados, \\(\\hat{\\boldsymbol{\\beta}}=\\left(\\mathbf{X}^{\\mathbf{T}} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\mathbf{T}} \\mathbf{y}\\). A variância do modelo de superfície de resposta depende da matriz do planejamento \\(\\mathbf X\\), com covariância \\(\\left(\\mathbf{X}^{\\mathbf{T}} \\mathbf{X}\\right)^{-1}\\), do ponto avaliado, que em um modelo quadrático completo é da forma \\(\\mathbf x_0^T = [1, x_1, \\dots,x_k, x_{11}, \\dots,x_{kk}, x_1x_2, \\dots, x_{k-1}x_k]^T\\), e do erro experimental \\(\\hat\\sigma^2 = \\sqrt{MS_E}\\), isto é, \\(Var[\\hat {\\mathbf y}(\\mathbf x)]=\\mathbf x_0^T\\left(\\mathbf{X}^{\\mathbf{T}} \\mathbf{X}\\right)^{-1}\\mathbf x_0\\).\nConsiderando o exemplo Exemplo 6.2 a seguir expõe-se a sintaxe para obtenção do modelo de regressão de superfície de resposta. Pode-se observar que o comando lm é utilizado, assim como no fatorial \\(2^k\\). Os termos quadráticos são adicionados usando a sintaxe I(xj^2). Para o estudo em questão observa-se que o termo linear do pH, o termo quadrático tanto da vazão quanto do pH foram significativos, além da constante.\n\nlm1 &lt;- lm(y ~ (x1+x2)^2 + I(x1^2) + I(x2^2), data = ccd1)\nsummary(lm1)\n\n\nCall:\nlm.default(formula = y ~ (x1 + x2)^2 + I(x1^2) + I(x2^2), data = ccd1)\n\nResiduals:\n      1       2       3       4       5       6       7       8       9      10 \n-3.0731 -4.6705 -2.7245 -4.3219  2.5680  4.8270  3.9440  3.4510  0.1967 -0.3933 \n     11 \n 0.1967 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   99.803      2.768  36.052 3.09e-07 ***\nx1             2.129      1.695   1.256  0.26470    \nx2             7.076      1.695   4.174  0.00871 ** \nI(x1^2)      -10.035      2.018  -4.974  0.00420 ** \nI(x2^2)       -9.590      2.018  -4.753  0.00509 ** \nx1:x2          0.740      2.397   0.309  0.77002    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.795 on 5 degrees of freedom\nMultiple R-squared:  0.9176,    Adjusted R-squared:  0.8352 \nF-statistic: 11.14 on 5 and 5 DF,  p-value: 0.009668\n\n# summary(aov(lm1))\n\nO modelo pode ser reduzido, usando o comando step, conforme segue. É importante notar que a estrutura hierárquica se mantém, de forma que a avaliação da eliminação de um termo linear só será realizada durante o algoritmo de eliminação caso o termo quadrático e os de interação que o involvem forem eliminados antes. Observa-se que o ajuste do modelo passou de 0,8352 para 0,8601 após a redução.\n\nlm1_red &lt;- step(lm1)\n\nStart:  AIC=37.81\ny ~ (x1 + x2)^2 + I(x1^2) + I(x2^2)\n\n          Df Sum of Sq    RSS    AIC\n- x1:x2    1      2.19 117.14 36.020\n&lt;none&gt;                 114.95 37.813\n- I(x2^2)  1    519.39 634.35 54.602\n- I(x1^2)  1    568.71 683.66 55.425\n\nStep:  AIC=36.02\ny ~ x1 + x2 + I(x1^2) + I(x2^2)\n\n          Df Sum of Sq    RSS    AIC\n&lt;none&gt;                 117.14 36.020\n- x1       1     36.25 153.39 36.986\n- x2       1    400.52 517.66 50.366\n- I(x2^2)  1    519.39 636.54 52.640\n- I(x1^2)  1    568.71 685.85 53.460\n\nsummary(lm1_red)\n\n\nCall:\nlm.default(formula = y ~ x1 + x2 + I(x1^2) + I(x2^2), data = ccd1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.4105 -2.8988  0.1967  3.0095  4.8270 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   99.803      2.551  39.122 1.86e-08 ***\nx1             2.129      1.562   1.363  0.22192    \nx2             7.076      1.562   4.529  0.00398 ** \nI(x1^2)      -10.035      1.859  -5.397  0.00167 ** \nI(x2^2)       -9.590      1.859  -5.158  0.00210 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.419 on 6 degrees of freedom\nMultiple R-squared:  0.916, Adjusted R-squared:  0.8601 \nF-statistic: 16.36 on 4 and 6 DF,  p-value: 0.002219",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#condições-de-otimalidade-de-primeira-ordem",
    "href": "07-rsm.html#condições-de-otimalidade-de-primeira-ordem",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.6 Condições de otimalidade de primeira ordem",
    "text": "7.6 Condições de otimalidade de primeira ordem\nApós apresentação do planejamento composto central e suas propriedades, além da obtenção do modelo de regressão, convém expor uma forma analítica para possibilitar a avaliação das condições de otimalidade de primeira ordem ou obtenção do ponto estacionário. O modelo exposto na Equação 7.6 também pode ser exposto em outra notação, sendo esta útil para otimização, conforme Equação 7.7:\n\\[\n\\hat y = \\beta_0 + \\mathbf{x}^T\\mathbf b + \\mathbf{x}^T\\mathbf B \\mathbf x\\text{ ,}\n\\tag{7.7}\\]\nonde \\(\\beta_0\\) é a estimativa da constante, \\(\\mathbf{x}\\) é o vetor das \\(k\\) variáveis de controle de ordem \\(k \\times 1\\), \\(\\mathbf b\\) é o vetor de coeficientes lineares de ordem \\(k \\times 1\\) e \\(\\mathbf B\\) é a matriz simétrica que contém os termos quadráticos e de interação de ordem \\(k \\times k\\), conforme segue. Pode-se averiguar que os elementos da diagonal principal desta matriz são responsáveis pelos efeitos quadráticos, enquanto os outros elementos contribuem para a obtenção dos termos de interação.\n\\[\n\\mathbf b = \\left[\\begin{array}{c}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_k\n\\end{array}\\right]\\text{, }\n\\mathbf x = \\left[\\begin{array}{c}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_k\n\\end{array}\\right]\\text{, }\n\\mathbf{X} = \\left[\\begin{array}{cccc}\n\\beta_{11} & \\beta_{12}/2 & \\cdots & \\beta_{1k}/2 \\\\\n& \\beta_{22} & \\cdots & \\beta_{2k}/2 \\\\\n&  & \\ddots & \\vdots \\\\\n\\text{sym} &   &   & \\beta_{kk}\n\\end{array}\\right] \\\\\n\\]\nPara obter o ponto de inflexão ou estacionário, que são as condições de otimalidade de primeira ordem, iguala-se o gradiente da função a zero e resolve-se para \\(\\mathbf x\\), conforme Equação 7.8.\n\\[\n\\begin{align}\n\\nabla \\hat y &= \\frac {\\partial \\hat y}{\\partial \\mathbf x} = 0 \\\\\n&= \\mathbf b + 2 \\mathbf B \\mathbf x = 0 \\\\\n\\end{align}\n\\]\n\\[\n\\mathbf x_s = -\\frac{1}{2}\\mathbf B^{-1}\\mathbf b\n\\tag{7.8}\\]\nO pacote rsm apresenta uma saída completa que, além do modelo de superfície de resposta, teste t e ANOVA reduzida, apresenta as condições de otimalidade de primeira ordem, ou ponto estacionário codificado e decodificado, além das condições de otimalidade de segunda ordem, às quais serão explicitadas em sequência. Pode-se usar a seguinte sintaxe, onde o modelo quadrático completo seria obtido via SO(x1,x2,...). O modelo reduzido deve ser escrito com termos de ordem distinta separados, com os termos de primeira ordem dentro de FO(x1,x2,...) e os termos quadráticos puros em PQ(x1,x2,...). Caso haja algum termo de interação significativo deveria vir com a sintaxe TWI(xi,xj). É importante esclarecer que para aplicar o comando step recomenda-se escrever o modelo da forma convencional e usar o comando lm, para depois definir o modelo reduzido análogo via rsm, obtendo uma análise completa.\n\n# modelo completo via funcao rsm\n# rsm1 &lt;- rsm(y~SO(x1,x2), data = ccd1)\n# summary(rsm1)\n\n# modelo reduzido\nrsm2 &lt;- rsm(y~FO(x1,x2)+PQ(x1,x2), data = ccd1)\nsummary(rsm2)\n\n\nCall:\nrsm(formula = y ~ FO(x1, x2) + PQ(x1, x2), data = ccd1)\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  99.8033     2.5510 39.1225 1.863e-08 ***\nx1            2.1287     1.5622  1.3626  0.221920    \nx2            7.0757     1.5622  4.5293  0.003978 ** \nx1^2        -10.0354     1.8594 -5.3972  0.001668 ** \nx2^2         -9.5904     1.8594 -5.1579  0.002099 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMultiple R-squared:  0.916, Adjusted R-squared:  0.8601 \nF-statistic: 16.36 on 4 and 6 DF,  p-value: 0.002219\n\nAnalysis of Variance Table\n\nResponse: y\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)\nFO(x1, x2)   2 436.77  218.39  11.186 0.009458\nPQ(x1, x2)   2 841.17  420.59  21.543 0.001826\nResiduals    6 117.14   19.52                 \nLack of fit  4 116.91   29.23 251.887 0.003958\nPure error   2   0.23    0.12                 \n\nStationary point of response surface:\n       x1        x2 \n0.1060599 0.3688933 \n\nStationary point in original units:\n      vz       pH \n8.106060 8.368893 \n\nEigenanalysis:\neigen() decomposition\n$values\n[1]  -9.590417 -10.035417\n\n$vectors\n   [,1] [,2]\nx1    0   -1\nx2   -1    0\n\n\nO ponto estacionário nas unidades originais consiste em vz = 8.106 \\(mL/min\\) e pH = 8.369. O comando rsm também retorna como saídas as matrizes \\(\\mathbf b\\) e \\(\\mathbf B\\), viabilizando a obtenção do ponto estacionário como -0.5*solve(B)%*%b, ou usando o comando canonical e a saída xs.\n\n# matrizes b e B\nb &lt;- rsm2$b\nB &lt;- rsm2$B\n\n# ponto estacionario\nxs &lt;- canonical(rsm2)$xs\n# ou\nxs &lt;- -0.5*solve(B)%*%b\nxs\n\n        [,1]\nx1 0.1060599\nx2 0.3688933\n\n\nPara saber o valor da resposta no ponto estacionário, isto é, \\(\\hat y(\\mathbf x_s)\\), pode-se usar o comando predict, conforme segue.\n\npredict(rsm2, newdata = data.frame(x1 = xs[1],\n                                   x2 = xs[2]))\n\n       1 \n101.2213 \n\n\nO modelo de superfície de resposta pode ser visualizado usando gráficos de superfície e/ou contorno, conforme Figura 7.5 e Figura 7.6, respectivamente. Especialmente no caso do gráfico de contorno fica fácil confirmar os níveis do ponto estacionário.\n\ncontour(rsm2, ~x1 + x2, image = TRUE)\n\n\n\n\n\n\n\nFigura 7.5: Gráfico de contorno para o experimento de determinação de conteúdo de cobre em água\n\n\n\n\n\n\npersp(rsm2, ~x1 + x2, zlab=\"y [%]\", \n      col = rainbow(50), contours = (\"colors\"))\n\n\n\n\n\n\n\nFigura 7.6: Gráfico de superfície para o experimento de determinação de conteúdo de cobre em água\n\n\n\n\n\nOutras visualizações podem ser concebidas para interpretar o efeito dos fatores na resposta de interesse, conforme Figura 7.7 e Figura 7.8 com códigos explicitados à seguir.\n\nlibrary(ggplot2)\n# x1\nx1_grid &lt;- seq(min(ccd1$x1), max(ccd1$x1), 0.1)\ncenter_grid &lt;- rep(0,length(x1_grid))\n\nx_range &lt;- c(min(c(predict(rsm2,\n                             newdata = data.frame(x1 = x1_grid, \n                                                  x2 = center_grid)),\n                         predict(rsm2,\n                             newdata = data.frame(x2 = x1_grid, \n                                                  x1 = center_grid)))),\n             max(c(predict(rsm2,\n                             newdata = data.frame(x1 = x1_grid, \n                                                  x2 = center_grid)),\n                         predict(rsm2,\n                             newdata = data.frame(x2 = x1_grid, \n                                                  x1 = center_grid))))\n             )\n\np1 &lt;- ggplot() +        \n  geom_line(aes(x = x1_grid, \n                y = (predict(rsm2,\n                             newdata = data.frame(x1 = x1_grid, \n                                                  x2 = center_grid)))),\n            linewidth = 1,\n            colour = 'firebrick1') +\n  xlab(\"vz [mL/min]\") +\n  ylab(\"sinal [%]\") + \n  ylim(x_range) + \n  scale_x_continuous(breaks = c(-1, 0, 1), label = c(7,8,9)) +\n  theme_bw()\n\np2 &lt;- ggplot() +        \n  geom_line(aes(x = x1_grid, \n                y = (predict(rsm2,\n                             newdata = data.frame(x2 = x1_grid, \n                                                  x1 = center_grid)))),\n            linewidth = 1,\n            colour = 'dodgerblue3') +\n  xlab(\"pH\") +\n  ylab(\"sinal [%]\") + \n  ylim(x_range) + \n  scale_x_continuous(breaks = c(-1, 0, 1), label = c(7,8,9)) +\n  theme_bw()\n\nlibrary(ggpubr)\nggarrange(p1,p2, nrow=1)\n\n\n\n\n\n\n\nFigura 7.7: Gráficos de efeitos principais para o experimento de determinação de conteúdo de cobre em água\n\n\n\n\n\n\np12 &lt;- ggplot() +\n  geom_line(aes(x = x1_grid, \n                y = predict(rsm2, \n                            newdata = data.frame(x2 = x1_grid, \n                                                 x1 = center_grid)),\n                color = \"8\", linetype = \"8\"), linewidth = 1) +\n  ggtitle('') +\n  xlab('pH') +\n  ylab('sinal [%]') +\n  ylim(58,103) + \n  scale_x_continuous(breaks = c(-1, 0, 1), label = c(7,8,9)) +\n  theme_bw()\n\nx2_grid_1 = rep(-1,length(x1_grid))\nx2_grid1 = rep(1,length(x1_grid))\n\np12 &lt;- p12 +\n  geom_line(aes(x = x1_grid,\n                y = predict(rsm2,\n                            newdata = data.frame(x2 = x1_grid,\n                                                 x1 = x2_grid_1)),\n                color = \"7\", linetype = \"7\"), linewidth = 1) +\n  geom_line(aes(x = x1_grid, \n                y = predict(rsm2, \n                            newdata = data.frame(x2 = x1_grid, \n                                                 x1 = x2_grid1)),\n                color = \"9\", linetype = \"9\"), linewidth = 1) +\n  scale_color_manual(name = \"vz\", \n                     values = c(\"7\" = \"orange1\", \n                                \"8\" = \"green3\", \n                                \"9\" = \"red1\")) +\n  scale_linetype_manual(name = \"vz\", \n                     values = c(\"7\" = \"dashed\", \n                                \"8\" = \"longdash\", \n                                \"9\" = \"solid\"))\n\np12\n\n\n\n\n\n\n\nFigura 7.8: Gráfico de interação para o experimento de determinação de conteúdo de cobre em água",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#condições-de-otimalidade-de-segunda-ordem",
    "href": "07-rsm.html#condições-de-otimalidade-de-segunda-ordem",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.7 Condições de otimalidade de segunda ordem",
    "text": "7.7 Condições de otimalidade de segunda ordem\nPor ambas representações gráficas das Figura 7.7 e Figura 7.8 observa-se que o modelo obtido tem convexidade para baixo, apresentando ponto de máximo. Como no experimento do Exemplo 7.2 deseja-se maximizar a resposta, o ponto estacionário é suficiente para garantir o máximo rendimento no processo de estração de cobre. Existem casos, porém, que não é possível avaliar se o ponto estacionário é de interesse prático ou seja, sua natureza, de forma a saber se ele maximiza ou minimiza a função. Isso acontece porque quando \\(k \\ge 3\\) a superfície de resposta não pode ser visualizada integralmente. Em tais casos é comum avaliar as condições de otimalidade de segunda ordem ou a natureza do ponto estacionário e a convexidade da superfície de resposta.\nAs condições de otimalidade de segunda ordem ou condições são obtidas a partir da matriz hessiana, ou seja, se por exemplo \\(\\mathbf H = \\nabla^2 \\hat y\\) é positiva definida. A matriz \\(\\mathbf{H}\\) é obtida conforme segue. Pode-se observar que ela consiste na matriz \\(\\mathbf{B}\\) multiplicada por 2.\n\\[\n\\mathbf{H} = \\nabla^2 \\hat{y}(\\mathbf{x}) =\n\\left[\n\\begin{array}{cccc}\n\\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_1^2} & \\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_1 \\partial x_k} \\\\\n\\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_k \\partial x_1} & \\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_k \\partial x_2} & \\cdots & \\frac{\\partial^2 \\hat{y}(\\mathbf{x})}{\\partial x_k^2}\n\\end{array}\n\\right]\n=\n\\left[\n\\begin{array}{cccc}\n2{\\beta}_{11} & {\\beta}_{12} & \\cdots & {\\beta}_{1k} \\\\\n{\\beta}_{12} & 2{\\beta}_{22} & \\cdots & {\\beta}_{2k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n{\\beta}_{1k} & {\\beta}_{2k} & \\cdots & 2{\\beta}_{kk}\n\\end{array}\n\\right]\n= 2{\\mathbf{B}}\n\\]\nSabendo que a matriz \\(\\mathbf{B}\\) é simétrica de ordem \\(k \\times k\\), pelo teorema da decomposição espectral, existe uma matriz ortogonal \\(\\mathbf{P}\\), \\(k \\times k\\), tal que \\(\\mathbf{P}^T\\mathbf{B}\\mathbf{P} = \\mathbf \\Lambda\\), que contém em cada coluna os autovetores \\(w = [w_1, w_2, \\cdots, w_k]\\) associados aos autovalores de \\(\\mathbf{B}\\). A matriz \\(\\mathbf \\Lambda\\) é a matriz diagonal de autovalores \\(\\lambda_i\\), \\(i = 1, …, k\\), de \\(\\mathbf{B}\\). Os sinais dos autovalores, \\(\\lambda_i\\), determinam a natureza do ponto estacionário e o tipo de superfície de resposta. A Figura 7.9 ilustra uma superfície de resposta com orientação inclinada em relação aos eixos das variáveis independentes. Tal inclinação aparecerá sempre que os termos de interação, o qual compõe os termos fora da diagonal da matriz \\(\\mathbf B\\) forem não nulos. As linhas que definem os eixos do modelo são os autovalores deste. É importante rotacionar o modelo, ou diagonalizar \\(\\mathbf B\\), de forma que a análise dos sinais de \\(\\lambda_i\\) viabilizem a interpretação da convexidade do modelo.\n\n\n\n\n\n\n\n\nFigura 7.9: Superfície de resposta com orientação inclinada em relação aos eixos das variáveis independentes\n\n\n\n\n\nA interpretação das condições de otimalidade de segunda ordem para superfície de resposta pode ser feita conforme segue:\n\nSe \\(\\lambda_1, \\cdots, \\lambda_k\\) são negativos, \\(\\mathbf{B}\\) é negativa definida, \\(\\hat y\\) tem convexidade para baixo e o ponto estacionário é de máximo;\nSe \\(\\lambda_1, \\cdots, \\lambda_k\\) são positivos, \\(\\mathbf{B}\\) é positiva definida, \\(\\hat y\\) tem convexidade para cima e o ponto estacionário é de mínimo;\nSe \\(\\lambda_1, \\cdots, \\lambda_k\\) são mistos, \\(\\mathbf{B}\\) é indefinida e o ponto estacionário é de sela.\n\nA Figura 7.10 ilustra três exemplos de modelos com distintas características de convexidade. À esquerda um modelo com autovalores negativos, no meio um com autovalores positivos e à direita um com autovalores mistos, apresentando respectivamente ponto estacionário de máximo, de mínimo e de sela. É importante perceber que este último não é de máximo tampouco de mínimo. Na prática caso o objetivo seja maximizar a resposta é interessante obter uma superfície de resposta com convexidade para baixo. Caso o objetivo seja minimizar a resposta é interessante obter uma superfície de resposta com convexidade para cima. A superfície no formato de sela nunca é interessante, uma vez que o ponto estacionário é apenas um ponto onde a derivada é nula, mas não otimiza a função, independente do objetivo do estudo.\n\n\n\n\n\n\n\n\nFigura 7.10: Gráfico de interação para o experimento de determinação de conteúdo de cobre em água\n\n\n\n\n\nPara obter os autovalores de \\(\\mathbf{B}\\) deve-se resolver o autoproblema \\(|\\mathbf{B} - \\mathbf \\lambda \\mathbf I| = 0\\), resultando ema uma equação polinomial de ordem \\(k\\) cujas raizes são os autovalores de \\(\\mathbf{B}\\).\n\nExemplo 7.3 Seja um estudo para otimizar a composição de catalisadores à base de Co, Ce e W suportados em carvão ativado, com foco na reforma de \\(CO_2–CH_4\\). Os fatores de controle são x1: massa de Co (g), x2: massa de W (g) e x3: massa de Ce (g). A resposta consiste no rendimento de CO. https://doi.org/10.1016/j.ijhydene.2020.01.226\n\nO planejamento para o Exemplo 7.3 pode ser obtido com o código a seguir. Os valores da resposta também são fornecidos.\n\nplan &lt;-  ccd(basis = ~x1+x2+x3,\n             n0 = c(0,3),\n             randomize = F,\n             alpha = \"rotatable\",\n             coding = list(x1 ~ (Co - 10)/2, #  Co\n                           x2 ~ (W - 1.5)/0.5, # W\n                           x3 ~ (Ce - 4)/1)) # Ce\nplan\n\n   run.order std.order        Co         W       Ce Block\n1          1         1  8.000000 1.0000000 3.000000     1\n2          2         2 12.000000 1.0000000 3.000000     1\n3          3         3  8.000000 2.0000000 3.000000     1\n4          4         4 12.000000 2.0000000 3.000000     1\n5          5         5  8.000000 1.0000000 5.000000     1\n6          6         6 12.000000 1.0000000 5.000000     1\n7          7         7  8.000000 2.0000000 5.000000     1\n8          8         8 12.000000 2.0000000 5.000000     1\n9          1         1  6.636414 1.5000000 4.000000     2\n10         2         2 13.363586 1.5000000 4.000000     2\n11         3         3 10.000000 0.6591036 4.000000     2\n12         4         4 10.000000 2.3408964 4.000000     2\n13         5         5 10.000000 1.5000000 2.318207     2\n14         6         6 10.000000 1.5000000 5.681793     2\n15         7         7 10.000000 1.5000000 4.000000     2\n16         8         8 10.000000 1.5000000 4.000000     2\n17         9         9 10.000000 1.5000000 4.000000     2\n\nData are stored in coded form using these coding formulas ...\nx1 ~ (Co - 10)/2\nx2 ~ (W - 1.5)/0.5\nx3 ~ (Ce - 4)/1\n\ny &lt;- c(88.36, 93.40, 89.22, 92.02, 91.28, 92.02, 89.62, 88.92,\n       85.98, 89.72, 91.43, 88.53, 95.66, 94.63,         \n       94.38, 94.53, 94.08) \n\nplan$y &lt;- y\n\nA seguir realiza-se a análise completa via rsm. Observa-se que todos os termos do modelo foram significativos e o modelo apresentou excelente ajuste, com \\(R^2_{aj} = 0,9894\\). Apesar dos autovalores serem obtidos, neste caso eles não são úteis, dado que os autovalores são mistos, de forma que o modelo tem formato de sela.\n\nres.rsm &lt;- rsm(y ~ SO(x1,x2,x3), data = plan)\nsummary(res.rsm)\n\n\nCall:\nrsm(formula = y ~ SO(x1, x2, x3), data = plan)\n\n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) 94.341870   0.164148 574.7379 &lt; 2.2e-16 ***\nx1           1.037567   0.077085  13.4600 2.932e-06 ***\nx2          -0.743744   0.077085  -9.6483 2.708e-05 ***\nx3          -0.211780   0.077085  -2.7474  0.028613 *  \nx1:x2       -0.460000   0.100717  -4.5673  0.002582 ** \nx1:x3       -0.975000   0.100717  -9.6806 2.649e-05 ***\nx2:x3       -0.530000   0.100717  -5.2623  0.001170 ** \nx1^2        -2.331911   0.084843 -27.4849 2.166e-08 ***\nx2^2        -1.578842   0.084843 -18.6089 3.211e-07 ***\nx3^2         0.247261   0.084843   2.9143  0.022521 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMultiple R-squared:  0.9954,    Adjusted R-squared:  0.9894 \nF-statistic: 167.6 on 9 and 7 DF,  p-value: 2.464e-07\n\nAnalysis of Variance Table\n\nResponse: y\n                Df Sum Sq Mean Sq F value    Pr(&gt;F)\nFO(x1, x2, x3)   3 22.869  7.6230  93.937 5.112e-06\nTWI(x1, x2, x3)  3 11.545  3.8483  47.422 5.104e-05\nPQ(x1, x2, x3)   3 87.991 29.3302 361.429 4.909e-08\nResiduals        7  0.568  0.0812                  \nLack of fit      5  0.463  0.0926   1.764    0.4001\nPure error       2  0.105  0.0525                  \n\nStationary point of response surface:\n        x1         x2         x3 \n 0.1693026 -0.3289331  0.4095174 \n\nStationary point in original units:\n       Co         W        Ce \n10.338605  1.335533  4.409517 \n\nEigenanalysis:\neigen() decomposition\n$values\n[1]  0.3614754 -1.5213599 -2.5036078\n\n$vectors\n         [,1]        [,2]      [,3]\nx1  0.1675212  0.30486530 0.9375467\nx2  0.1138866 -0.95060326 0.2887616\nx3 -0.9792683 -0.05840032 0.1939663\n\n\nA Figura 7.11 ilustra gráficos de contorno obtidos com código abaixo. É importante entender que cada visualização consiste em um corte do modelo que não pode ser visualizado de forma integral, uma vez que está no \\(\\mathcal R ^4\\). Logo, para cada par de variáveis plotadas, a remanescente é fixada, neste caso no nível central.\n\npar(mfrow = c(1,3))\ncontour(res.rsm, ~x1 + x2 + x3, image = TRUE)\n\n\n\n\n\n\n\nFigura 7.11: Gráficos de contorno para rendimento de CO",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#planejamento-box-behnken",
    "href": "07-rsm.html#planejamento-box-behnken",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.9 Planejamento Box-Behnken",
    "text": "7.9 Planejamento Box-Behnken\nO planejamento Box-Behnken (Box-Behnken Design - BBD) foi proposto pelos pesquisadores George Box e Bonald Behnken nos anos 60, como proposta alternativa para obtenção de modelos de superfície de resposta, garantindo boas propriedades estatísticas e baixo custo na experimentação. Para \\(k\\leq6\\) fatores o planejamento consiste em blocos de combinações de fatoriais \\(2^2\\) com os fatores remanescentes fixos no ponto central. A Figura 7.12 ilustra o planejamento para \\(k=3\\) com três pontos centrais, com correspondência com a Tabela 7.4. Pode-se observar em azul os 4 primeiros pontos consistindo em um fatorial \\(2^2\\) para \\(x_1\\) e \\(x_2\\) com \\(x_3\\) no ponto central, os pontos 5 a 8 com um fatorial \\(2^2\\) para \\(x_1\\) e \\(x_3\\) e \\(x_2\\) no ponto central e os pontos 9 a 12 com um fatorial \\(2^2\\) para \\(x_2\\) e \\(x_3\\) e \\(x_1\\) no ponto central, além de três pontos centrais nos experimentos 13 a 15. O número de pontos centrais pode ser customizado. Para \\(k=6\\) ou mais fatores ao invés de combinações de fatoriais \\(2^2\\) são considerados fatoriais \\(2^3\\).\n\n\n\n\n\n\n\n\nFigura 7.12: Representação do BBD para \\(k=3\\)\n\n\n\n\n\n\n\n\n\nTabela 7.4: Planejamento BBD para k=3 fatores com pontos centrais\n\n\n\n\n\n\nOrdem\nx₁\nx₂\nx₃\n\n\n\n\n1\n-1\n-1\n0\n\n\n2\n1\n-1\n0\n\n\n3\n-1\n1\n0\n\n\n4\n1\n1\n0\n\n\n5\n-1\n0\n-1\n\n\n6\n1\n0\n-1\n\n\n7\n-1\n0\n1\n\n\n8\n1\n0\n1\n\n\n9\n0\n-1\n-1\n\n\n10\n0\n1\n-1\n\n\n11\n0\n-1\n1\n\n\n12\n0\n1\n1\n\n\n13\n0\n0\n0\n\n\n14\n0\n0\n0\n\n\n15\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\nUm planejamento BBD para \\(k\\leq5\\) apresenta \\(N=2k(k-1)+n_c\\) experimentos no total. Para os pontos nas arestas do cubo a distância até os pontos centrais é exatamente igual a \\(\\sqrt{2}\\). Ou seja, o BBD é um planejamento esférico com raio igual \\(\\sqrt{2}\\) para \\(k\\leq5\\) e \\(\\sqrt{3}\\) para \\(k\\geq6\\). Recomenda-se entretanto realizar RSM para número baixo de fatores. É importante observar que o BBD só é possível para \\(k\\geq3\\) fatores.\nA Tabela 7.5 compara o número de ensaios para o BBD e o CCD segundo o número de fatores. Observa-se que para \\(3\\leq k\\leq4\\) o BBD é uma opção interessante, sendo mais econômico que o CCD. Já para \\(k \\geq5\\) o CCD resulta em número menor de ensaios. É importante enfatizar que a escolha não deve-se basear somente no número de experimentos, mas também na estratéga experimental almejada. Por exemplo, o CCD permite a experimentação sequencial. Outra questão é que enquanto no CCD o raio do planejamento cresce com \\(k\\), no BBD ele é fixo, de forma que, ao se realizar procedimentos de otimização restrita para casos onde as condições de otimalidade de segunda ordem não são de interesse, a região experimental codificada é limitada comparativamente ao CCD. Obviamente tudo depende da relativa escolha dos níveis decodificados dos fatores em estudo.\n\n\n\nTabela 7.5: Comparativo entre número de experimentos no CCD e no BBD\n\n\n\n\n\nk\nCCD\nBBD\n\n\n\n\n2\n8 + \\(n_c\\)\n-\n\n\n3\n14 + \\(n_c\\)\n12 + \\(n_c\\)\n\n\n4\n24 + \\(n_c\\)\n24 + \\(n_c\\)\n\n\n5\n26* + \\(n_c\\)\n40 + \\(n_c\\)\n\n\n6\n44 + \\(n_c\\)\n48 + \\(n_c\\)\n\n\n7\n78 + \\(n_c\\)\n56 + \\(n_c\\)\n\n\n*fatorial fracionado \\(2^{5-1}\\)\n\n\n\n\n\n\n\n\n\nExemplo 7.4 Seja um experimento de sinterização de inibição seletiva de peças de polietileno de alta densidade com os seguintes fatores de controle: x1: altura da camada (mm), x2: Energia do aquecedor (\\(J/mm^2\\)), x3: Velocidade de avanço do aquecedor (mm/s) e x4: Velocidade de avanço da impressora (mm/min). A resposta y consiste no encolhimento das peças no sentido da largura. # https://link.springer.com/article/10.1007%2Fs40799-018-0286-6\n\nA Tabela Tabela 7.6 apresenta o planejamento com a resposta, o qual pode ser obtido com o código abaixo.\n\n# Planejamento\ndesign &lt;- bbd(k = ~x1+x2+x3+x4,\n              block = F,\n              n0 = 5,\n              randomize = F,\n              coding = list(x1 ~ (Ac - 0.2)/0.1,\n                            x2 ~ (Ea - 25.32)/3.16,\n                            x3 ~ (vf_a - 3.5)/0.5,\n                            x4 ~ (vf_p - 100)/20))\n\n# desvio na largura\nwidth &lt;- c(5.3533, 5.2615, 5.0008, 4.2712, 4.5840, 2.7470, 3.8086, 3.9839, \n           4.3630, 3.5519, 4.0534, 4.0031, 5.1495, 4.5581, 4.1959, 3.5946, \n           5.1642, 4.0103, 3.6354, 4.2529, 3.5171, 4.4485, 5.3879, 3.4132, \n           3.8905, 4.3263, 4.2203, 3.9451, 3.9024)\n\ndesign$y &lt;- width\n\n\n\n\n\nTabela 7.6: Planejamento BBD para k=3 fatores com pontos centrais\n\n\n\n\n\n\nrun.order\nstd.order\nx1\nx2\nx3\nx4\ny\n\n\n\n\n1\n1\n-1\n-1\n0\n0\n5.3533\n\n\n2\n2\n1\n-1\n0\n0\n5.2615\n\n\n3\n3\n-1\n1\n0\n0\n5.0008\n\n\n4\n4\n1\n1\n0\n0\n4.2712\n\n\n5\n5\n0\n0\n-1\n-1\n4.5840\n\n\n6\n6\n0\n0\n1\n-1\n2.7470\n\n\n7\n7\n0\n0\n-1\n1\n3.8086\n\n\n8\n8\n0\n0\n1\n1\n3.9839\n\n\n9\n9\n-1\n0\n0\n-1\n4.3630\n\n\n10\n10\n1\n0\n0\n-1\n3.5519\n\n\n11\n11\n-1\n0\n0\n1\n4.0534\n\n\n12\n12\n1\n0\n0\n1\n4.0031\n\n\n13\n13\n0\n-1\n-1\n0\n5.1495\n\n\n14\n14\n0\n1\n-1\n0\n4.5581\n\n\n15\n15\n0\n-1\n1\n0\n4.1959\n\n\n16\n16\n0\n1\n1\n0\n3.5946\n\n\n17\n17\n-1\n0\n-1\n0\n5.1642\n\n\n18\n18\n1\n0\n-1\n0\n4.0103\n\n\n19\n19\n-1\n0\n1\n0\n3.6354\n\n\n20\n20\n1\n0\n1\n0\n4.2529\n\n\n21\n21\n0\n-1\n0\n-1\n3.5171\n\n\n22\n22\n0\n1\n0\n-1\n4.4485\n\n\n23\n23\n0\n-1\n0\n1\n5.3879\n\n\n24\n24\n0\n1\n0\n1\n3.4132\n\n\n25\n25\n0\n0\n0\n0\n3.8905\n\n\n26\n26\n0\n0\n0\n0\n4.3263\n\n\n27\n27\n0\n0\n0\n0\n4.2203\n\n\n28\n28\n0\n0\n0\n0\n3.9451\n\n\n29\n29\n0\n0\n0\n0\n3.9024\n\n\n\n\n\n\n\n\nA análise pode ser realizada com o comando rsm, conforme segue. Pelos resultados observa-se que apenas as interações \\(x_1x_2\\), \\(x_1x_4\\) e \\(x_2x_3\\) não foram significativas, além do termo quadrático \\(x_3^2\\). O modelo apresenta um bom ajuste, com \\(R_{aj}^2 = 0,9198\\), porém sugere-se ao leitor tentar reduzir o modelo via lm e step para avaliar se é possível melhorar um pouco mais, aproximando \\(R_{aj}^2\\) de \\(R^2\\). Já é possível constatar pela análise dos sinais dos autovalores que o ponto estacionário não é últil para minimizar o desvio dimensional no sentido da largura.\n\n# Analise\nrsm.bbd &lt;- rsm(y ~ SO(x1,x2,x3,x4), data = design)\nsummary(rsm.bbd)\n\n\nCall:\nrsm(formula = y ~ SO(x1, x2, x3, x4), data = design)\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  4.056920   0.081357 49.8655 &lt; 2.2e-16 ***\nx1          -0.184933   0.052516 -3.5215 0.0033875 ** \nx2          -0.298233   0.052516 -5.6789 5.693e-05 ***\nx3          -0.405417   0.052516 -7.7199 2.068e-06 ***\nx4           0.119883   0.052516  2.2828 0.0385872 *  \nx1:x2       -0.159450   0.090960 -1.7530 0.1014672    \nx1:x3        0.442850   0.090960  4.8686 0.0002485 ***\nx1:x4        0.190200   0.090960  2.0910 0.0552423 .  \nx2:x3       -0.002475   0.090960 -0.0272 0.9786765    \nx2:x4       -0.726525   0.090960 -7.9873 1.395e-06 ***\nx3:x4        0.503075   0.090960  5.5307 7.405e-05 ***\nx1^2         0.323777   0.071429  4.5328 0.0004688 ***\nx2^2         0.477602   0.071429  6.6864 1.033e-05 ***\nx3^2        -0.080797   0.071429 -1.1312 0.2769959    \nx4^2        -0.308648   0.071429 -4.3210 0.0007043 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nMultiple R-squared:  0.9599,    Adjusted R-squared:  0.9198 \nF-statistic: 23.94 on 14 and 14 DF,  p-value: 2.31e-07\n\nAnalysis of Variance Table\n\nResponse: y\n                    Df Sum Sq Mean Sq F value    Pr(&gt;F)\nFO(x1, x2, x3, x4)   4 3.6225 0.90563 27.3647 1.738e-06\nTWI(x1, x2, x3, x4)  6 4.1546 0.69243 20.9225 3.067e-06\nPQ(x1, x2, x3, x4)   4 3.3140 0.82850 25.0338 2.984e-06\nResiduals           14 0.4633 0.03310                  \nLack of fit         10 0.3000 0.03000  0.7347    0.6856\nPure error           4 0.1633 0.04083                  \n\nStationary point of response surface:\n        x1         x2         x3         x4 \n 1.0579092  0.1742857 -0.8902676 -0.4104952 \n\nStationary point in original units:\n        Ac         Ea       vf_a       vf_p \n 0.3057909 25.8707427  3.0548662 91.7900965 \n\nEigenanalysis:\neigen() decomposition\n$values\n[1]  0.6966486  0.3725336 -0.0899158 -0.5673314\n\n$vectors\n         [,1]        [,2]       [,3]        [,4]\nx1  0.4113305  0.78063120  0.4678823  0.05008278\nx2 -0.7896263  0.50636028 -0.1821966  0.29477793\nx3  0.2429853  0.36542084 -0.7745350 -0.45554504\nx4  0.3850399 -0.02611146 -0.3846896  0.83849651\n\n\nNão há indícios para rejeição da hipótese de normalidade dos resíduos, dado resultado do teste de Shapiro-Wilk exposto abaixo.\n\n# Normalidade\nshapiro.test(rsm.bbd$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  rsm.bbd$residuals\nW = 0.93612, p-value = 0.07937\n\n\nA Figura 7.13 ilustra gráficos de contorno para desvio dimensional de peças obtidas via sinterização de inibição seletiva.\n\n# Graficos\npar(mfrow = c(2,3))\ncontour(rsm.bbd, ~x1 + x2 + x3 + x4, image = TRUE)\n\n\n\n\n\n\n\nFigura 7.13: Gráficos de contorno para o desvio dimensional\n\n\n\n\n\nPor fim, apresenta-se o código e resultado da otimização restrita, sendo expostos níveis dos fatores que minimizam o desvio dimensional. Recomenda-se \\(Ac\\) = 0,1987 \\(mm\\), \\(Ea\\) = 24,628 \\(J/mm^2\\), \\(Vf_a\\) = 3,93 \\(mm/s\\) e \\(Vf_p\\) = 78,36 \\(mm/min\\). O desvio mínimo predito foi \\(\\hat y\\) = 2,6 \\(mm\\).\n\n# Otimizacao restrita\notimo &lt;- steepest(rsm.bbd, dist=seq(0, sqrt(2), by=.1), descent=TRUE)\n\nPath of steepest descent from ridge analysis:\n\notimo[nrow(otimo),]\n\n   dist     x1     x2   x3     x4 |     Ac       Ea vf_a  vf_p |  yhat\n15  1.4 -0.013 -0.219 0.86 -1.082 | 0.1987 24.62796 3.93 78.36 | 2.606",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#otimização-não-linear-restrita",
    "href": "07-rsm.html#otimização-não-linear-restrita",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.8 Otimização não linear restrita",
    "text": "7.8 Otimização não linear restrita\nPara os casos onde o modelo apresenta formato de sela ou então apresenta convexidade ao contrário do sentido desejado para otimização, sugere-se realizar a otimização não linear restrita que, no contexto da RSM, é chamada de análise rígida. Por exemplo, seja o caso onde deseja-se minimizar a resposta, a Equação 7.9 define a formulação da otimização restrita, onde a restrição \\(\\mathbf x^T\\mathbf x \\leq \\rho^2\\) define a região experimental, podendo ser escrita como \\(x_1^2 + x_2^2 + \\cdots + x_k^2 \\leq \\rho^2\\).\n\\[\n\\begin{align}\n\\min_{\\mathbf x} & \\{\\hat y = \\beta_0 + \\mathbf{x}^T\\mathbf b + \\mathbf{x}^T\\mathbf B \\mathbf x\\} \\\\\n\\textrm{s.t.: } & \\mathbf x^T\\mathbf x \\leq \\rho^2\\\\\n\\end{align}\n\\tag{7.9}\\]\nO código à seguir pode ser utilizado para maximizar o rendimento de CO considerando o modelo de superfície de resposta estimado restrito à região experimental. A restrição de desigualdade g_x foi definida. O comando solnl do pacote NlcOptim permite a minimização de funções usando o algoritmo de programação sequencial quadrática, o qual admite restrições. Tal comando foi implementado para minimização. Como deseja-se maximizar o rendimento, usa-se o artifício de minimizar o negativo da função.\n\ny_hat &lt;- function(x){\n  y_hat &lt;- predict(res.rsm, newdata = data.frame(x1 = x[1],\n                                                 x2 = x[2],\n                                                 x3 = x[3]))\n  return(-y_hat)\n}\n\nro &lt;&lt;- (2^3)^0.25 # raio do planejamento\n\n# restrição esférica\ng_x &lt;- function(x){\n  g1 &lt;- x[1]^2 + x[2]^2 + x[3]^2 - ro^2\n  return(list(ceq=NULL,c=g1))\n}\n\nx0 &lt;- rep(0,3)\n\n# Otimização\nlibrary(NlcOptim)\nres.otim &lt;- solnl(X = x0, objfun = y_hat, confun = g_x)\n\nA seguir obtém-se os níveis ótimos codificados dos parâmetros.\n\nres.otim$par\n\n            [,1]\n[1,]  0.47133056\n[2,] -0.02587354\n[3,] -1.61418871\n\n\nFinalmente obtém-se o rendimento ótimo.\n\n\n       1 \n96.04244 \n\n\nFelizmente o pacote rsm também apresenta a função steepest que viabiliza a obtenção do ótimo restrito à região esférica. A pequena diferença no resultado é devido ao passo utilizado de 0,01, neste caso.\n\n# Analise rigida\notim &lt;- steepest(res.rsm, dist=seq(0, ro, by=.01), descent = F)\n\nPath of steepest ascent from ridge analysis:\n\n# otim\notim[nrow(otim),]\n\n    dist    x1     x2     x3 |     Co     W    Ce |   yhat\n169 1.68 0.471 -0.026 -1.612 | 10.942 1.487 2.388 | 96.039",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#bibliografia",
    "href": "07-rsm.html#bibliografia",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "Bibliografia",
    "text": "Bibliografia\nANDERSON-COOK, C. M.; BORROR, C. M.; MONTGOMERY, D. C. Response surface design evaluation and comparison. Journal of Statistical Planning and Inference, v. 139, n. 2, p. 629-641, 2009.\nBOX, G. E. P.; DRAPER, N. R. A basis for the selection of a response surface design. Journal of the American Statistical Association, v. 54, n. 287, p. 622-654, 1959.\nBOX, G. E. P.; DRAPER, N. R. Response surfaces, mixtures, and ridge analyses. New Jersey: John Wiley & Sons, 2007.\nBOX, G. E. P.; HUNTER, J. S. Multi-factor experimental designs for exploring response surfaces. The Annals of Mathematical Statistics, p. 195-241, 1957.\nBOX, G. E. P.; HUNTER, J. S. The 2k-p fractional factorial designs. Technometrics, v. 3, n. 3, p. 311-351, 1961.\nBOX, G. E. P.; HUNTER, J. S.; HUNTER, William Gordon. Statistics for experimenters: design, innovation, and discovery. New York: Wiley-Interscience, 2005.\nBOX, G. E. P.; WILSON, K. B. On the Experimental Attainment of Optimum Conditions. Journal of the Royal Statistical Society. Series B (Methodological), v. 13, n. 1, p. 1-45, 1951.\nDEL CASTILLO, E. Process optimization: a statistical approach. New York: Springer, 2007.\nDRAPER, N. R.; GUTTMAN, I. An index of rotatability. Technometrics, v. 30, n. 1, p. 105-111, 1988.\nDRAPER, N. R.; LIN, D. K. J. Small response-surface designs. Technometrics, v. 32, n. 2, p. 187-194, 1990.\nDUNN, K. Process Improvement Using Data. Disponível em: http://learnche.org/pid, 2010. Acesso em: 05/2025.\nGIOVANNITTI-JENSEN, A.; MYERS, R. H. Graphical assessment of the prediction capability of response surface designs. Technometrics, v. 31, n. 2, p. 159-171, 1989.\nKHURI, A. I. A measure of rotatability for response-surface designs. Technometrics, v. 30, n. 1, p. 95-104, 1988.\nLUCAS, J. M. Which response surface design is best: a performance comparison of several types of quadratic response surface designs in symmetric regions. Technometrics, v. 18, n. 4, p. 411-417, 1976.\nMONTGOMERY, D. C. Design and analysis of experiments. John Wiley & Sons, 2013.\nMORRIS, M. D. A class of three-level experimental designs for response surface modeling. Technometrics, v. 42, n. 2, p. 111-121, 2000.\nMYERS, R. H.; MONTGOMERY, D. C.; ANDERSON-COOK, C. M. Response surface methodology: process and product optimization using designed experiments. John Wiley & Sons, 2016.\nNOCEDAL, J.; WRIGHT, S. J. Numerical optimization. Springer Science, v. 35, n. 67-68, p. 7, 2006.\nOYEJOLA, B. A.; NWANYA, J. C. Selecting the right Central Composite Design. International Journal of Statistics and Applications, v. 5, n. 1, p. 21-30, 2015.\nRAO, S. S. Engineering optimization: theory and practice. John Wiley & Sons, 2009.\nSEBER, G. A. F.; LEE, A. J. Linear regression analysis. John Wiley & Sons, 2003.\nUKAEGBU, E. C.; CHIGBU, P. E. Graphical evaluation of the prediction capabilities of partially replicated orthogonal central composite designs. Quality and Reliability Engineering International, v. 31, n. 4, p. 707-717, 2015.\nWEISBERG, S. Applied linear regression. John Wiley & Sons, 2005.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  },
  {
    "objectID": "08-mix.html",
    "href": "08-mix.html",
    "title": "8  Experimentos para Misturas",
    "section": "",
    "text": "8.1 Introdução\nOs planejamnetos fatoriais e de superfície de resposta possibilitam a inferência, modelagem e otimização considerando variáveis contínuas ou de processo. Tais variáveis incluem temperatura, pressão, velocidade, entre outras. Em procedimentos experimentais e processos onde deseja-se avaliar o efeito da proporção de dois ou mais componentes (reagentes ou ingredientes) existem planejamentos específicos para não somente avaliar a influência da proporção de cada componente na resposta, mas também visando obter a proporção ótima dos componentes. Tais experimentos são comuns na indústria química, farmacêutica, de alimentos, civil, entre outras. Estes experimentos são chamados de experimentos de misturas. Pretende-se neste capítulo elucidar as particularidades relacionadas a este tipo de experimento, os planejamentos disponíveis e como realizar a modelagem e otimização.\nNeste capítulo são utilizados os pacotes mixexp, ggtern, Ternary e NlcOptim, além das funções básicas do R. Recomenda-se a instalação destes utilizando o comando install.packages(\"&lt;nome_pacote&gt;\"). A instalação é realizada uma única vez, porém o pacote deve ser carregado via library(&lt;nome_pacote&gt;) sempre que deseja-se usar suas funções.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#trabalhando-com-proporções-de-componentes",
    "href": "08-mix.html#trabalhando-com-proporções-de-componentes",
    "title": "8  Experimentos para Misturas",
    "section": "8.2 Trabalhando com proporções de componentes",
    "text": "8.2 Trabalhando com proporções de componentes\nQuando trabalhamos com experimentos de misturas tem-se as seguintes restrições:\n\\[\n\\begin{align}\n&0 \\leq x_i \\leq 1 \\text{, } i=1\\dots,q \\\\\n&\\sum_{i=1}^q x_i =1,\n\\end{align}\n\\]\nou seja, obviamente cada um dos \\(q\\) componentes deve ter proporção entre 0 e 1 e a soma da proporção dos \\(q\\) componentes deve ser unitária. Pode-se inferir que \\(x_j = 1 -\\sum_{i \\neq j}x_i\\), ou seja, é possível saber a proporção de um componente caso saiba-se a proporção dos \\(q-1\\) remanmescentes. Neste sentido, há uma redundância moderada entre as proporções dos componentes em planejamentos para misturas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#polinômios-canônicos-de-misturas",
    "href": "08-mix.html#polinômios-canônicos-de-misturas",
    "title": "8  Experimentos para Misturas",
    "section": "8.3 Polinômios canônicos de misturas",
    "text": "8.3 Polinômios canônicos de misturas\nNos experimentos de misturas devido as restrições relacionadas à proporção de componentes, os modelos obtidos apresentam características especiais. Seja um modelo linear exposto à seguir.\n\\[\n\\begin{align}\n\\hat y =& \\beta_0^* + \\beta_1^*x_1 + \\beta_2^*x_2 + \\dots  + \\beta_q^*x_q \\\\\n\\hat y =& \\beta_0^* + \\sum_{i=1}^q \\beta_i^*x_i\\\\\n\\end{align}\n\\]\nSabendo que \\(\\sum_{i=1}^q x_i =1\\), pode-se fazer o seguinte:\n\\[\n\\begin{align}\n\\hat y =& \\beta_0^*\\underbrace{\\sum_{i=1}^q x_i =1}_1 + \\sum_{i=1}^q \\beta_i^*x_i \\\\\n\\hat y =& \\sum_{i=1}^q\\underbrace{(\\beta_0^* + \\beta_i^*)}_{\\beta_i}x_i\\\\\n\\hat y =& \\sum_{i=1}^q \\beta_ix_i.\n\\end{align}\n\\]\nPode-se observar que devido a restrição de soma unitária das proporções o modelo linear pode ser representado sem a constante ou, pode-se dizer que devido a redundância nas proporções dos componentes, o coeficiente \\(\\beta_i\\) consiste não somente no efeito linear, mas na constante ou intercepto no vértice \\(i\\), \\(i=1,\\dots,q\\).\nSeja um modelo de segunda ordem completo, conforme segue.\n\\[\n\\hat y = \\beta_0^* + \\sum_{i=1}^q \\beta_i^* x_i + \\sum_{i=1}^q \\beta_{ii}^* x_i^2 + \\sum_{i &lt; }\\sum_j \\beta_{ij}^* x_i x_j\n\\tag{8.1}\\]\nUsando \\(\\sum_{i=1}^q x_i =1\\) e \\(x_i^2 = x_i\\underbrace{(1 -\\sum_{x \\neq q}x_i)}_{x_i}\\), obtém-se:\n\\[\n\\hat y = \\sum_{i=1}^q \\beta_i x_i + \\sum_{i &lt; }\\sum_j \\beta_{ij} x_i x_j,\n\\tag{8.2}\\]\nonde \\(\\beta_i = \\beta_0^* + \\beta_j^* + \\beta_{jj}^*\\) e \\(\\beta_{ij} = \\beta_{ij}^* - \\beta_{ii}^* - \\beta_{jj}^*\\). Logo, dada a redundância nas proporções, um modelo de segunda ordem completo pode ser rezumido a um modelo com termos lineares e de interação. Entretanto, deve-se atentar que em tal modelo o termo linear abrange também a constante e o termo quadrático, enquanto o termo de interação é função dos termos de interação originais e quadráticos.\nEm modelos de misturas a multicolineariedade entre os componentes ocasionada pela restrição de soma unitária pode inflar \\(R^2\\) e dar uma impressão errada da capacidade de previsão do modelo. Logo, o coeficiente de determinação múltipla deve ser corrigido considerando o número de termos no modelo conforme Equação 8.3, onde \\(p\\) é o número de termos no modelo.\n\\[\nR^2_{corr} = 1 - \\biggl(\\frac{(1-R^2)(N-1)}{N-p-1} \\biggr)\n\\tag{8.3}\\]",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#sistema-de-coordenadas-simplex",
    "href": "08-mix.html#sistema-de-coordenadas-simplex",
    "title": "8  Experimentos para Misturas",
    "section": "8.4 Sistema de coordenadas simplex",
    "text": "8.4 Sistema de coordenadas simplex\nConsiderando as restrições relacionadas à proporção de componentes em uma mistura, é importante entender o sistema de coordenadas simplex, utilizado em experimentos para misturas. A Figura 8.1 ilustra o sistema de coordenadas simplex para \\(q=3\\) componentes. O sistema de coordenadas neste caso consiste em um triângulo equilátero com cada um dos vértices representando a proporção máxima de um dos componentes, ou seja, no vértice superior tem-se proporção máxima de \\(x_1\\), isto é, \\(x_1=1\\) e \\(x_2=x_3=0\\). No vértice da esquerda tem-se proporção máxima de \\(x_2\\), enquanto no vértice da direita tem-se proporção máxima de \\(x_3\\).\n\n\n\n\n\n\n\n\nFigura 8.1: Sistema de coordenadas simplex\n\n\n\n\n\nA Figura 8.2 plota três pontos distintos no sistema de coorenadas simplex para \\(q=3\\). Seja \\(\\mathbf x = (x_1,x_2,\\dots,x_3)\\). Neste caso foram plotados os pontos \\((0,6;0,2;0,2)\\) em vermelho, \\((0,3;0,6;0,1)\\) em azul e \\((0,4;0,3;0,3)\\) em verde. Neste gráfico os vértices e linhas de grade estão identificados em porcentagem.\n\n\n\n\n\n\n\n\nFigura 8.2: Exemplos de misturas no sistema de coordenadas simplex",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#planejamento-simplex-lattice",
    "href": "08-mix.html#planejamento-simplex-lattice",
    "title": "8  Experimentos para Misturas",
    "section": "8.5 Planejamento simplex-lattice",
    "text": "8.5 Planejamento simplex-lattice\nUm planejamento muito usual para misturas é o planejamento simplex-lattice ou rede simplex. Um planejamento simplex-lattice com \\(q\\) componentes e grau \\(m\\) pode ser denotado SLD(\\(q\\),\\(m\\)), onde \\(m\\) consiste no grau do polinômio de misturas a ser obtido. Neste planejamento o número total de experimentos para uma réplica pode ser calculado conforme segue:\n\\[\nN=\\binom {q+m-1}{m}=\\frac{(q+m-1)!}{m!(q-1)!}.\n\\]\nUm SLD(3,1) apresentará N = 3 experimentos, sendo representado conforme Figura 8.1, enquanto um SLD(3,2) apresentará N = 6 experimentos, conforme Figura 8.3. Os pontos nos vérticies são chamados de misturas puras, enquanto os pontos nas arestas são chamados de misturas binárias. Enquanto um SLD(3,1) permite a obtenção de um modelo na forma da Equação 8.1, um SLD(3,2) permite a obtenção de modelo na forma da Equação 8.2. A Tabela Tabela 8.1 apresenta um SLD(3,2).\n\n\n\n\n\n\n\n\nFigura 8.3: Planejamento SLD(3,2)\n\n\n\n\n\n\n\n\n\nTabela 8.1: Planejamento SLD(3,2)\n\n\n\n\n\n\nx1\nx2\nx3\n\n\n\n\n1.0\n0.0\n0.0\n\n\n0.5\n0.5\n0.0\n\n\n0.0\n1.0\n0.0\n\n\n0.5\n0.0\n0.5\n\n\n0.0\n0.5\n0.5\n\n\n0.0\n0.0\n1.0\n\n\n\n\n\n\n\n\nÉ importante observar também que em um planejamento simplex-lattice o grau é o contrário do espaçamento \\(\\delta\\) entre os pontos no espaço simplex ou, de forma análoga, \\(\\delta = 1/m\\). Logo, para \\(m=2\\), \\(delta = 1/2\\), o que fica claro na Figura 8.3, uma vez que o comprimento da aresta é unitário. Para finalizar, a Figura 8.4 ilustra um SLD(3,3). Pode-se observar que neste caso N = 10 e \\(\\delta = 1/3\\). O ponto que consiste em proporção de 1/3 para todos os três componentes é chamado de mistura ternária.\n\n\n\n\n\n\n\n\nFigura 8.4: Planejamento SLD(3,3)\n\n\n\n\n\n\nExemplo 8.1 Seja um experimento de misturas onde deseja-se otimizar a proporção de fibras naturais como reforço em um compósito. Foram utilizados três tipos de fibra: sisal (x1), juta (x2) e coco (x3). Foi utilizado um planejamento SLD(3,2). A resposta avaliada foi a tensão específica de ruptura e foram realizadas três réplicas.\n\nA Tabela 8.2 expõe o planejamento SLD(3,2) com a resposta. O código abaixo é usado para obter tal planejamento. O pacote mixexp é sugerido para análise de experimentos de msituras e o comando SLD é usado para obter um planejamento simplex-lattice.\n\n# simplex lattice com q = 3, m = 2\nplan.simplex &lt;- SLD(3,2)\n# plan.simplex\n\n# Desenho do planejamento\n# DesignPoints(plan.simplex)\n\n# planejamento foi replicado tres vezes\nplan.simplex &lt;- rbind(plan.simplex,\n                      plan.simplex,\n                      plan.simplex)\n\n# resposta\ny &lt;- c(28.56, 21.73, 26.38, 33.71, 24.22, 22.93,\n       29.58, 20.98, 25.9, 32.98, 23.98, 21.79,\n       29.26, 21.23, 26.65, 34, 23.15, 22.17)\n\nplan.simplex$SBS &lt;- y\n\n\n\n\n\nTabela 8.2: Planejamento SLD(3,2) para o experimento de fibras naturais\n\n\n\n\n\n\n\nx1\nx2\nx3\nSBS\n\n\n\n\n1\n1.0\n0.0\n0.0\n28.56\n\n\n2\n0.5\n0.5\n0.0\n21.73\n\n\n3\n0.0\n1.0\n0.0\n26.38\n\n\n4\n0.5\n0.0\n0.5\n33.71\n\n\n5\n0.0\n0.5\n0.5\n24.22\n\n\n6\n0.0\n0.0\n1.0\n22.93\n\n\n11\n1.0\n0.0\n0.0\n29.58\n\n\n21\n0.5\n0.5\n0.0\n20.98\n\n\n31\n0.0\n1.0\n0.0\n25.90\n\n\n41\n0.5\n0.0\n0.5\n32.98\n\n\n51\n0.0\n0.5\n0.5\n23.98\n\n\n61\n0.0\n0.0\n1.0\n21.79\n\n\n12\n1.0\n0.0\n0.0\n29.26\n\n\n22\n0.5\n0.5\n0.0\n21.23\n\n\n32\n0.0\n1.0\n0.0\n26.65\n\n\n42\n0.5\n0.0\n0.5\n34.00\n\n\n52\n0.0\n0.5\n0.5\n23.15\n\n\n62\n0.0\n0.0\n1.0\n22.17\n\n\n\n\n\n\n\n\nA análise a seguir com o comando MixModel permite a obtenção do modelo completo. Observa-se que apenas o termo \\(x_2x_3\\) não foi significativo e que o ajuste foi excelente. Caso seja usado model = 1, será obtido um modelo com apenas os termos lineares.\n\nres.comp &lt;- MixModel(frame = plan.simplex,\n                     response = \"SBS\",\n                     mixcomps = c(\"x1\", \"x2\", \"x3\"),\n                     model = 2)\n\n     \n      coefficients   Std.err    t.value         Prob\nx1        29.13333 0.2877756 101.236276 0.000000e+00\nx2        26.31000 0.2877756  91.425392 0.000000e+00\nx3        22.29667 0.2877756  77.479342 0.000000e+00\nx2:x1    -25.63333 1.4098069 -18.182159 4.230261e-10\nx3:x1     31.39333 1.4098069  22.267825 3.966427e-11\nx2:x3     -2.08000 1.4098069  -1.475379 1.658606e-01\n     \nResidual standard error:  0.498442  on  12 degrees of freedom \nCorrected Multiple R-squared:  0.9908558\n\n\nCaso seja desejado especificar um modelo distinto, por exemplo sem o coeficiente não significativo, pode-se usar o comando lm. É importante suprimir a constante neste caso, com -1 na fórmula.\n\n# Modelo reduzido\nres.red &lt;- lm(SBS ~ -1 + x1 + x2 + x3 + x1*x2 + x1*x3,\n              data = plan.simplex)\nsummary(res.red)\n\n\nCall:\nlm(formula = SBS ~ -1 + x1 + x2 + x3 + x1 * x2 + x1 * x3, data = plan.simplex)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.98000 -0.30917  0.06833  0.37333  0.80667 \n\nCoefficients:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nx1     29.1333     0.3005   96.94  &lt; 2e-16 ***\nx2     26.1367     0.2743   95.27  &lt; 2e-16 ***\nx3     22.1233     0.2743   80.64  &lt; 2e-16 ***\nx1:x2 -25.2867     1.4516  -17.42 2.15e-10 ***\nx1:x3  31.7400     1.4516   21.86 1.23e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5205 on 13 degrees of freedom\nMultiple R-squared:  0.9997,    Adjusted R-squared:  0.9996 \nF-statistic:  9266 on 5 and 13 DF,  p-value: &lt; 2.2e-16\n\n\nA Figura 8.5 ilustra o gráfico de contorno para o modelo reduzido. Observa-se que uma proporção próxima de 0,6 de fibra de sisal e uma proporção próxima de 0,4 para fibra de coco maximiza a resistência do compósito. O gráfico foi obtido via comando TernaryPlot da biblioteca Ternary, porém poderia ser obtido via ModelPlot da biblioteca mixexp.\n\n# contour plot\n# ModelPlot(model = res.red,\n#           dimensions = list(x1 = \"x1\", \n#                             x2 = \"x2\",\n#                             x3 = \"x3\"),\n#           contour = T,\n#           fill = T,\n#           axislabs = c(\"sisal\", \"juta\", \"coco\"),\n#           color.palette = cm.colors,\n#           colorkey = T)\n\n\nlibrary(Ternary)\npar(mar = rep(0.2, 4))\nTernaryPlot(alab = \"sisal\", blab = \"juta\", clab = \"coco\")\n\nFunctionToContour &lt;- function(a, b, c) {\n  yhat &lt;- predict(res.red, newdata = data.frame(x1=a,\n                                                x2=b,\n                                                x3=c))\n  return(yhat)\n  # 29.133*sisal + 26.1367*juta + 22.1233*coco - \n  #   25.2867*x1*x2 + 31.7400*x1*x3\n}\n\n# Add contour lines\nvalues &lt;- TernaryContour(FunctionToContour, \n                         # resolution = 36L, \n                         filled = TRUE)\n\nzRange &lt;- range(values$z, na.rm = TRUE)\n\n# Continuous legend for colour scale\nPlotTools::SpectrumLegend(\n  \"topleft\",\n  legend = round(seq(zRange[1], zRange[2], length.out = 4), 3),\n  palette = hcl.colors(265, palette = \"viridis\", alpha = 0.6),\n  bty = \"n\",    # No framing box\n  inset = 0.02,\n  xpd = NA      # Do not clip at edge of figure\n)\n\n\n\n\n\n\n\nFigura 8.5: Gráfico de contorno para o exprimento de misturas de fibras naturais\n\n\n\n\n\nA Figura 8.6 expõe o gráfico de efeitos para o experimento de misturas de fibras naturais. Observa-se que o eixo x apresenta-se em desvio do centróide que seria o centro do sistema de coordenadas simplex. Aumentando a proporção de \\(x_1\\) aumenta a resistência mecânica do compósito. Aumentando a proporção de \\(x_2\\) até em torno de pouco menos que 0,2 a mais que o centróide aumenta a resistência mecânica. Já para \\(x_2\\) a redução deste maximiza a resistência do material. Obviamente, deve-se pensar que aumentar um componente implica em reduzir ao menos um dos demais. O comando ModelEff tem duas opções Piepel ou Cox em dir=1 ou dir=2, respectivamente. Para mais detalhes ver Cornell (2011).\n\n# Grafico de efeitos\nModelEff(nfac = 3,\n         mod = 2,\n         dir = 2,\n         nproc = 0,\n         ufunc = res.comp)\n\n\n\n\n\n\n\nFigura 8.6: Gráfico de efeitos para o exprimento de misturas de fibras naturais\n\n\n\n\n\nApesar de neste caso o gráfico de contorno exposto na Figura 8.5 auxiliar na definição das proporções ótimas, na maioria dos casos, especialmente onde \\(q \\geq 4\\), é importante realizar a otimização restrita, conforme Equação 8.4. Neste procedimento deseja-se minimizar o modelo polinomial de misturas sujeito as restrições de proporção e soma unitária das proporções. A maioria dos pacotes de otimização são implementados para minimização, de forma que, caso seja desejado a maximização da função, conforme o exemplo de misturas de fibras, pode-se minimizar o negativo e depois multiplicar o resultado obtido por menos 1.\n\\[\n\\begin{align}\n\\min_{\\mathbf x} & \\{\\hat y = \\sum_{i=1}^q \\beta_i x_i + \\sum_{i &lt; j} \\beta_{ij} x_i x_j\\} \\\\\n\\textrm{s.t.: } & 0 \\leq x_i \\leq 1 \\text{, } i = 1,\\dots,q \\\\\n                & \\sum_{i=1}^q x_i =1 \\\\\n\\end{align}\n\\tag{8.4}\\]\nPara otimização de modelos polinomiais de misturas quadráticos pode-se usar métodos de programação não-linear, como a programação sequencial quadrática. O pacote NlcOptim tem a função solnl que considera este método. A seguir expõe-se a implementação do procedimento para otimização. Deve-se defirnir a função objetivo. Neste caso sugere-se usar o artifício de colocar a função predict disponível para modelos lm em uma função via function. Deve-se definir a restrição igualdade (ceq) nula, na forma \\(\\sum x_i - 1\\). Já as proporções são definidas via limites inferiores (lower bound - lb) e superiores (upper bound - ub) em 0 e 1, respectivamente, para todos os componentes da mistura.\n\nlibrary(NlcOptim)\n### Otimizacao nao linear restrita\n# Funcao objetivo\nobj &lt;- function(x){\n  \n  y_hat &lt;- predict(res.red, \n                   newdata = data.frame(x1 = x[1],\n                                        x2 = x[2],\n                                        x3 = x[3]))\n  return(-y_hat)\n}\n\n# restricao de espaco experimental\ncons_eq &lt;- function(x){ \n  \n  g &lt;- x[1] + x[2] + x[3] - 1\n  \n  return(list(ceq = g, c = NULL))\n  \n}\n\n# x inicial\nx0 &lt;- c(1/3, 1/3, 1/3)\n\n# Teste funcao objetivo e restricao\n# obj(x0)\n# cons_eq(x0)\n\n# otimizacao\nOpt &lt;- solnl(X = x0,\n             objfun = obj,\n             confun = cons_eq,\n             lb = rep(0,3), \n             ub = rep(1,3))\n\nA seguir expõe-se o código para se obter as proporções ótimas dos componentes. Sugere-se 0,61 de fibra de sisal e 0,39 de fibra de coco.\n\n# Proporcoes otimas\nOpt$par\n\n              [,1]\n[1,]  6.104285e-01\n[2,] -6.384098e-13\n[3,]  3.895715e-01\n\n\nPor fim, obtém-se o valor ótimo previsto da resposta conforme segue. Neste caso a mistura ótima de fibras possibilitaria a obtenção de um compósito com tensão específica de ruptura de 33,95 MPa.\n\n# resposta otima\n-Opt$fn\n\n       1 \n33.95039 \n\n\nPara modelos de ordem maior sugere-se usar algoritmo genético ou outro método metaheurístico populacional, de forma a viabilizar uma busca não dependente do gradiente, uma vez que ainda serão considerados modelos de ordem maior que os quadráticos, dificultando a otimização via métodos não lineares.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#planejamento-simplex-centróide",
    "href": "08-mix.html#planejamento-simplex-centróide",
    "title": "8  Experimentos para Misturas",
    "section": "8.6 Planejamento simplex-centróide",
    "text": "8.6 Planejamento simplex-centróide\nUm planejamento simplex-centróide é outra opção interessante para experimentos de misturas. Este planejamento pode ser denotado por SCD(\\(q\\)), onde \\(q\\) consiste ao mesmo tempo no número de componentes e na ordem do modelo possível de ser obtido. Um planejamento simplex centróide de ordem \\(q\\) apresentará:\n\n\\(\\binom {q}{1}\\) misturas puras;\n\\(\\binom {q}{2}\\) misturas binárias;\n\\(\\binom {q}{3}\\) misturas ternárias;\n\\(\\vdots\\)\n\\(\\binom {q}{q} = 1\\) mistura de ordem \\(q\\).\n\nLogo, um planejamento simplex-centróide apresentará \\(N=2^q-1\\) experimentos. A Figura 8.7 ilustra um planejamento simplex-centróide para \\(q=3\\), SCD(3). Pode-se observar que ele contém 7 pontos, 3 misturas puras, que são os experimentos com proporção unitária de cada componente ilustrados nos vértices do planejamento, 2 misturas binárias que são combinações dois a dois com metade de cada um dos componentes envolvidos ilustrados no meio das arestas e uma mistura ternária que apresenta um terço de cada um dos três componentes, sendo ilustrada no centro do planejamento. O planejamento é exposto integralmente na Tabela 8.3.\n\n\n\n\n\n\n\n\nFigura 8.7: Planejamento SCD(3)\n\n\n\n\n\n\n\n\n\nTabela 8.3: Planejamento SCD(3)\n\n\n\n\n\n\nx1\nx2\nx3\n\n\n\n\n1.0000000\n0.0000000\n0.0000000\n\n\n0.0000000\n1.0000000\n0.0000000\n\n\n0.0000000\n0.0000000\n1.0000000\n\n\n0.5000000\n0.5000000\n0.0000000\n\n\n0.5000000\n0.0000000\n0.5000000\n\n\n0.0000000\n0.5000000\n0.5000000\n\n\n0.3333333\n0.3333333\n0.3333333\n\n\n\n\n\n\n\n\nA Equação 8.5 apresenta o polinômio geral que pode ser obtido via SCD(\\(q\\)). Por exemplo, para \\(q=2\\), só é possível obter um modelo de segunda ordem. Já para \\(q=3\\) é possível obter o modelo exibido antes das reticências, enquanto para \\(q\\geq4\\) mais termos são adicionados, um para cada componente adicional considerado.\n\\[\n\\hat y = \\sum_{i=1}^q \\beta_i x_i + \\sum_{i &lt; }\\sum_j \\beta_{ij} x_i x_j +  \\sum_{i &lt; }\\sum_j\\sum_l \\beta_{ijl}x_ix_jx_l + \\dots\n\\tag{8.5}\\]\n\nExemplo 8.2 Seja um experimento de mistura para obter um biodiesel a base de óleo vegetal e gordura animal. Os componentes da mistura são óleo de soja, sebo bovino e gordura de aves. A resposta é o período de indução no ensaio, de forma que um valor maior resulta em maior resistência à oxidação. Foi utilizado um SCD(3) para o estudo.\n\nA Tabela 8.4 expõe o planejamento SCD(3) com a resposta. O código abaixo é usado para obter tal planejamento. O comando SCD é usado para obter o planejamento.\n\n# simplex centroide, q = 3\nplan.centroide &lt;- SCD(3)\n\n# replicando ponto central\nplan.centroide &lt;- rbind(plan.centroide,\n                        plan.centroide[7,],\n                        plan.centroide[7,],\n                        plan.centroide[7,])\n\n# desenho planejamento\n# DesignPoints(plan.centroide)\n\n# Resposta\nIP &lt;- c(3.76, 9.57, 9.77, 8.19, 7.92, 12.92,\n        10.04, 9.27, 10.07, 9.35)\n\n# adicionando resposta ao planejamento\nplan.centroide$y &lt;- IP\n\n\n\n\n\nTabela 8.4: Planejamento SCD(3) para o experimento de biodiesel\n\n\n\n\n\n\n\nx1\nx2\nx3\ny\n\n\n\n\n1\n1.0000000\n0.0000000\n0.0000000\n3.76\n\n\n2\n0.0000000\n1.0000000\n0.0000000\n9.57\n\n\n3\n0.0000000\n0.0000000\n1.0000000\n9.77\n\n\n4\n0.5000000\n0.5000000\n0.0000000\n8.19\n\n\n5\n0.5000000\n0.0000000\n0.5000000\n7.92\n\n\n6\n0.0000000\n0.5000000\n0.5000000\n12.92\n\n\n7\n0.3333333\n0.3333333\n0.3333333\n10.04\n\n\n71\n0.3333333\n0.3333333\n0.3333333\n9.27\n\n\n72\n0.3333333\n0.3333333\n0.3333333\n10.07\n\n\n73\n0.3333333\n0.3333333\n0.3333333\n9.35\n\n\n\n\n\n\n\n\nA seguir expõe-se a sintaxe para modelagem e o modelo cúbico obtido. Os três termos lineares foram signifcativos além do termo de segunda ordem \\(x_2x_3\\).\n\nres.centroide &lt;- lm(y ~ -1 + (x1+x2+x3)^3, plan.centroide)\nsummary(res.centroide)\n\n\nCall:\nlm(formula = y ~ -1 + (x1 + x2 + x3)^3, data = plan.centroide)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-2.776e-17  1.388e-17 -1.388e-17 -1.628e-17 -7.786e-18 -2.637e-17  3.575e-01 \n        71         72         73 \n-4.125e-01  3.875e-01 -3.325e-01 \n\nCoefficients:\n         Estimate Std. Error t value Pr(&gt;|t|)    \nx1         3.7600     0.4315   8.713 0.003182 ** \nx2         9.5700     0.4315  22.176 0.000201 ***\nx3         9.7700     0.4315  22.640 0.000189 ***\nx1:x2      6.1000     2.1141   2.885 0.063250 .  \nx1:x3      4.6200     2.1141   2.185 0.116764    \nx2:x3     13.0000     2.1141   6.149 0.008652 ** \nx1:x2:x3 -17.6325    10.9278  -1.614 0.205028    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4315 on 3 degrees of freedom\nMultiple R-squared:  0.9994,    Adjusted R-squared:  0.9979 \nF-statistic: 669.6 on 7 and 3 DF,  p-value: 8.779e-05\n\n\nPara obter o mesmo modelo via MixModel é importante definir o modelo com o argumento model = 4, sendo este o quarto tipo de modelo definido pelo autor do pacote para a função, não tendo relação com a ordem do modelo.\n\n# res.cent &lt;- MixModel(frame = plan.centroide,\n#                      response = \"y\",\n#                      mixcomps = c(\"x1\", \"x2\", \"x3\"),\n#                      model = 4)\n\nA Figura 8.8 expõe o gráfico de contorno para o experimento de biodiesel obtida com sintaxe exibida abaixo. Observa-se que aproximadamente metade de sebo bovino e metade de gordura de aves na mistura acarreta no biodiesel com maior resistência à corrosão.\n\npar(mar = rep(0.2, 4))\nTernaryPlot(\"x1\",\"x2\",\"x3\", \nalab = \"óleo de soja\", \nblab = \"sebo bovino\", \nclab = \"gordura de aves\")\n\nFunctionToContour &lt;- function(a, b, c) {\n  yhat &lt;- predict(res.centroide, newdata = data.frame(x1=a,\n                                                      x2=b,\n                                                      x3=c))\n  return(yhat)\n}\n\n# Add contour lines\nvalues &lt;- TernaryContour(FunctionToContour, \n                         # resolution = 36L, \n                         filled = TRUE)\n\nzRange &lt;- range(values$z, na.rm = TRUE)\n\n# Continuous legend for colour scale\nPlotTools::SpectrumLegend(\n  \"topleft\",\n  legend = round(seq(zRange[1], zRange[2], length.out = 4), 3),\n  palette = hcl.colors(265, palette = \"viridis\", alpha = 0.6),\n  bty = \"n\",    # No framing box\n  inset = 0.02,\n  xpd = NA      # Do not clip at edge of figure\n)\n\n\n\n\n\n\n\nFigura 8.8: Gráfico de contorno para o experimento de biodiesel\n\n\n\n\n\nO código a seguir é utilizado para otimização. Pode-se confirmar que \\(x_2 = 0,492\\) e \\(x_3 = 0,508\\) são as proporções ótimas dos componentes e 12,92 seria o valor ótimo da resposta prevista.\n\n# Funcao objetivo\nobj &lt;- function(x){\n  \n  y_hat &lt;- predict(res.centroide,\n                   newdata = data.frame(x1 = x[1],\n                                        x2 = x[2],\n                                        x3 = x[3]))\n  return(-y_hat) # maximizacao\n}\n\n# restricao\ncons_eq &lt;- function(x) {\n  g &lt;- x[1]+x[2]+x[3]-1\n  return(list(ceq = g, c = NULL))\n}\n\n# x inicial\nx0 &lt;- c(1/3,1/3,1/3)\n\n# Otimizacao\nOpt &lt;- solnl(X = x0,\n             objfun = obj,\n             confun = cons_eq,\n             lb = rep(0,3),\n             ub = rep(1,3))\n\n# proporcoes otimas\nOpt$par\n\n              [,1]\n[1,] -6.758037e-16\n[2,]  4.923077e-01\n[3,]  5.076923e-01\n\n\n\n# Resposta\n-Opt$fn\n\n       1 \n12.92077",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#planejamento-de-vértices-extremos",
    "href": "08-mix.html#planejamento-de-vértices-extremos",
    "title": "8  Experimentos para Misturas",
    "section": "8.7 Planejamento de vértices extremos",
    "text": "8.7 Planejamento de vértices extremos\nEm muitos experimentos de misturas não é possível realizar misturas puras, ou de outra forma, para o experimento dar certo é necessário que todos componentes estejam envolvidos na mistura. Por exemplo, para fazer massa artesanal é necessário farinha, ovos, água e sal. Não seria viável uma massa sem farinha. Para fazer reboco sugere-se usar argamassa, cal, cimento e aditivo. A ausência de um dos componentes pode deixar o reboco mais fraco ou com consistência inadequada para aplicação. Obviamente que nestes exemplos os profssionais da área já sabem a composição ótima da mistura. Porém, em casos onde deseja-se trabalhar experimentos de mistura com restrições nos componentes, deve-se usar o planejamento de vértices extremos.\nO planejamento de vértices extremos pode ser usado quando um ou mais componentes apresentam limites nas proporções diferentes de 0 e/ou 1, isto é:\n\\[\nl_i \\leq x_i \\leq u_i \\text{, } i=1,\\dots,q,\n\\]\ncom \\(l_i &gt;0\\) e \\(u_i &lt; 1\\). Um primeiro caso do planejamento de vértices extremos seria aquele com limite inferior apenas, \\(l_i \\leq x_i \\leq 1\\), \\(i=1,\\dots,q\\). Por exemplo, suponha um experimento de misturas com as seguintes restrições:\n\\[\n\\begin{cases}\nx_1 \\geq 0,3\\\\\nx_2 \\geq 0,4\\\\\nx_3 \\geq 0,1.\n\\end{cases}                                                     \n\\]\nA Figura 8.9 ilustra tais restrições no espaço simplex, com \\(x_1 \\geq 0,3\\) em vermelho, \\(x_2 \\geq 0,4\\) em azul e \\(x_3 \\geq 0,1\\) em verde. Observe que neste tipo de experimento a região continua consistindo em um triângulo equilátero - para \\(q=3\\), logo, em uma região simplex. Porém, os vértices não são mais misturas puras. Na imagem observa-se que o vértice em laranja consiste em \\((0,5;0,4;0,1)\\), enquanto o vértice em roxo consiste em \\((0,3;0,6;0,1)\\) e o vértice em verde consiste em \\((0,3;0,4;0,3)\\).\n\n\n\n\n\n\n\n\nFigura 8.9: Região restrita no planejamento de misturas com \\(x_1 \\geq 0,3\\), \\(x_2 \\geq 0,4\\) e \\(x_1 \\geq 0,1\\)\n\n\n\n\n\nÉ possível descrever os componentes de forma codificada como pseudo componentes, de forma que os novos vértices seriam misturas puras neste simplex codificado. Usando a Equação 8.6 obtém-se a proporção do pseudo-componente.\n\\[\nX_i = \\frac{x_i-l_i}{1-\\sum_{i=1}^q l_i}\n\\tag{8.6}\\]\nQuando o experimento apresenta apenas limites superiores, \\(0 \\leq x_i \\leq u_i\\), \\(i=1,\\dots,q\\), há dois casos possíveis. Seja um experimento de misturas com as seguintes restrições:\n\\[\n\\begin{cases}\nx_1 \\leq 0,4\\\\\nx_2 \\leq 0,5\\\\\nx_3 \\leq 0,3.\n\\end{cases}                                                     \n\\]\nA Figura 8.10 ilustra tal caso. Pode-se observar que a região restrita consiste em um simplex invertido. Observa-se neste caso a restrição \\(x_1 \\leq 0,4\\) em vermelho, \\(x_2 \\leq 0,5\\) em azul e \\(x_3 \\leq 0,3\\) em verde. São gerados os vértices \\((0,2;0,5;0,3)\\) em verde, \\((0,4;0,5;0,1)\\) em roxo e \\((0,4;0,3;0,3)\\) em laranja. Para saber se um experimento de misturas apresentará região simplex invertida, basta fazer \\(\\sum u_i - min\\{u_i\\}\\). Caso o resultado seja menor que 1, tem-se um simplex invertido. Para o exemplo, \\(0,4+0,5+0,3-0,3 = 0,9\\). Logo, confirma-se o observado na Figura.\n\n\n\n\n\n\n\n\nFigura 8.10: Região restrita no planejamento de misturas com \\(x_1 \\leq 0,4\\), \\(x_2 \\leq 0,5\\) e \\(x_1 \\leq 0,3\\)\n\n\n\n\n\nSeja um segundo caso com apenas limites superiores, conforme segue:\n\\[\n\\begin{cases}\nx_1 \\leq 0,7\\\\\nx_2 \\leq 0,5\\\\\nx_3 \\leq 0,8.\n\\end{cases}                                                     \n\\]\nA Figura 8.11 ilustra tal região restrita. Pode-se observar que neste caso a região não é um simplex. Sugere-se ao leitor identificar as restrições definidas em cores distintas e também os vértices gerados. Observa-se que neste caso foram gerados seis vértices. Sempre que \\(\\sum u_i - min\\{u_i\\} &gt; 1\\), tem-se uma região experimental não triangular e o número de vértices dependerá das restrições.\n\n\n\n\n\n\n\n\nFigura 8.11: Região restrita no planejamento de misturas com \\(x_1 \\leq 0,7\\), \\(x_2 \\leq 0,5\\) e \\(x_1 \\leq 0,8\\)\n\n\n\n\n\nO planejamento de vértices extremos sempre considera, além dos pontos nos vértices, os quais dependem das restrições, um ponto central ou centróide que também dependerá das restrições e da região gerada. Para casos nos quais deseja-se modelos de ordem maior, pode-se considerar também pontos intermediários nas arestas geradas segundo as restrições. Deve-se recordar que a ordem do polinômio de misturas depende do número de pontos. Para modelos de segunda ordem na forma da Equação 8.2 é necessário no mínimo \\(q + q(q-1)/2\\) experimentos. A Figura 8.12 ilustra o planejamento com as restrições do último exemplo. Neste caso o centróide gerado consiste em \\((0,35;0,25;0,4)\\) e o planejamento fica com \\(N=7\\) experimentos. O número de experimentos dependerá das restrições e se são considerados ou não os pontos intermediários nas arestas. Obviamente há casos onde são considerados limites inferiores e superiores dos componentes.\n\n\n\n\n\n\n\n\nFigura 8.12: Planejamento de vértices extremos com restrições \\(x_1 \\leq 0,7\\), \\(x_2 \\leq 0,5\\) e \\(x_1 \\leq 0,8\\)\n\n\n\n\n\n\nExemplo 8.3 Seja um experimento de mistura para o desenvolvimento de filmes de amido de mandioca e quitosana. Além de amido (\\(x_1\\)) e quitosana (\\(x_2\\)), há na mistura glicerol (\\(x_3\\)). São consideradas as seguintes restrições: \\(0,7 \\leq x_1 \\leq 0,82\\), \\(0 \\leq x_2 \\leq 0,05\\) e \\(0,18 \\leq x_3 \\leq 0,25\\). A resposta medida é o módulo de Young.\n\nA Tabela 8.5 expõe o planejamento com a resposta. O código abaixo é usado para obter tal planejamento com o comando Xvert do pacote mixexp.\n\ndesign &lt;- Xvert(nfac = 3, \n                lc = c(0.70, 0.00, 0.18),\n                uc = c(0.82, 0.05, 0.25), \n                ndm = 1, plot = F)\ndesign &lt;- rbind(design, design[9,], design[9,])\n\n# Resposta\nym &lt;- c(2.45, 0.85, 2.54, 1.08, 1.97, 2.06, 2.71, 0.99, 1.33, 1.38, 1.53)\n\ndesign$y &lt;- ym\n\n\n\n\n\nTabela 8.5: Planejamento de vértices extremos para o experimento de filmes de amido de mandioca e quitosana\n\n\n\n\n\n\n\nx1\nx2\nx3\ndimen\ny\n\n\n\n\n1\n0.820\n0.000\n0.180\n0\n2.45\n\n\n2\n0.700\n0.050\n0.250\n0\n0.85\n\n\n3\n0.770\n0.050\n0.180\n0\n2.54\n\n\n4\n0.750\n0.000\n0.250\n0\n1.08\n\n\n5\n0.785\n0.000\n0.215\n1\n1.97\n\n\n6\n0.735\n0.050\n0.215\n1\n2.06\n\n\n7\n0.795\n0.025\n0.180\n1\n2.71\n\n\n8\n0.725\n0.025\n0.250\n1\n0.99\n\n\n9\n0.760\n0.025\n0.215\n2\n1.33\n\n\n91\n0.760\n0.025\n0.215\n2\n1.38\n\n\n92\n0.760\n0.025\n0.215\n2\n1.53\n\n\n\n\n\n\n\n\nA seguir expõe-se a sintaxe para modelagem e resultado obtido. Seguiu-se o modelo considerado pelos autores do trabalho com apenas dois termos de segunda ordem. Entretanto, apenas os termos lineares de \\(x_1\\) e \\(x_3\\) foram significativos.\n\nres.xvert &lt;- lm(y ~ -1 + (x1 + x2 + x3)^2 - x1:x3, design)\nsummary(res.xvert)\n\n\nCall:\nlm(formula = y ~ -1 + (x1 + x2 + x3)^2 - x1:x3, data = design)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.2580 -0.1267 -0.0580  0.1677  0.3253 \n\nCoefficients:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nx1       6.236      1.008   6.189 0.000819 ***\nx2     385.799    233.487   1.652 0.149553    \nx3     -14.240      3.643  -3.909 0.007904 ** \nx1:x2 -379.200    243.612  -1.557 0.170576    \nx2:x3 -470.628    282.828  -1.664 0.147167    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2514 on 6 degrees of freedom\nMultiple R-squared:  0.9897,    Adjusted R-squared:  0.9811 \nF-statistic: 115.2 on 5 and 6 DF,  p-value: 7.102e-06\n\n\nA Figura 8.13 expõe o gráfico de contorno do modelo obtido com código abaixo. Este foi plotado em pseudo componentes para facilitar a visualização.\n\nModelPlot(model = res.xvert,\n          dimensions = list(x1 = \"x1\",\n                            x2 = \"x2\",\n                            x3 = \"x3\"),\n          constraints = T,\n          lims = c(0.70, 0.82, 0.00, 0.05, 0.18, 0.25),\n          pseudo = T,\n          contour = T, \n          fill = T,\n          color.palette = terrain.colors,\n          colorkey = T,\n          axislab.offset = 0.1)\n\n\n\n\n\n\n\nFigura 8.13: Gráfico de contorno para o experimento de filmes de amido de mandioca e quitosana\n\n\n\n\n\nA seguir expõe-se a sintaxe para otimização com o resultado obtido. Neste caso considerou-se a minimização do módulo de Young para obter filmes mais flexíveis. Sugere-se \\((0.72, 0.03, 0.25)\\) para obter \\(\\hat y = 0,783\\).\n\n# Funcao objetivo\nobj &lt;- function(x){\n  \n  y_hat &lt;- predict(res.xvert,\n                   newdata = data.frame(x1 = x[1],\n                                        x2 = x[2],\n                                        x3 = x[3]))\n  return(y_hat) # min\n}\n\n# restricao\ncons_eq &lt;- function(x) {\n  g &lt;- x[1]+x[2]+x[3]-1\n  return(list(ceq = g, c = NULL))\n}\n\n# x inicial\nx0 &lt;- c(0.76,0.025,0.215)\n\n# Otimizacao\nOpt &lt;- solnl(X = x0,\n             objfun = obj,\n             confun = cons_eq,\n             lb = c(0.7,0,0.18),\n             ub = c(0.82,0.05,0.25))\n\n# proporcoes otimas\nOpt$par\n\n           [,1]\n[1,] 0.72034106\n[2,] 0.02965894\n[3,] 0.25000000\n\n\n\n\n        1 \n0.7831026",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "08-mix.html#bibliografia",
    "href": "08-mix.html#bibliografia",
    "title": "8  Experimentos para Misturas",
    "section": "Bibliografia",
    "text": "Bibliografia\nCORNELL, John A. A primer on experiments with mixtures. John Wiley & Sons, 2011.\nCORNELL, John A. Experiments with mixtures: designs, models, and the analysis of mixture data. Wiley-interscience, 2002. 3rd edition.\nDAS, Dipayan; MUKHOPADHYAY, Samrat; KAUR, Harpreet. Optimization of fiber composition in natural fiber-reinforced composites using a simplex lattice design. Journal of composite materials, v. 46, n. 26, p. 3311-3319, 2012.\nORIVES, Juliane Resges et al. Multiresponse optimisation on biodiesel obtained through a ternary mixture of vegetable oil and animal fat: Simplex-centroid mixture design application. Energy Conversion and Management, v. 79, p. 398-404, 2014.\nPELISSARI, Franciele M. et al. Constrained mixture design applied to the development of cassava starch–chitosan blown films. Journal of Food Engineering, v. 108, n. 2, p. 262-267, 2012.\nSCHEFFÉ, Henry. Experiments with mixtures. Journal of the Royal Statistical Society: Series B (Methodological), v. 20, n. 2, p. 344-360, 1958.\nSCHEFFE, Henry. The simplex‐centroid design for experiments with mixtures. Journal of the Royal Statistical Society: Series B (Methodological), v. 25, n. 2, p. 235-251, 1963.\nSNEE, Ronald D. Experimental designs for quadratic models in constrained mixture spaces. Technometrics, v. 17, n. 2, p. 149-159, 1975.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Experimentos para Misturas</span>"
    ]
  },
  {
    "objectID": "07-rsm.html#planejamento-fatorial-2k-com-pontos-centrais",
    "href": "07-rsm.html#planejamento-fatorial-2k-com-pontos-centrais",
    "title": "7  Metodologia de Superfície de Resposta",
    "section": "7.3 Planejamento fatorial \\(2^k\\) com pontos centrais",
    "text": "7.3 Planejamento fatorial \\(2^k\\) com pontos centrais\nEm diversas situações um modelo linear pode não se ajustar bem à região experimental. Nestes casos o fatorial \\(2^k\\) não oferecerá um modelo de regressão útil em toda região experimental, especialmente para a região central do planejamento. Há casos também que o experimentador deseja testar a presença de curvatura, isto é, testar se um modelo quadrático se ajustaria melhor aos dados, para propósito de experimentação sequencial e busca dos níveis ótimos operacionais dos fatores de controle avaliados.\nA adição de pontos centrais no fatorial \\(2^k\\) permite testar a presença de curvatura na região experimental. Os pontos centrais são condições intermediárias entre os dois níveis fatoriais, sendo codificados em \\(x_{j(0)}=0\\). O planejamento fatorial com pontos centrais permite testar a hipótese \\(H_0: \\sum\\beta_{jj}=0\\), onde \\(\\beta_{jj}\\), \\(j = 1, ..., k\\) são os coeficientes quadráticos, sendo portanto multiplicados por \\(x_j^2\\), \\(j = 1, ..., k\\), em um modelo de regressão de segunda ordem completo almejado. O fatorial \\(2^k\\) com pontos centrais não permite, entretanto, estimar um modelo quadrático, visto que não tem níveis suficientes para tal finalidade. Entretanto, ele é um passo preliminar para a obtenção de um modelo com termos de segunda ordem puros (quadráticos), possibilitando a posterior realização de experimentos em níveis adicionais para viabilizar a obtenção de um modelo quadrático. Tal estratégia sequencial para metodologia de superfície de resposta pode ser efetivada via planejamento composto central.\nO fatorial \\(2^k\\) com pontos centrais também permite a economia experimental pela replicação apenas na condição intermediária, especialmente nos casos com elevado número de fatores \\(k\\). Deste modo, ao se obter um modelo completo via fatorial \\(2^k\\) com pontos centrais, os graus de liberdade para o erro são calculados com base nos pontos centrais, sendo o erro experimental estimado tomando a variância dos pontos centrais, conforme Equação 5.8, onde \\(y_{c(i)}\\) é o i-ésimo ponto central e \\(n_c\\) é o número de pontos centrais.\n\\[\n\\hat{\\sigma}^2 = MS_E = \\frac{\\displaystyle \\sum_{i=1}^{n_c}(y_{c(i)}-\\bar{y}_c)^2}{n_c-1}\n\\tag{7.3}\\]\n\nExemplo 7.1 A influência da temperatura, da concentração de catalisador e da razão molar álcool/óleo no rendimento da produção de uma fração de baixo peso molecular foi estudada e otimizada por meio de um planejamento fatorial. A fração é composta de ésteres de caprilato, caprato, laurato e miristato butílico, os quais podem ser usados como valorosos produtos químicos (devido a suas inúmeras aplicações nas indústrias cosmética, farmacêutica e de alimentos). O planejamento fatorial \\(2^3\\) com adição de pontos centrais foi inicialmente utilizado para testar curvatura e avaliar a possibilidade futura de obtenção de um modelo quadrático. O planejamento é exposto na Tabela 7.1.\n\n\n\n\n\nTabela 7.1: Planejamento fatorial 23 com pontos centrais\n\n\n\n\n\n\nordem\nT [ºC]\nC [%]\nMR\ny [%]\n\n\n\n\n1\n55\n3\n3\n38\n\n\n2\n75\n3\n3\n49\n\n\n3\n55\n7\n3\n59\n\n\n4\n75\n7\n3\n49\n\n\n5\n55\n3\n7\n39\n\n\n6\n75\n3\n7\n59\n\n\n7\n55\n7\n7\n65\n\n\n8\n75\n7\n7\n75\n\n\n9\n65\n5\n5\n63\n\n\n10\n65\n5\n5\n62\n\n\n11\n65\n5\n5\n58\n\n\n12\n65\n5\n5\n60\n\n\n\n\n\n\n\n\nO efeito dos pontos centrais \\(E_{0}\\) é calculado como a diferença entre médias entre os pontos centrais e os pontos axiais, conforme Equação 7.4, onde \\(\\bar{y}_{fat}\\) é a média dos pontos fatoriais, enquanto \\(\\bar{y}_{ctpt}\\) é a média dos pontos centrais.\n\\[\nE_{0} = \\bar{y}_{fat}-\\bar{y}_{ctpt}\n\\tag{7.4}\\]\nPara gerar o planejamento do Exemplo 7.1 pode-se utilizar o código à seguir.\n\nlibrary(FrF2)\n# Planejamento\nplanctpt &lt;- FrF2(nruns = 8,\n                 nfactors = 3, \n                 factor.names = c(\"T\", \"C\", \"MR\"),\n                 ncenter = 4,\n                 randomize = F)\n\n# Adicionando a coluna com a resposta\nplanctpt$y &lt;- c(38, 49, 59, 49, 39, 59, 65, 75, 63, 62, 58, 60)\n\nsummary(planctpt)\n\nCall:\nFrF2(nruns = 8, nfactors = 3, factor.names = c(\"T\", \"C\", \"MR\"), \n    ncenter = 4, randomize = F)\n\nExperimental design of type  full factorial.center \n12  runs\n\nFactor settings (scale ends):\n   T  C MR\n1 -1 -1 -1\n2  1  1  1\n\nThe design itself:\n    T  C MR  y\n1  -1 -1 -1 38\n2   1 -1 -1 49\n3  -1  1 -1 59\n4   1  1 -1 49\n5  -1 -1  1 39\n6   1 -1  1 59\n7  -1  1  1 65\n8   1  1  1 75\n9   0  0  0 63\n10  0  0  0 62\n11  0  0  0 58\n12  0  0  0 60\nclass=design, type= full factorial.center \n\n\nPara testar a curvatura, deve-se considerar a soma dos quadrados para curvatura, conforme Equação 7.5.\n\\[\nSS_0 = \\frac{n_{fat}n_{ctpt}(\\bar{y}_{fat}-\\bar{y}_{center})^2}{n_{fat}+n_{ctpt}}\n\\tag{7.5}\\]\nPara obter a ANOVA com teste de curvatura, deve-se proceder conforme segue. Optou-se por adicionar uma coluna center no planejamento para testar curvatura. Posteriormente, adicionou-se o termo center no modelo. Outra opção, caso o analista não queira criar esta coluna seria adicionando o termo !iscube(planctpt) no modelo. Em caso de significância na curvatura, o modelo de regressão é útil desde que ao realizar previsão nos pontos centrais, seja somado o efeito dos pontos centrais. Já ao realizar previsão nos pontos fatoriais o efeito da curvatura deve ser desconsiderado.\nPara o Exemplo 7.1 o teste de curvatura apresentou significância estatística, \\(p-valor = 0,01646 &lt; 0,05 = \\alpha\\). Consequentemente, é viável a realização de experimentos adicionais para estimar um modelo quadrático completo. Entretanto, este exemplo será retomado posteriormente para entendimento da estratégia sequencial para metodologia de superfície de resposta.\n\n# Adicionando coluna para teste de curvatura\nplanctpt$center &lt;- c(rep(0, times =8), rep(1, times = 4))\n\n# Regressão teste de curvatura\nlm1 &lt;- lm(formula = y ~ T*C*MR + center, data = planctpt)\nsummary(lm1)\n\n\nCall:\nlm.default(formula = y ~ T * C * MR + center, data = planctpt)\n\nResiduals:\n         1          2          3          4          5          6          7 \n 3.053e-16  1.031e-16 -1.048e-16 -8.049e-17 -1.489e-16 -1.462e-17  2.309e-16 \n         8          9         10         11         12 \n 1.087e-16  2.250e+00  1.250e+00 -2.750e+00 -7.500e-01 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   54.125      0.784  69.041  6.7e-06 ***\nT              3.875      0.784   4.943  0.01588 *  \nC              7.875      0.784  10.045  0.00210 ** \nMR             5.375      0.784   6.856  0.00635 ** \ncenter         6.625      1.358   4.879  0.01646 *  \nT:C           -3.875      0.784  -4.943  0.01588 *  \nT:MR           3.625      0.784   4.624  0.01904 *  \nC:MR           2.625      0.784   3.348  0.04411 *  \nT:C:MR         1.375      0.784   1.754  0.17772    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.217 on 3 degrees of freedom\nMultiple R-squared:  0.9884,    Adjusted R-squared:  0.9576 \nF-statistic: 32.03 on 8 and 3 DF,  p-value: 0.008\n\n# ANOVA\n# anova1 &lt;- aov(lm1)\n# summary(anova1)\n\nA Figura 7.2 ilustra os gráficos de efeitos principais. Pode-se observar que a média da resposta nos pontos centrais confirma o indício de presença de curvatura na região experimental.\n\nplanctpt$fit &lt;- lm1$fitted.values \n\nmeanc1 &lt;- planctpt |&gt;\n  group_by(T) |&gt;\n  summarise(y=mean(fit))\n\nmeanc2 &lt;- planctpt |&gt;\n  group_by(C) |&gt;\n  summarise(y=mean(fit))\n\nmeanc3 &lt;- planctpt |&gt;\n  group_by(MR) |&gt;\n  summarise(y=mean(fit))\n\nmeanc1$ct &lt;- ifelse(meanc1$T == 0, \"0\", \"1\")\nmeanc2$ct &lt;- ifelse(meanc2$C == 0, \"0\", \"1\")\nmeanc3$ct &lt;- ifelse(meanc3$MR == 0, \"0\", \"1\")\n\nrangec &lt;- c(min(meanc1$y,meanc2$y,meanc3$y),\n            max(meanc1$y,meanc2$y,meanc3$y))\n\npc1 &lt;- ggplot(meanc1, aes(T,y,col = ct)) + \n  geom_line(lwd=1) +\n  geom_point(size=2) +\n  ylim(rangec) + theme(legend.position=\"none\")\n\npc2 &lt;- ggplot(meanc2, aes(C,y,col = ct)) + \n  geom_line(lwd=1) +\n  geom_point(size=2) +\n  ylim(rangec) + theme(legend.position=\"none\")\n\npc3 &lt;- ggplot(meanc3, aes(MR,y,col = ct)) + \n  geom_line(lwd=1) +\n  geom_point(size=2) +\n  ylim(rangec) + theme(legend.position=\"none\")\n\nlibrary(ggpubr)\nggarrange(pc1,pc2,pc3, nrow=1)\n\n\n\n\n\n\n\nFigura 7.2: Efeitos principais, fatorial \\(2^k\\) com pontos centrais\n\n\n\n\n\nA Figura 7.3 ilustra os gráficos de interação de segunda ordem. Os pontos centrais são plotados à parte.\n\nmeanc12 &lt;- planctpt |&gt;\n  group_by(T,C) |&gt;\n  summarise(y=mean(fit))\n\nmeanc13 &lt;- planctpt |&gt;\n  group_by(T,MR) |&gt;\n  summarise(y=mean(fit))\n\nmeanc23 &lt;- planctpt |&gt;\n  group_by(C,MR) |&gt;\n  summarise(y=mean(fit))\n\nrangecc &lt;- c(min(meanc12$y,meanc13$y,meanc23$y),\n             max(meanc12$y,meanc13$y,meanc23$y))\n\npc12 &lt;- ggplot() + \n  geom_line(data = meanc12 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(C),\n                   shape = as.factor(C)), lwd=1) +\n  geom_point(data = meanc12 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(C),\n                   shape = as.factor(C)), size=2) +\n  geom_point(data = meanc12 |&gt; filter(T == 0),\n             mapping = aes(x=T, y), shape=8, size=2) +\n  ylim(rangecc) + \n  labs(col = \"C\", shape = \"C\") + \n  theme(legend.position = \"bottom\")\n\npc13 &lt;- ggplot() + \n  geom_line(data = meanc13 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(MR),\n                   shape = as.factor(MR)), lwd=1) +\n  geom_point(data = meanc13 |&gt; filter(T != 0),\n               mapping = aes(x=T, y, col = as.factor(MR),\n                   shape = as.factor(MR)), size=2) +\n  geom_point(data = meanc13 |&gt; filter(T == 0),\n             mapping = aes(x=T, y), shape=8, size=2) +\n  ylim(rangecc) + \n  labs(col = \"MR\", shape = \"MR\") + \n  theme(legend.position = \"bottom\")\n\npc23 &lt;- ggplot() + \n  geom_line(data = meanc23 |&gt; filter(C != 0),\n               mapping = aes(x=C, y, col = as.factor(MR),\n                   shape = as.factor(MR)), lwd=1) +\n  geom_point(data = meanc23 |&gt; filter(C != 0),\n               mapping = aes(x=C, y, col = as.factor(MR),\n                   shape = as.factor(MR)), size=2) +\n  geom_point(data = meanc23 |&gt; filter(C == 0),\n             mapping = aes(x=C, y), shape=8, size=2) +\n  ylim(rangecc) + \n  labs(col = \"MR\", shape = \"MR\") + \n  theme(legend.position = \"bottom\")\n\nlibrary(ggpubr)\nggarrange(pc12,pc13,pc23, nrow=1)\n\n\n\n\n\n\n\nFigura 7.3: Interações no fatorial com pontos centrais",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodologia de Superfície de Resposta</span>"
    ]
  }
]